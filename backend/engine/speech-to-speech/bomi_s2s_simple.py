import os
from pathlib import Path

import numpy as np
import sounddevice as sd
import soundfile as sf
from dotenv import load_dotenv

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from openai import OpenAI

from melo.api import TTS as MeloTTS


# ===== 0. ê¸°ë³¸ ì„¤ì • & í™˜ê²½ ë³€ìˆ˜ =====
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    raise SystemExit(1)

openai_client = OpenAI(api_key=OPENAI_API_KEY)

SAMPLE_RATE = 16000
CHANNELS = 1
BLOCK_SEC = 10  # í•œ ë²ˆì— 10ì´ˆì”© ë…¹ìŒ

# ğŸ”Š ë¬´ìŒ ê°ì§€ ì„¤ì •
SILENCE_THRESHOLD = 500  # ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ê±°ì˜ ë¬´ìŒìœ¼ë¡œ ê°„ì£¼
SILENT_ROUNDS_FOR_HINT = 2  # ì—°ì† ëª‡ ë²ˆ ë¬´ìŒì¼ ë•Œ ëŒ€ê¸° ë©˜íŠ¸

# ì¢…ë£Œ í‚¤ì›Œë“œ
END_KEYWORDS = [
    "ì¢…ë£Œ",
    "ê·¸ë§Œ",
    "ë",
    "ë‚˜ê°ˆê²Œ",
    "ë‚˜ê°ˆê²Œ ì§„ì§œ",
    "ìƒë‹´ì¢…ë£Œ",
    "ìƒë‹´ì¢…ë£Œí•´ì¤˜",
    "ìƒë‹´ ì¢…ë£Œ",
    "ìƒë‹´ ì¢…ë£Œí•´ì¤˜",
]


def is_end_command(text: str) -> bool:
    """ì‚¬ìš©ì ë°œí™”ì— ì¢…ë£Œ ê´€ë ¨ í‘œí˜„ì´ ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸"""
    if not text:
        return False
    t = text.strip().replace(" ", "")  # 'ìƒë‹´ ì¢…ë£Œ' â†’ 'ìƒë‹´ì¢…ë£Œ'
    for kw in END_KEYWORDS:
        if kw.replace(" ", "") in t:
            return True
    return False


# ===== 1. Whisper large-v3-turbo ë¡œë”© (STT) =====
WHISPER_MODEL_ID = "openai/whisper-large-v3-turbo"

whisper_device = "cuda:0" if torch.cuda.is_available() else "cpu"
whisper_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

print(
    f"[Whisper] {WHISPER_MODEL_ID} ë¡œë”© ì¤‘... (device={whisper_device}, dtype={whisper_dtype})"
)

whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(
    WHISPER_MODEL_ID,
    torch_dtype=whisper_dtype,
    low_cpu_mem_usage=True,
).to(whisper_device)

whisper_processor = AutoProcessor.from_pretrained(WHISPER_MODEL_ID)

whisper_pipe = pipeline(
    task="automatic-speech-recognition",
    model=whisper_model,
    tokenizer=whisper_processor.tokenizer,
    feature_extractor=whisper_processor.feature_extractor,
    torch_dtype=whisper_dtype,
    device=0 if torch.cuda.is_available() else -1,
    chunk_length_s=20,
    batch_size=4 if torch.cuda.is_available() else 1,
    return_timestamps=False,
)


# ===== 2. MeloTTS ë¡œë”© (3-7 ë´„ì´ ëª©ì†Œë¦¬) =====
MELO_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"[MeloTTS] device = {MELO_DEVICE}")

melo_tts = MeloTTS(language="KR", device=MELO_DEVICE)
MELO_SPEAKER_ID = 0  # 3-7ì—ì„œ ì“°ë˜ speaker_id ê°’ìœ¼ë¡œ í•„ìš”ì‹œ ì¡°ì •


# ===== 3. ë§ˆì´í¬ì—ì„œ í•œ ë²ˆ ë…¹ìŒ =====
def record_once(seconds: int = BLOCK_SEC):
    """
    ë§ˆì´í¬ì—ì„œ secondsì´ˆ ë§Œí¼ ë…¹ìŒí•˜ê³ ,
    ì†Œë¦¬ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ Noneì„ ë¦¬í„´í•´ì„œ 'ì¹¨ë¬µ'ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.
    """
    print(f"\nğŸ™ {seconds}ì´ˆ ë™ì•ˆ ë§ì”€í•´ ì£¼ì„¸ìš”...")
    audio = sd.rec(
        int(seconds * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
    )
    sd.wait()

    audio_int16 = audio.flatten()

    # ìµœëŒ€ ì§„í­ìœ¼ë¡œ ë¬´ìŒ ì—¬ë¶€ íŒë‹¨
    max_amp = int(np.max(np.abs(audio_int16)))
    # print(f"[DEBUG] max_amp={max_amp}")

    if max_amp < SILENCE_THRESHOLD:
        print("ğŸ˜¶ ê±°ì˜ ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ëŒ€ê¸°ëª¨ë“œ í›„ë³´)")
        return None

    return audio_int16


# ===== 4. Whisper STT =====
def stt_whisper(audio_int16: np.ndarray) -> str:
    """
    ë§ˆì´í¬ì—ì„œ ë°›ì€ int16 PCM ë°°ì—´ì„ ê·¸ëŒ€ë¡œ Whisperì— ë„£ì–´ì„œ
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤. (ffmpeg í•„ìš” X)
    """
    print("ğŸ§  STT(Whisper): ë³€í™˜ ì¤‘...")

    # int16 â†’ float32, -1.0 ~ 1.0 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
    audio_float = audio_int16.astype(np.float32) / 32768.0

    result = whisper_pipe(
        audio_float,
        generate_kwargs={"task": "transcribe", "language": "ko"},
    )

    text = (result["text"] or "").strip()
    print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")
    return text


# ===== 5. ë´„ì´ TTS (MeloTTS) =====
def tts_bomi(text: str):
    """ë´„ì´ TTS: MeloTTS(3-7 ë´„ì´ ëª©ì†Œë¦¬)"""
    if not text:
        return

    print("ğŸ”Š TTS(Melo ë´„ì´): ì¬ìƒ ì¤‘...")

    out_path = "bomi_tts.wav"

    melo_tts.tts_to_file(
        text,
        speaker_id=MELO_SPEAKER_ID,
        output_path=out_path,
        speed=1.0,  # í•„ìš”í•˜ë©´ 0.9, 1.1 ì´ëŸ° ì‹ìœ¼ë¡œ ì¡°ì •
    )

    audio_np, sr = sf.read(out_path, dtype="int16")
    sd.play(audio_np, sr)
    sd.wait()


# ===== 6. LLM (OpenAI) - ë´„ì´ ìƒë‹´ì‚¬ =====
SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ 'ë´„ì´'ë¼ëŠ” ì´ë¦„ì˜ ë”°ëœ»í•œ í•œêµ­ì–´ ê°ì • ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. "
    "ëŒ€ë‹µì€ í•­ìƒ 3ë¬¸ì¥ ì´ë‚´ë¡œ, ë‹¤ìŒ í˜•ì‹ì„ ì§€í‚µë‹ˆë‹¤. "
    "1) ì‚¬ìš©ìì˜ ê°ì •ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ê³µê°í•˜ë©° ìš”ì•½í•©ë‹ˆë‹¤. "
    "2) ì™œ ê·¸ëŸ° ê°ì •ì„ ëŠë¼ê²Œ ë˜ì—ˆëŠ”ì§€ ë¶€ë“œëŸ½ê²Œ í•œ ê°€ì§€ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. "
    "3) ì˜¤ëŠ˜ ë‹¹ì¥ í•´ë³¼ ìˆ˜ ìˆëŠ” ì‘ì€ í–‰ë™ í•œ ê°€ì§€ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. "
    "í•­ìƒ í•œêµ­ì–´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ë‰´ìŠ¤ë‚˜ ê³„ì ˆ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”."
)

history = []  # ìµœê·¼ ëª‡ í„´ë§Œ ìœ ì§€


def chat_with_bomi(user_text: str) -> str:
    global history

    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    messages.extend(history)
    messages.append({"role": "user", "content": user_text})

    print("ğŸ¤– LLM: ìƒë‹´ ë‹µë³€ ìƒì„± ì¤‘...")
    resp = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=200,
        temperature=0.7,
    )
    answer = resp.choices[0].message.content.strip()
    print(f"ğŸ’¬ ë´„ì´: {answer}")

    history.append({"role": "user", "content": user_text})
    history.append({"role": "assistant", "content": answer})
    history[:] = history[-10:]  # ìµœê·¼ 10 ë©”ì‹œì§€ë§Œ ìœ ì§€

    return answer


# ===== 7. ë©”ì¸ ë£¨í”„ =====
def main():
    print("=== ë´„ì´ ìŒì„± ìƒë‹´ ë°ëª¨ (Whisper STT + MeloTTS + OpenAI LLM) ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë' ê°™ì´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n")

    silent_rounds = 0  # ì—°ì† ë¬´ìŒ íšŸìˆ˜

    while True:
        try:
            # 1) ë…¹ìŒ
            audio_int16 = record_once(BLOCK_SEC)

            # 2) ì¹¨ë¬µì´ë©´ -> STT/LLM í˜¸ì¶œ ì•ˆ í•˜ê³  â€˜ëŒ€ê¸° ë©˜íŠ¸â€™ ê´€ë¦¬
            if audio_int16 is None:
                silent_rounds += 1

                if silent_rounds >= SILENT_ROUNDS_FOR_HINT:
                    wait_msg = (
                        "ì§€ê¸ˆì€ ì ì‹œ ì¡°ìš©í•œ ì‹œê°„ì´ë„¤ìš”. "
                        "í˜¹ì‹œ ë” ëŒ€í™”í•˜ê³  ì‹¶ìœ¼ì‹  ë‚´ìš©ì´ ìˆìœ¼ì‹¤ê¹Œìš”? "
                        "ì²œì²œíˆ ìƒê°í•´ ë³´ì‹œê³ , ì¤€ë¹„ë˜ì‹œë©´ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”."
                    )
                    print(f"ğŸ’¬ ë´„ì´(ëŒ€ê¸°): {wait_msg}")
                    tts_bomi(wait_msg)
                    silent_rounds = 0
                continue

            # ë§ì´ ê°ì§€ë˜ë©´ ì¹´ìš´í„° ë¦¬ì…‹
            silent_rounds = 0

            # 3) STT (Whisper)
            text = stt_whisper(audio_int16)
            if not text:
                print("â— ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                continue

            # 4) ì¢…ë£Œ í‚¤ì›Œë“œ
            if is_end_command(text):
                bye_msg = (
                    "ì˜¤ëŠ˜ ëŒ€í™”ëŠ” ì—¬ê¸°ê¹Œì§€ í• ê²Œìš”. í•¨ê»˜ ì´ì•¼ê¸° ë‚˜ëˆ  ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                )
                print(f"ğŸ’¬ ë´„ì´: {bye_msg}")
                tts_bomi(bye_msg)
                break

            # 5) LLM ìƒë‹´
            reply = chat_with_bomi(text)

            # 6) ë´„ì´ TTSë¡œ ë°”ë¡œ ì½ì–´ì£¼ê¸°
            tts_bomi(reply)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Ctrl+Cë¡œ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break


if __name__ == "__main__":
    main()
