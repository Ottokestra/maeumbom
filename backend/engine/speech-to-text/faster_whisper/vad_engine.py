"""
ë§ˆìŒë´„ - Silero VAD ì—”ì§„
ìŒì„± í™œë™ ê°ì§€ (Voice Activity Detection)
"""

import torch
import numpy as np
from typing import Optional, Tuple
import time


class SileroVAD:
    """Silero VAD ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŒì„± í™œë™ ê°ì§€"""
    
    def __init__(
        self,
        threshold: float = 0.5,
        min_speech_duration_ms: int = 250,
        max_speech_duration_s: float = 30.0,
        min_silence_duration_ms: int = 2000,
        short_silence_duration_ms: int = 500,  # ì§§ì€ ì¹¨ë¬µ ê°ì§€ (ë¬¸ì¥ êµ¬ë¶„ìš©)
        speech_pad_ms: int = 300,
        sample_rate: int = 16000
    ):
        """
        Args:
            threshold: ìŒì„± ê°ì§€ ì„ê³„ê°’ (0.0 ~ 1.0)
            min_speech_duration_ms: ìµœì†Œ ë°œí™” ê¸¸ì´ (ms)
            max_speech_duration_s: ìµœëŒ€ ë°œí™” ê¸¸ì´ (ì´ˆ)
            min_silence_duration_ms: ë¬´ìŒ ê°ì§€ ì‹œê°„ (ms) - ë°œí™” ì¢…ë£Œ
            short_silence_duration_ms: ì§§ì€ ë¬´ìŒ ê°ì§€ ì‹œê°„ (ms) - ë¬¸ì¥ êµ¬ë¶„/í™•ì •
            speech_pad_ms: ë°œí™” ì•ë’¤ íŒ¨ë”© (ms)
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
        """
        self.threshold = threshold
        self.min_speech_duration_ms = min_speech_duration_ms
        self.max_speech_duration_s = max_speech_duration_s
        self.min_silence_duration_ms = min_silence_duration_ms
        self.short_silence_duration_ms = short_silence_duration_ms
        self.speech_pad_ms = speech_pad_ms
        self.sample_rate = sample_rate
        
        # ìƒ˜í”Œ ë‹¨ìœ„ë¡œ ë³€í™˜
        self.min_speech_samples = int(sample_rate * min_speech_duration_ms / 1000)
        self.max_speech_samples = int(sample_rate * max_speech_duration_s)
        self.min_silence_samples = int(sample_rate * min_silence_duration_ms / 1000)
        self.short_silence_samples = int(sample_rate * short_silence_duration_ms / 1000)
        self.speech_pad_samples = int(sample_rate * speech_pad_ms / 1000)
        
        # Silero VAD ëª¨ë¸ ë¡œë“œ
        print("ğŸ“¥ Silero VAD ëª¨ë¸ ë¡œë”© ì¤‘...")
        try:
            self.model, utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                force_reload=False,
                onnx=False
            )
            self.get_speech_timestamps = utils[0]
            print("âœ… Silero VAD ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Silero VAD ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
            
        # ìƒíƒœ
        self.is_speaking = False
        self.speech_start_sample = 0
        self.silence_start_sample = 0
        self.current_sample = 0
        self.speech_buffer = []
        self.last_was_speech = False  # ì´ì „ ì²­í¬ê°€ ìŒì„±ì´ì—ˆëŠ”ì§€ ì¶”ì 
        self.short_pause_triggered = False  # ì§§ì€ ì¹¨ë¬µ ì´ë¯¸ ê°ì§€ë¨
        
    def reset(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.is_speaking = False
        self.speech_start_sample = 0
        self.silence_start_sample = 0
        self.current_sample = 0
        self.speech_buffer = []
        self.last_was_speech = False
        self.short_pause_triggered = False
        
    def process_chunk(
        self,
        audio_chunk: np.ndarray
    ) -> Tuple[bool, Optional[np.ndarray], bool]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
        
        Args:
            audio_chunk: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array, float32)
            
        Returns:
            (ë°œí™” ì™„ë£Œ ì—¬ë¶€, ë°œí™” ì˜¤ë””ì˜¤ ë°ì´í„°, ì§§ì€ ì¹¨ë¬µ ê°ì§€ ì—¬ë¶€)
        """
        # Tensorë¡œ ë³€í™˜
        if len(audio_chunk) == 0:
            return False, None, False
            
        audio_tensor = torch.from_numpy(audio_chunk).float()
        
        # VAD í™•ë¥  ê³„ì‚°
        with torch.no_grad():
            speech_prob = self.model(audio_tensor, self.sample_rate).item()
        
        # ğŸ” VAD í™•ë¥  ë¡œê¹… (ìŒì„±ì´ ìˆì„ ë•Œë§Œ)
        if speech_prob > 0.3:  # ì„ê³„ê°’ë³´ë‹¤ ë‚®ì•„ë„ í™•ì¸
            print(f"[VAD PROB] speech_prob={speech_prob:.3f}, threshold={self.threshold:.3f}, is_speech={speech_prob >= self.threshold}", flush=True)
        
        is_short_pause = False  # ì§§ì€ ì¹¨ë¬µ ê°ì§€ í”Œë˜ê·¸
        current_is_speech = speech_prob >= self.threshold
        
        # ìŒì„± ê°ì§€
        if current_is_speech:
            if not self.is_speaking:
                # ë°œí™” ì‹œì‘
                print(f"[VAD] ğŸ¤ ë°œí™” ì‹œì‘ ê°ì§€! (prob={speech_prob:.3f})", flush=True)
                self.is_speaking = True
                self.speech_start_sample = self.current_sample
                self.speech_buffer = []
                self.silence_start_sample = self.current_sample
                self.short_pause_triggered = False
                
            # ë²„í¼ì— ì¶”ê°€
            self.speech_buffer.append(audio_chunk)
            
            # â­ ì´ì „ì— ë¬´ìŒì´ì—ˆë‹¤ê°€ ì§€ê¸ˆ ìŒì„±ì´ë©´ ì¹¨ë¬µ ì¢…ë£Œ
            if not self.last_was_speech:
                # ì¹¨ë¬µì—ì„œ ìŒì„±ìœ¼ë¡œ ì „í™˜ - ì¹¨ë¬µ ì‹œì‘ì  ë¦¬ì…‹
                self.silence_start_sample = self.current_sample
                # ì§§ì€ ì¹¨ë¬µ í”Œë˜ê·¸ë„ ë¦¬ì…‹ (ë‹¤ìŒ ì¹¨ë¬µì„ ìœ„í•´)
                self.short_pause_triggered = False
            
        else:
            # ë¬´ìŒ ê°ì§€
            if self.is_speaking:
                # â­ ìŒì„±ì—ì„œ ë¬´ìŒìœ¼ë¡œ ì „í™˜ë˜ëŠ” ìˆœê°„ - ì¹¨ë¬µ ì‹œì‘!
                if self.last_was_speech:
                    self.silence_start_sample = self.current_sample
                
                # ë²„í¼ì— ì¶”ê°€ (ë¬´ìŒë„ í¬í•¨)
                self.speech_buffer.append(audio_chunk)
                
                # ë¬´ìŒ ì§€ì† ì‹œê°„ í™•ì¸
                silence_duration = self.current_sample - self.silence_start_sample
                
                # â­ ì§§ì€ ì¹¨ë¬µ ê°ì§€ (ë¬¸ì¥ êµ¬ë¶„ìš©) - í•œ ë²ˆë§Œ!
                if not self.short_pause_triggered and silence_duration >= self.short_silence_samples:
                    is_short_pause = True
                    self.short_pause_triggered = True  # í”Œë˜ê·¸ ì„¤ì •
                    print(f"[VAD ë””ë²„ê·¸] ì§§ì€ ì¹¨ë¬µ ê°ì§€ë¨! ({silence_duration / self.sample_rate * 1000:.0f}ms)", flush=True)
                
                if silence_duration >= self.min_silence_samples:
                    # ë°œí™” ì¢…ë£Œ
                    speech_duration = self.current_sample - self.speech_start_sample
                    silence_ms = silence_duration / self.sample_rate * 1000
                    print(f"[VAD ë””ë²„ê·¸] ê¸´ ì¹¨ë¬µ ê°ì§€ ({silence_ms:.0f}ms) -> ë°œí™” ì¢…ë£Œ!", flush=True)
                    
                    if speech_duration >= self.min_speech_samples:
                        # ìœ íš¨í•œ ë°œí™”
                        speech_audio = np.concatenate(self.speech_buffer)
                        self.reset()
                        return True, speech_audio, False
                    else:
                        # ë„ˆë¬´ ì§§ì€ ë°œí™” - ë¬´ì‹œ
                        print(f"[VAD ë””ë²„ê·¸] ë°œí™”ê°€ ë„ˆë¬´ ì§§ì•„ ë¬´ì‹œë¨", flush=True)
                        self.reset()
                        
                elif (self.current_sample - self.speech_start_sample) >= self.max_speech_samples:
                    # ìµœëŒ€ ë°œí™” ê¸¸ì´ ì´ˆê³¼
                    speech_audio = np.concatenate(self.speech_buffer)
                    self.reset()
                    return True, speech_audio, False
        
        # ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.last_was_speech = current_is_speech
        self.current_sample += len(audio_chunk)
        return False, None, is_short_pause
        
    def get_speech_probability(self, audio_chunk: np.ndarray) -> float:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ì˜ ìŒì„± í™•ë¥  ê³„ì‚°
        
        Args:
            audio_chunk: ì˜¤ë””ì˜¤ ë°ì´í„°
            
        Returns:
            ìŒì„± í™•ë¥  (0.0 ~ 1.0)
        """
        if len(audio_chunk) == 0:
            return 0.0
            
        audio_tensor = torch.from_numpy(audio_chunk).float()
        
        with torch.no_grad():
            speech_prob = self.model(audio_tensor, self.sample_rate).item()
            
        return speech_prob
    
    def get_current_silence_duration_ms(self) -> float:
        """
        í˜„ì¬ ì¹¨ë¬µ ì§€ì† ì‹œê°„ ë°˜í™˜ (ms)
        
        Returns:
            ì¹¨ë¬µ ì§€ì† ì‹œê°„ (ë°€ë¦¬ì´ˆ)
        """
        if not self.is_speaking:
            return 0.0
        
        silence_duration_samples = self.current_sample - self.silence_start_sample
        return (silence_duration_samples / self.sample_rate) * 1000
    
    def has_short_pause(self) -> bool:
        """
        ì§§ì€ ì¹¨ë¬µ(ë¬¸ì¥ êµ¬ë¶„ìš©)ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
        
        Returns:
            ì§§ì€ ì¹¨ë¬µ ê°ì§€ ì—¬ë¶€
        """
        if not self.is_speaking:
            return False
        
        silence_duration = self.current_sample - self.silence_start_sample
        return silence_duration >= self.short_silence_samples
    
    def get_buffer_length(self) -> int:
        """
        í˜„ì¬ ë²„í¼ì— ì €ì¥ëœ ì˜¤ë””ì˜¤ ê¸¸ì´ ë°˜í™˜
        
        Returns:
            ë²„í¼ ì²­í¬ ê°œìˆ˜
        """
        return len(self.speech_buffer)