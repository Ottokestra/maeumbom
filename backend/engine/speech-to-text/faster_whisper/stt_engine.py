"""
ë§ˆìŒë´„ í”„ë¡œí† íƒ€ì… 2 - Silero VAD + Whisper.cpp
ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
"""

import sys
import yaml
import time
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from common.audio_handler import AudioHandler, AudioBuffer
from common.latency_tracker import LatencyTracker
from faster_whisper.vad_engine import SileroVAD
from faster_whisper.whisper_engine import WhisperSTT


class MaumBomSTT:
    """ë§ˆìŒë´„ í†µí•© STT ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë¡œë“œ
        print("ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë”© ì¤‘...")
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._init_components()
        
    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # ì˜¤ë””ì˜¤ í•¸ë“¤ëŸ¬
        audio_config = self.config['audio']
        self.audio_handler = AudioHandler(
            sample_rate=audio_config['sample_rate'],
            channels=audio_config['channels'],
            chunk_size=audio_config['chunk_size']
        )
        
        # ì˜¤ë””ì˜¤ ë²„í¼
        self.audio_buffer = AudioBuffer(
            max_duration=self.config['vad']['max_speech_duration_s'],
            sample_rate=audio_config['sample_rate']
        )
        
        # VAD ì—”ì§„
        vad_config = self.config['vad']
        self.vad = SileroVAD(
            threshold=vad_config['threshold'],
            min_speech_duration_ms=vad_config['min_speech_duration_ms'],
            max_speech_duration_s=vad_config['max_speech_duration_s'],
            min_silence_duration_ms=vad_config['min_silence_duration_ms'],
            short_silence_duration_ms=vad_config.get('short_silence_duration_ms', 500),
            speech_pad_ms=vad_config['speech_pad_ms'],
            sample_rate=audio_config['sample_rate']
        )
        
        # Whisper STT
        whisper_config = self.config['whisper']
        self.whisper = WhisperSTT(
            model_path=whisper_config['model_path'],
            language="ko",  # í•œêµ­ì–´ ê³ ì •
            n_threads=whisper_config['n_threads'],
            sample_rate=audio_config['sample_rate']
        )
        
        # ì§€ì—° ì‹œê°„ ì¶”ì ê¸°
        self.latency_tracker = LatencyTracker()
        
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print("\n" + "="*60)
        print("ğŸ¤ ë§ˆì´í¬ ì¤€ë¹„ ì™„ë£Œ. ë§ì”€í•´ì£¼ì„¸ìš”...")
        print("   (Ctrl+Cë¡œ ì¢…ë£Œ)")
        print("="*60 + "\n")
        
        try:
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            self.audio_handler.start_stream()
            
            # ë©”ì¸ ë£¨í”„
            is_currently_speaking = False
            is_processing = False  # ì²˜ë¦¬ ì¤‘ í”Œë˜ê·¸ ì¶”ê°€
            speech_buffer = []
            committed_text = ""  # í™•ì •ëœ í…ìŠ¤íŠ¸ (VAD ì§§ì€ ì¹¨ë¬µ ê°ì§€ ì‹œ í™•ì •)
            last_commit_buffer_length = 0  # ë§ˆì§€ë§‰ í™•ì • ì‹œì ì˜ ë²„í¼ ê¸¸ì´
            last_commit_time = time.time()  # ë§ˆì§€ë§‰ í™•ì • ì‹œê°„
            last_stt_time = time.time()
            stt_interval = 1.5  # 1.5ì´ˆë§ˆë‹¤ ì¤‘ê°„ STT ì‹¤í–‰
            commit_interval = 3.0  # 3ì´ˆë§ˆë‹¤ ê°•ì œ í™•ì •
            
            while True:
                # ì˜¤ë””ì˜¤ ì²­í¬ ì½ê¸°
                audio_bytes = self.audio_handler.read_chunk()
                if audio_bytes is None:
                    continue
                    
                # numpy ë°°ì—´ë¡œ ë³€í™˜
                audio_chunk = self.audio_handler.bytes_to_numpy(audio_bytes)
                
                # ì²˜ë¦¬ ì¤‘ì´ë©´ ì˜¤ë””ì˜¤ í ë¹„ìš°ê³  VAD ì²´í¬ ìƒëµ (ì¤‘ìš”!)
                if is_processing:
                    # ì˜¤ë””ì˜¤ íì— ìŒ“ì¸ ë°ì´í„° ë²„ë¦¬ê¸°
                    while not self.audio_handler.audio_queue.empty():
                        try:
                            self.audio_handler.audio_queue.get_nowait()
                        except:
                            break
                    continue
                
                # â­ VAD ì²˜ë¦¬ ë¨¼ì € ì‹¤í–‰ (ì¹¨ë¬µ ê°ì§€ ì—…ë°ì´íŠ¸)
                is_speech_end, speech_audio, is_short_pause = self.vad.process_chunk(audio_chunk)
                
                # VAD ìƒíƒœ í™•ì¸ (ë°œí™” ì¤‘ì¸ì§€)
                speech_prob = self.vad.get_speech_probability(audio_chunk)
                
                # ë°œí™” ì‹œì‘ ê°ì§€
                if speech_prob > self.vad.threshold and not is_currently_speaking:
                    is_currently_speaking = True
                    speech_buffer = []
                    committed_text = ""  # ìƒˆ ë°œí™” ì‹œì‘ ì‹œ í™•ì • í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    last_commit_buffer_length = 0
                    last_commit_time = time.time()  # í™•ì • ì‹œê°„ ì´ˆê¸°í™”
                    print("\nğŸ¤ [ë°œí™” ì‹œì‘] ë§ì”€í•˜ì„¸ìš”...", flush=True)
                    self.latency_tracker.mark_speech_start()
                
                # ë°œí™” ì¤‘ ì²˜ë¦¬
                if is_currently_speaking and not is_speech_end:
                    # ë²„í¼ì— ì¶”ê°€
                    speech_buffer.append(audio_chunk)
                    
                    # ì£¼ê¸°ì  VAD ìƒíƒœ ë¡œê·¸ ì œê±° (Log Flooding ë°©ì§€)
                    # ìƒíƒœ ë³€í™” ì‹œì—ë§Œ ë¡œê·¸ ì¶œë ¥ (ë°œí™” ì‹œì‘, ì§§ì€ ì¹¨ë¬µ, ê¸´ ì¹¨ë¬µ, ë°œí™” ì¢…ë£Œ)
                    
                    current_time = time.time()
                    should_commit = False
                    commit_reason = ""
                    
                    # â­ í™•ì • íŠ¸ë¦¬ê±° ì¡°ê±´ ì²´í¬
                    # 1. ì§§ì€ ì¹¨ë¬µ ê°ì§€ ì‹œ (ë²„í¼ì— ì¶©ë¶„í•œ ì˜¤ë””ì˜¤ê°€ ìˆì„ ë•Œë§Œ)
                    buffer_duration = sum(len(chunk) for chunk in speech_buffer) / self.audio_handler.sample_rate
                    if is_short_pause and buffer_duration >= 0.5:  # ìµœì†Œ 0.5ì´ˆ ì´ìƒ
                        should_commit = True
                        commit_reason = "ì§§ì€ ì¹¨ë¬µ ê°ì§€"
                    
                    # 2. ì‹œê°„ ê¸°ë°˜ ê°•ì œ í™•ì • (3ì´ˆë§ˆë‹¤, ë²„í¼ì— ì¶©ë¶„í•œ ì˜¤ë””ì˜¤ê°€ ìˆì„ ë•Œë§Œ)
                    elif current_time - last_commit_time >= commit_interval and buffer_duration >= 1.0:  # ìµœì†Œ 1ì´ˆ ì´ìƒ
                        should_commit = True
                        commit_reason = f"ì‹œê°„ ê²½ê³¼ ({commit_interval}ì´ˆ)"
                    
                    # â­ í™•ì • ì‹¤í–‰
                    if should_commit and len(speech_buffer) > last_commit_buffer_length:
                        buffer_length = len(speech_buffer)
                        total_audio_sec = sum(len(chunk) for chunk in speech_buffer) / self.audio_handler.sample_rate
                        new_audio_sec = sum(len(chunk) for chunk in speech_buffer[last_commit_buffer_length:]) / self.audio_handler.sample_rate
                        
                        # â­ ìµœì†Œ ì˜¤ë””ì˜¤ ê¸¸ì´ ì²´í¬ (ìì› ë‚­ë¹„ ë°©ì§€)
                        if new_audio_sec < 0.5:
                            print(f"[ë””ë²„ê·¸] ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŒ ({new_audio_sec:.1f}ì´ˆ < 0.5ì´ˆ) - í™•ì • ê±´ë„ˆëœ€", flush=True)
                            last_commit_time = current_time  # ë¬´í•œë£¨í”„ ë°©ì§€
                            continue
                        
                        print(f"\n[ë””ë²„ê·¸] {commit_reason} -> í™•ì • ì‹¤í–‰", flush=True)
                        print(f"[ë””ë²„ê·¸] ë²„í¼: ì „ì²´ {buffer_length}ì²­í¬ ({total_audio_sec:.1f}ì´ˆ), ìƒˆë¡œìš´ ë¶€ë¶„ {buffer_length - last_commit_buffer_length}ì²­í¬ ({new_audio_sec:.1f}ì´ˆ)", flush=True)
                        
                        try:
                            stt_start = time.time()
                            
                            # â­ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì²˜ë¦¬ (ë³‘ëª© í•´ê²°!)
                            if last_commit_buffer_length > 0:
                                # ì´ë¯¸ í™•ì •ëœ ë¶€ë¶„ì´ ìˆìŒ - ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì²˜ë¦¬
                                new_audio_chunks = speech_buffer[last_commit_buffer_length:]
                                new_audio = np.concatenate(new_audio_chunks)
                                print(f"[ë””ë²„ê·¸] ì¦ë¶„ í™•ì •: ìƒˆë¡œìš´ {len(new_audio_chunks)}ì²­í¬ë§Œ STT ì²˜ë¦¬...", flush=True)
                                # â­ initial_promptë¡œ ì´ì „ í™•ì • í…ìŠ¤íŠ¸ ì „ë‹¬ (ë¬¸ë§¥ ìœ ì§€)
                                transcript, quality = self.whisper.transcribe(
                                    new_audio, 
                                    callback=None,
                                    initial_prompt=committed_text[-100:] if committed_text else ""  # ë§ˆì§€ë§‰ 100ì
                                )
                            else:
                                # ì²« í™•ì • - ì „ì²´ ì²˜ë¦¬
                                buffer_audio = np.concatenate(speech_buffer)
                                print(f"[ë””ë²„ê·¸] ì²« í™•ì •: ì „ì²´ {len(speech_buffer)}ì²­í¬ STT ì²˜ë¦¬...", flush=True)
                                transcript, quality = self.whisper.transcribe(buffer_audio, callback=None)
                            
                            stt_time = (time.time() - stt_start) * 1000
                            
                            if quality in ["success", "medium"] and transcript:
                                # â­ í…ìŠ¤íŠ¸ ëˆ„ì  (ì´ì „ í™•ì • + ìƒˆë¡œìš´ í…ìŠ¤íŠ¸)
                                if committed_text:
                                    committed_text = committed_text + " " + transcript
                                else:
                                    committed_text = transcript
                                
                                last_commit_buffer_length = len(speech_buffer)
                                last_commit_time = current_time
                                print(f"âœ“ [í™•ì •] {committed_text} (ì²˜ë¦¬ì‹œê°„: {stt_time:.0f}ms)", flush=True)
                            elif quality == "low_quality" and transcript:
                                # â­ low_qualityë„ í™•ì •ìœ¼ë¡œ ì²˜ë¦¬ (ë¬´í•œë£¨í”„ ë°©ì§€)
                                if committed_text:
                                    committed_text = committed_text + " " + transcript
                                else:
                                    committed_text = transcript
                                
                                last_commit_buffer_length = len(speech_buffer)
                                last_commit_time = current_time
                                print(f"âš ï¸  [í™•ì •/í’ˆì§ˆë‚®ìŒ] {committed_text} (ì²˜ë¦¬ì‹œê°„: {stt_time:.0f}ms)", flush=True)
                            elif quality == "no_speech":
                                # ìŒì„±ì´ ì—†ëŠ” ê²½ìš° - í™•ì • ì‹œê°„ë§Œ ì—…ë°ì´íŠ¸í•˜ê³  ë²„í¼ëŠ” ìœ ì§€
                                print(f"[ë””ë²„ê·¸] ìŒì„± ì—†ìŒ - í™•ì • ê±´ë„ˆëœ€ (ë²„í¼ ìœ ì§€)", flush=True)
                                last_commit_time = current_time  # ì‹œê°„ë§Œ ì—…ë°ì´íŠ¸ (ë¬´í•œ ë°˜ë³µ ë°©ì§€)
                            else:
                                print(f"[ë””ë²„ê·¸] í™•ì • ì‹¤íŒ¨: í’ˆì§ˆ={quality}, í…ìŠ¤íŠ¸='{transcript}'", flush=True)
                                last_commit_time = current_time  # â­ ë¬´í•œë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ì‹œê°„ ì—…ë°ì´íŠ¸
                        except Exception as e:
                            print(f"[ë””ë²„ê·¸] í™•ì • ì˜¤ë¥˜: {e}", flush=True)
                            import traceback
                            traceback.print_exc()
                    
                    # ì¼ì • ì‹œê°„ë§ˆë‹¤ ì¤‘ê°„ STT ì‹¤í–‰ (ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ!)
                    if current_time - last_stt_time >= stt_interval:
                        if len(speech_buffer) > last_commit_buffer_length:
                            # â­ í™•ì •ëœ ì´í›„ì˜ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì²˜ë¦¬ (ë³‘ëª© í•´ê²°!)
                            if last_commit_buffer_length > 0:
                                # ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                                new_audio_chunks = speech_buffer[last_commit_buffer_length:]
                                if len(new_audio_chunks) > 0:
                                    new_audio = np.concatenate(new_audio_chunks)
                                    new_audio_sec = len(new_audio) / self.audio_handler.sample_rate
                                    
                                    # â­ ìµœì†Œ ì˜¤ë””ì˜¤ ê¸¸ì´ ì²´í¬ (0.5ì´ˆ)
                                    if new_audio_sec >= 0.5:
                                        print(f"\n[ë””ë²„ê·¸] ì¦ë¶„ STT: ìƒˆë¡œìš´ {len(new_audio_chunks)}ì²­í¬ ({new_audio_sec:.1f}ì´ˆ) ì²˜ë¦¬ ì¤‘...", end="", flush=True)
                                        stt_start = time.time()
                                        partial_text = self._process_partial_speech_incremental(new_audio, committed_text)
                                        stt_time = (time.time() - stt_start) * 1000
                                        
                                        if partial_text and committed_text:
                                            # í™•ì •ëœ í…ìŠ¤íŠ¸ + ìƒˆë¡œìš´ ë¶€ë¶„
                                            print(f"\rğŸ’¬ [ì‹¤ì‹œê°„] {committed_text} {partial_text} ({stt_time:.0f}ms)", end="", flush=True)
                                        elif partial_text:
                                            print(f"\rğŸ’¬ [ì‹¤ì‹œê°„] {partial_text} ({stt_time:.0f}ms)", end="", flush=True)
                            else:
                                # ì•„ì§ í™•ì •ëœ ê²ƒì´ ì—†ìœ¼ë©´ ì „ì²´ ì²˜ë¦¬
                                buffer_audio = np.concatenate(speech_buffer)
                                total_audio_sec = len(buffer_audio) / self.audio_handler.sample_rate
                                
                                # â­ ìµœì†Œ ì˜¤ë””ì˜¤ ê¸¸ì´ ì²´í¬ (0.5ì´ˆ)
                                if total_audio_sec >= 0.5:
                                    print(f"\n[ë””ë²„ê·¸] ì „ì²´ STT: {len(speech_buffer)}ì²­í¬ ({total_audio_sec:.1f}ì´ˆ) ì²˜ë¦¬ ì¤‘...", end="", flush=True)
                                    self._process_partial_speech(buffer_audio)
                            
                            last_stt_time = current_time
                
                if is_speech_end and speech_audio is not None:
                    print("\nğŸ”š [ë°œí™” ì¢…ë£Œ] ìµœì¢… ì²˜ë¦¬ ì¤‘...", flush=True)
                    is_currently_speaking = False
                    speech_buffer = []
                    is_processing = True  # ì²˜ë¦¬ ì‹œì‘
                    
                    try:
                        # VAD ìƒíƒœ ì™„ì „íˆ ë¦¬ì…‹
                        self.vad.reset()
                        
                        # ë°œí™” ì™„ë£Œ - ìµœì¢… ì²˜ë¦¬
                        self._process_speech(speech_audio)
                        
                    except Exception as e:
                        print(f"\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        import traceback
                        traceback.print_exc()
                        
                    finally:
                        # ë°˜ë“œì‹œ ì‹¤í–‰: ì²˜ë¦¬ ì™„ë£Œ í›„ ì˜¤ë””ì˜¤ í ë¹„ìš°ê¸°
                        try:
                            queue_cleared = 0
                            while not self.audio_handler.audio_queue.empty():
                                try:
                                    self.audio_handler.audio_queue.get_nowait()
                                    queue_cleared += 1
                                    if queue_cleared > 1000:  # ë¬´í•œ ë£¨í”„ ë°©ì§€
                                        break
                                except:
                                    break
                        except Exception as e:
                            print(f"[ë””ë²„ê·¸] í ë¹„ìš°ê¸° ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
                        
                        # ë°˜ë“œì‹œ ì‹¤í–‰: VAD í•œ ë²ˆ ë” ë¦¬ì…‹ (í™•ì‹¤í•˜ê²Œ)
                        try:
                            self.vad.reset()
                        except Exception as e:
                            print(f"[ë””ë²„ê·¸] VAD ë¦¬ì…‹ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
                        
                        # ë°˜ë“œì‹œ ì‹¤í–‰: ì²˜ë¦¬ í”Œë˜ê·¸ í•´ì œ
                        is_processing = False
                        is_currently_speaking = False  # í˜¹ì‹œ ëª¨ë¥¼ ìƒíƒœ ì´ˆê¸°í™”
                        speech_buffer = []
                        committed_text = ""  # í™•ì • í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                        last_commit_buffer_length = 0  # í™•ì • ë²„í¼ ê¸¸ì´ ì´ˆê¸°í™”
                        last_commit_time = time.time()  # í™•ì • ì‹œê°„ ì´ˆê¸°í™”
                        
                        print("\n" + "="*60)
                        print("ğŸ¤ ë‹¤ìŒ ë°œí™”ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
                        print("="*60 + "\n")
                    
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            self.audio_handler.close()
    
    def _process_partial_speech(self, audio: np.ndarray):
        """
        ë°œí™” ì¤‘ ë¶€ë¶„ ìŒì„± ì²˜ë¦¬ (ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼) - ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬
        
        Args:
            audio: ë¶€ë¶„ ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        try:
            # ê°„ë‹¨í•œ STTë§Œ ì‹¤í–‰ (í›„ì²˜ë¦¬ ì—†ìŒ)
            transcript, quality = self.whisper.transcribe(audio, callback=None)
            # í’ˆì§ˆì´ ì¢‹ì„ ë•Œë§Œ ì¶œë ¥
            if transcript and quality == "success":
                print(f"\rğŸ’¬ [ì‹¤ì‹œê°„] {transcript}", end="", flush=True)
        except Exception as e:
            # ì¤‘ê°„ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
            pass
    
    def _process_partial_speech_incremental(self, audio: np.ndarray, context: str = "") -> str:
        """
        â­ ë°œí™” ì¤‘ ë¶€ë¶„ ìŒì„± ì²˜ë¦¬ (ì¦ë¶„ ë°©ì‹) - ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì²˜ë¦¬
        
        Args:
            audio: ìƒˆë¡œìš´ ë¶€ë¶„ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°
            context: ì´ì „ í™•ì • í…ìŠ¤íŠ¸ (ë¬¸ë§¥ ìœ ì§€ìš©)
            
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸ (í™•ì • ì´í›„ì˜ ìƒˆë¡œìš´ ë¶€ë¶„)
        """
        try:
            # â­ initial_promptë¡œ ë¬¸ë§¥ ì „ë‹¬
            transcript, quality = self.whisper.transcribe(
                audio, 
                callback=None,
                initial_prompt=context[-100:] if context else ""  # ë§ˆì§€ë§‰ 100ì
            )
            # í’ˆì§ˆì´ ì¢‹ì„ ë•Œë§Œ ë°˜í™˜
            if transcript and quality in ["success", "medium"]:
                return transcript
        except Exception as e:
            # ì¤‘ê°„ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
            pass
        return ""
            
    def _process_speech(self, audio: np.ndarray):
        """
        ë°œí™” ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        
        Args:
            audio: ë°œí™” ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        try:
            # ë°œí™” ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
            self.latency_tracker.mark_speech_end()
            
            # 1. STT ì²˜ë¦¬
            print("\nğŸ”„ ìŒì„± ì¸ì‹ ì¤‘...")
            
            # ë¶€ë¶„ í…ìŠ¤íŠ¸ ì½œë°±
            last_text = [""]
            def partial_callback(text):
                # ë§ˆì§€ë§‰ í…ìŠ¤íŠ¸ì™€ ë‹¤ë¥¼ ë•Œë§Œ ì¶œë ¥ (ì¤‘ë³µ ë°©ì§€)
                if text != last_text[0]:
                    print(f"\r[ì‹¤ì‹œê°„] {text}", end="", flush=True)
                    last_text[0] = text
                    self.latency_tracker.mark_partial_text()
            
            # Whisper STT (í’ˆì§ˆ ê²€ì‚¬ í¬í•¨)
            stt_start = time.time()
            transcript, quality = self.whisper.transcribe(audio, callback=partial_callback)
            stt_time = (time.time() - stt_start) * 1000
            
            self.latency_tracker.mark_stt_complete()
            
            # í’ˆì§ˆì— ë”°ë¥¸ ì²˜ë¦¬
            if quality == "no_speech":
                print(f"\nâš ï¸  [ìŒì„± ë¯¸ê°ì§€] ë§ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print(f"   (ì²˜ë¦¬ ì‹œê°„: {stt_time:.0f}ms)")
                self.latency_tracker.print_summary()
                return  # ì²˜ë¦¬ ì¤‘ë‹¨
                
            elif quality == "low_quality":
                print(f"\nâš ï¸  [ì¸ì‹ ë¶ˆê°€] ì†ŒìŒì´ ì‹¬í•´ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(f"   ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{transcript}'")
                print(f"   (ì²˜ë¦¬ ì‹œê°„: {stt_time:.0f}ms)")
                print("\nğŸ’¡ ì¡°ìš©í•œ ê³³ì—ì„œ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")
                self.latency_tracker.print_summary()
                return  # ì²˜ë¦¬ ì¤‘ë‹¨
            
            # í’ˆì§ˆì— ë”°ë¥¸ ì¶œë ¥
            if quality == "medium":
                print(f"\nâš ï¸  [STT ì™„ë£Œ] {transcript} (í’ˆì§ˆ: ë³´í†µ)")
                print(f"   (ì²˜ë¦¬ ì‹œê°„: {stt_time:.0f}ms)")
            else:
                print(f"\nâœ… [STT ì™„ë£Œ] {transcript}")
                print(f"   (ì²˜ë¦¬ ì‹œê°„: {stt_time:.0f}ms)")
            
            # 2. ì§€ì—° ì‹œê°„ ìš”ì•½
            self.latency_tracker.print_summary()
            
        except Exception as e:
            print(f"\nâŒ _process_speech ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸŒ¸ ë§ˆìŒë´„(MaumBom) STT ì—”ì§„")
    print("   Silero VAD + Faster-Whisper")
    print("="*60)
    print()
    
    # ì„¤ì • íŒŒì¼ í™•ì¸
    config_path = Path(__file__).parent / "config.yaml"
    if not config_path.exists():
        print("âŒ config.yaml íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
        
    # ì‹œìŠ¤í…œ ìƒì„± ë° ì‹¤í–‰
    try:
        system = MaumBomSTT(str(config_path))
        system.run()
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

