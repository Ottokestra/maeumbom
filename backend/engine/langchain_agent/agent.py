"""
ë§ˆìŒë´„ - LangChain Agent v1.0

STT â†’ ê°ì • ë¶„ì„ â†’ GPT-4o-mini ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ í”Œë¡œìš°ë¥¼ orchestrationí•˜ëŠ” Agent
"""
import os
import sys
import logging
from pathlib import Path
from typing import Any, Optional
from datetime import datetime
import uuid

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
ENABLE_DEBUG_LOGS = os.getenv("LANGCHAIN_DEBUG", "false").lower() == "true"

if ENABLE_DEBUG_LOGS:
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)

# ì–´ëŒ‘í„° imports
try:
    from .adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend
    from .adapters.memory_adapter import should_store_memory, add_memory, get_memories_for_prompt
    from .conversation_vectorstore import add_message_to_rag, get_rag_context_for_prompt
except ImportError:
    from adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend
    from adapters.memory_adapter import should_store_memory, add_memory, get_memories_for_prompt
    from conversation_vectorstore import add_message_to_rag, get_rag_context_for_prompt


# ============================================================================
# 1. In-Memory Conversation Store
# ============================================================================

class InMemoryConversationStore:
    """
    ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    v1.1: ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ë° íƒ€ì„ì•„ì›ƒ ê¸°ëŠ¥ ì¶”ê°€
    
    ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ì„¸ì…˜ ìˆ˜ ë° ë©”ì‹œì§€ ìˆ˜ ì œí•œì„ ì ìš©.
    """
    
    def __init__(self, max_sessions: int = 100, max_messages_per_session: int = 50, session_timeout_minutes: int = 60):
        """
        ì´ˆê¸°í™”
        
        Args:
            max_sessions: ìµœëŒ€ ì„¸ì…˜ ìˆ˜ (ê¸°ë³¸ê°’: 100)
            max_messages_per_session: ì„¸ì…˜ë‹¹ ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: 50)
            session_timeout_minutes: ì„¸ì…˜ ë§Œë£Œ ì‹œê°„ (ë¶„) (ê¸°ë³¸ê°’: 60)
        """
        # session_id -> list[dict] í˜•íƒœë¡œ íˆìŠ¤í† ë¦¬ ë³´ê´€
        self._store: dict[str, list[dict]] = {}
        # session_id -> dict í˜•íƒœë¡œ ë©”íƒ€ë°ì´í„° ë³´ê´€
        self._session_metadata: dict[str, dict] = {}
        self._speaker_profiles: dict[str, dict] = {}
        
        self.max_sessions = max_sessions
        self.max_messages_per_session = max_messages_per_session
        self.session_timeout_minutes = session_timeout_minutes
        
    def _init_session_metadata(self, session_id: str):
        """ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”"""
        self._session_metadata[session_id] = {
            "created_at": datetime.now().isoformat(),
            "last_activity_at": datetime.now().isoformat(),
            "message_count": 0,
            "status": "active"
        }

    def _update_session_activity(self, session_id: str):
        """ì„¸ì…˜ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        if session_id in self._session_metadata:
            self._session_metadata[session_id]["last_activity_at"] = datetime.now().isoformat()
            self._session_metadata[session_id]["message_count"] = len(self._store.get(session_id, []))

    def _check_session_timeout(self, session_id: str) -> bool:
        """ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ í™•ì¸"""
        if session_id not in self._session_metadata:
            return False
            
        try:
            last_activity = datetime.fromisoformat(self._session_metadata[session_id]["last_activity_at"])
            elapsed = datetime.now() - last_activity
            if elapsed.total_seconds() > self.session_timeout_minutes * 60:
                return True
        except Exception as e:
            logger.error(f"ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return False

    def add_message(self, session_id: str, role: str, content: str, metadata: Optional[dict] = None):
        """
        ë©”ì‹œì§€ ì¶”ê°€
        
        Args:
            session_id: ì„¸ì…˜ ID
            role: ì—­í•  ("user" ë˜ëŠ” "assistant")
            content: ë©”ì‹œì§€ ë‚´ìš©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        """
        # ì„¸ì…˜ ì´ˆê¸°í™” ë° ë©”íƒ€ë°ì´í„° ì„¤ì •
        if session_id not in self._store:
            self._store[session_id] = []
            self._init_session_metadata(session_id)
        
        # íƒ€ì„ì•„ì›ƒ ì²´í¬
        if self._check_session_timeout(session_id):
            logger.info(f"â³ ì„¸ì…˜ {session_id} ë§Œë£Œë¨ (ë§ˆì§€ë§‰ í™œë™ í›„ {self.session_timeout_minutes}ë¶„ ê²½ê³¼).")
            # ë§Œë£Œëœ ì„¸ì…˜ ì²˜ë¦¬ ì •ì±…:
            # 1. ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³  ê³„ì† ì‚¬ìš© (í˜„ì¬ ë°©ì‹)
            # 2. ì•„ì¹´ì´ë¸Œ í›„ ìƒˆ ì„¸ì…˜ ì‹œì‘ (í–¥í›„ êµ¬í˜„)
            self._session_metadata[session_id]["status"] = "expired"
        
        # ì„¸ì…˜ ìˆ˜ ì œí•œ (LRU ë°©ì‹)
        if len(self._store) > self.max_sessions:
            # ê°€ì¥ ì˜¤ë˜ëœ í™œë™ ì„¸ì…˜ ì°¾ê¸°
            oldest_session = min(
                self._session_metadata.items(),
                key=lambda x: x[1]['last_activity_at']
            )[0]
            if oldest_session != session_id: # í˜„ì¬ ì„¸ì…˜ì€ ì‚­ì œí•˜ì§€ ì•ŠìŒ
                del self._store[oldest_session]
                del self._session_metadata[oldest_session]
                logger.warning(f"ğŸ§¹ ì„¸ì…˜ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°: {oldest_session}")
        
        # ë©”ì‹œì§€ ìˆ˜ ì œí•œ (FIFO)
        if len(self._store[session_id]) >= self.max_messages_per_session:
            self._store[session_id].pop(0)
            logger.warning(f"ğŸ§¹ ë©”ì‹œì§€ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° (ì„¸ì…˜: {session_id})")
        
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        }
        
        if metadata:
            message["metadata"] = metadata
            
        self._store[session_id].append(message)
        self._update_session_activity(session_id)
        
    def get_history(self, session_id: str, limit: Optional[int] = None) -> list[dict]:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        Args:
            session_id: ì„¸ì…˜ ID
            limit: ìµœê·¼ Nê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒ)
            
        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        history = self._store.get(session_id, [])
        
        # í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸ (ì¡°íšŒë„ í™œë™ìœ¼ë¡œ ê°„ì£¼í• ì§€ ì—¬ë¶€ëŠ” ì •ì±…ì— ë”°ë¦„, ì—¬ê¸°ì„œëŠ” ì—…ë°ì´íŠ¸ ì•ˆ í•¨)
        
        if limit:
            return history[-limit:]
        return history
        
    def get_session_metadata(self, session_id: str) -> Optional[dict]:
        """ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        return self._session_metadata.get(session_id)
        
    def clear_session(self, session_id: str):
        """
        íŠ¹ì • ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ ì‚­ì œ
        
        Args:
            session_id: ì„¸ì…˜ ID
        """
        if session_id in self._store:
            del self._store[session_id]
        if session_id in self._session_metadata:
            del self._session_metadata[session_id]

    def add_speaker_profile(self, speaker_id: str, embedding: Any, quality: str, session_id: Optional[str] = None):
        """í™”ì í”„ë¡œí•„ ì¶”ê°€"""
        self._speaker_profiles[speaker_id] = {
            "embedding": embedding,
            "quality": quality,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "session_id": session_id
        }

    def update_speaker_embedding(self, speaker_id: str, new_embedding: Any, quality: str):
        """í™”ì ì„ë² ë”© ì—…ë°ì´íŠ¸"""
        if speaker_id in self._speaker_profiles:
            self._speaker_profiles[speaker_id]["embedding"] = new_embedding
            self._speaker_profiles[speaker_id]["quality"] = quality
            self._speaker_profiles[speaker_id]["updated_at"] = datetime.now().isoformat()

    def get_all_speaker_ids(self) -> list[str]:
        """ë“±ë¡ëœ ëª¨ë“  í™”ì ID ë°˜í™˜"""
        return list(self._speaker_profiles.keys())


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_conversation_store = InMemoryConversationStore()


def get_conversation_store() -> InMemoryConversationStore:
    """
    ì „ì—­ ëŒ€í™” ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        InMemoryConversationStore ì¸ìŠ¤í„´ìŠ¤
    """
    return _conversation_store


def get_all_sessions() -> dict[str, Any]:
    """
    ëª¨ë“  ì„¸ì…˜ ì •ë³´ ë°˜í™˜
    
    Returns:
        ì„¸ì…˜ë³„ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ì •ë³´
    """
    store = get_conversation_store()
    sessions_info = {}
    
    # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ì„¸ì…˜ ìš°ì„  ì¡°íšŒ
    for session_id, metadata in store._session_metadata.items():
        sessions_info[session_id] = metadata.copy()
        # ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€
        history = store.get_history(session_id, limit=1)
        if history:
            last_msg = history[-1]
            sessions_info[session_id]["last_message_preview"] = (
                last_msg.get("content", "")[:50] + "..." 
                if len(last_msg.get("content", "")) > 50 
                else last_msg.get("content", "")
            )
            
    # ë©”íƒ€ë°ì´í„°ì—ëŠ” ì—†ì§€ë§Œ storeì—ëŠ” ìˆëŠ” ì„¸ì…˜ (í•˜ìœ„ í˜¸í™˜ì„±)
    for session_id, messages in store._store.items():
        if session_id not in sessions_info and messages:
            sessions_info[session_id] = {
                "created_at": messages[0].get("timestamp"),
                "last_activity_at": messages[-1].get("timestamp"),
                "message_count": len(messages),
                "status": "active",
                "last_message_preview": messages[-1].get("content", "")[:50] + "..."
            }
    
    return sessions_info


# ============================================================================
# 2. Tool Router
# ============================================================================

def route_tools(user_text: str) -> dict[str, Any]:
    """
    ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ Tool ì‹¤í–‰
    
    ToolRouterë¥¼ í•¨ìˆ˜ë¡œ ë‹¨ìˆœí™” (ìƒíƒœê°€ ì—†ìœ¼ë¯€ë¡œ í´ë˜ìŠ¤ ë¶ˆí•„ìš”)
    v1.1: emotion-analysis ì‹¤í–‰ í›„ routine-recommend ìë™ ì‹¤í–‰ (need_routine_recommend=Trueì¼ ë•Œ)
    í–¥í›„: health_advisor ë“± ì¶”ê°€ ê°€ëŠ¥
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        Tool ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
            - routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
            - used_tools: ì‚¬ìš©ëœ ë„êµ¬ ëª©ë¡
    """
    # 1. emotion-analysis ì‹¤í–‰
    emotion_result = run_emotion_analysis(user_text)
    
    used_tools = ["emotion_analysis"]
    routine_result = None
    
    # 2. routine-recommend ì‹¤í–‰ (ê°ì • ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    try:
        # service_signalsì—ì„œ need_routine_recommend í™•ì¸
        service_signals = emotion_result.get("service_signals", {})
        need_routine = service_signals.get("need_routine_recommend", False)
        
        if need_routine:
            logger.debug("ğŸ”„ ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•©ë‹ˆë‹¤. routine-recommend ì‹¤í–‰ ì¤‘...")
            routine_result = run_routine_recommend(emotion_result)
            used_tools.append("routine_recommend")
            logger.info(f"âœ… ë£¨í‹´ ì¶”ì²œ ì™„ë£Œ: {len(routine_result)}ê°œ")
        else:
            logger.debug("â„¹ï¸  ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.warning(f"âš ï¸  ë£¨í‹´ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        # graceful degradation: ë£¨í‹´ ì¶”ì²œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    return {
        "emotion_result": emotion_result,
        "routine_result": routine_result,
        "used_tools": used_tools,
    }


# ============================================================================
# 3. LLM í˜¸ì¶œ (GPT-4o-mini)
# ============================================================================

# LLM ì²´ì¸ ìºì‹œ (ë§¤ë²ˆ ì¬ìƒì„± ë°©ì§€ - ì„±ëŠ¥ ìµœì í™”)
_llm_chain_cache = None


def create_llm_chain():
    """
    LLM ì²´ì¸ ìƒì„±
    
    LangChainì„ Lazy Importí•˜ì—¬ ëª¨ë“ˆ ë¡œë”© ì‹œê°„ ë‹¨ì¶• ë° ë©”ëª¨ë¦¬ ìµœì í™”
    
    Returns:
        LangChainì˜ LLM ì²´ì¸
    """
    # LangChain Lazy Import (í•„ìš” ì‹œì ì—ë§Œ ë¡œë“œ)
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.debug(f"LLM ì²´ì¸ ìƒì„± ì¤‘... (ëª¨ë¸: {model_name})")
    
    # ChatOpenAI ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.7,
        api_key=api_key
    )
    
    # System Prompt ì •ì˜
    system_prompt = """
ë„ˆëŠ” ê°ì • ê³µê°ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ í•˜ë£¨ë¥¼ ë”°ëœ»í•˜ê²Œ ëŒë´ì£¼ëŠ” ì¼€ì–´ AI ì¹œêµ¬ "AI ë´„ì´"ì´ë‹¤.

[ì •ì²´ì„±]
- ì „ë¬¸ ìƒë‹´ì‚¬ê°€ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ë§ˆìŒì„ í¸í•˜ê²Œ ë“¤ì–´ì£¼ëŠ” ì¼ìƒ ì† ë”°ëœ»í•œ ì¹œêµ¬.
- ì£¼ìš” íƒ€ê²Ÿì€ 'ê°±ë…„ê¸° ì—¬ì„±'ì´ë¯€ë¡œ ì‹ ì²´Â·ê°ì • ë³€í™”(ì—´ê°, ë¶ˆë©´, ê°ì • ê¸°ë³µ ë“±)ì— ì¹œìˆ™í•˜ê²Œ ë°˜ì‘í•´ì•¼ í•¨.
- ì§„ë‹¨Â·ì¹˜ë£Œ ì¡°ì–¸ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.

[ëŒ€í™” ëª©ì ]
- ë¶ˆì•ˆÂ·í˜¼ë€Â·ë¯¼ë§í•¨ ë“± ë³µí•©ì ì¸ ê°ì •ì„ ì¸ì •í•´ì£¼ê³ , í•„ìš”í•  ê²½ìš° ê°€ë²¼ìš´ ì•ˆì‹¬ê³¼ ì¼ìƒ ì† ì‘ì€ ë£¨í‹´ì„ ì œì•ˆí•œë‹¤.
- ì‚¬ìš©ìì˜ ê¸°ë¶„ì„ ì¡°ê¸ˆì´ë¼ë„ í¸ì•ˆí•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ë° ì§‘ì¤‘í•œë‹¤.
- ì‚¬ìš©ìê°€ ë°”ë¡œ ì†”ë£¨ì…˜ì„ ì›í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, ë¨¼ì € ìƒí™©ì„ ê°€ë³ê²Œ ë¬¼ì–´ë³´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ê²ƒì´ ìš°ì„ ì´ë‹¤.
- ì´í›„ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•´ ê³µê°Â·ì•ˆì •Â·ê²©ë ¤ë¥¼ ì „ë‹¬í•œë‹¤.

[ê¸°ë³¸ ë§íˆ¬ ê·œì¹™]
- ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‚¬ìš©.
- ì „ì²´ í†¤: ë¶€ë“œëŸ½ê³  ë”°ëœ»í•˜ë©° ë¶€ë‹´ ì—†ëŠ” ì¹œêµ¬ ê°™ì€ ëŒ€í™”.
- 1) ìƒí™© ê°€ë²¼ìš´ íƒìƒ‰ â†’ 2) ê°ì • ê³µê° â†’ 3) ë¶€ë“œëŸ¬ìš´ ê²©ë ¤ ìˆœì„œ.
- ê³µê° â†’ ê°ì • ì´í•´ â†’ ê°€ë²¼ìš´ ê²©ë ¤ ë˜ëŠ” ì„ íƒí˜• ì œì•ˆ ìˆœì„œ.
- ë¶„ì„ì  ì¡°ì–¸, ìœ„í—˜ í‘œí˜„, ê°•ìš” ê¸ˆì§€.
- ì¡´ëŒ“ë§/ë°˜ë§ì€ ì‚¬ìš©ìì˜ ë§íˆ¬ì— ìë™ ë§ì¶¤.
- ì „ì²´ ë¬¸ì¥ì€ 1~3ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ.

[ìƒí™© íƒìƒ‰ ê·œì¹™]
- ì‚¬ìš©ìì˜ ë°œí™”ê°€ ë§‰ì—°í•˜ê±°ë‚˜ ë‹¨í¸ì ì¼ ë•ŒëŠ” ë°”ë¡œ ìœ„ë¡œí•˜ì§€ ë§ê³ ,
  "ì–´ë–¤ ìƒí™©ì¸ì§€ ì¡°ê¸ˆ ë” ë“¤ì–´ë³´ê³  ì‹¶ì–´" ê°™ì€ ë¶€ë“œëŸ¬ìš´ ì§ˆë¬¸ 1ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € íƒìƒ‰ ê°€ëŠ¥.
- ë‹¨, ì‚¬ìš©ìì˜ ë°œí™”ê°€ ê°ì •ì ìœ¼ë¡œ ë§¤ìš° ëª…í™•í•˜ê³  ì´ë¯¸ ê³ í†µì„ í‘œí˜„í•˜ëŠ” ê²½ìš°ì—ëŠ”
  ì§ˆë¬¸ë³´ë‹¤ëŠ” ë°”ë¡œ ê°ì • ê³µê° ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ë„ ëœë‹¤.
- íƒìƒ‰ ì§ˆë¬¸ì€ ìµœëŒ€ 1ë¬¸ì¥, ì§§ê³  ë¶€ë‹´ ì—†ê²Œ.
ì˜ˆ)  
- "ê·¸ë•Œ ì–´ë–¤ ìƒí™©ì´ì—ˆëŠ”ì§€ ì¡°ê¸ˆ ë” ì´ì•¼ê¸°í•´ì¤„ë˜?"  
- "í˜¹ì‹œ ì–¸ì œë¶€í„° ê·¸ëŸ° ëŠë‚Œì´ ë“¤ì—ˆì–´?"  
- "ì¡°ê¸ˆë§Œ ë” ë§í•´ì£¼ë©´ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„."

[ê°±ë…„ê¸° íŠ¹í™” ê³µê° ê·œì¹™]
- ê°±ë…„ê¸°ì¸ ê±¸ í™•ì¸í•˜ì§€ë§Œ, ì‚¬ìš©ìì—ê²Œ ê°±ë…„ê¸°ë¼ëŠ”ê±¸ í‹°ë‚´ì§€ ì•Šë„ë¡ ë‹µë³€í•œë‹¤.
- ì‹ ì²´ ë°˜ì‘(ì—´ê°, ì•ˆë©´í™ì¡°, í”¼ê³¤í•¨, ê°‘ì‘ìŠ¤ëŸ¬ìš´ ê¸°ë¶„ ë³€í™”)ì— ë¯¼ê°í•˜ê²Œ ê³µê°í•´ì¤€ë‹¤.
- "ë‚˜ë§Œ ì´ëŸ°ê°€?"ë¼ëŠ” ê±±ì •ì— ìì—°ìŠ¤ëŸ½ê²Œ ì•ˆì‹¬ì„ ì¤€ë‹¤.
- ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ "ê´œì°®ë‹¤ë©´â€¦", "ë„ì›€ì´ ë  ìˆ˜ë„ ìˆì–´" ê°™ì€ ì„ íƒí˜• ì œì•ˆì„ í™œìš©í•œë‹¤.
- ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œë¥¼ íƒ“í•˜ì§€ ì•Šë„ë¡ ë•ëŠ”ë‹¤.

[ê°ì • ê¸°ë°˜ ë‹µë³€ ì •ì±…]
- positive: í•¨ê»˜ ê¸°ë»í•˜ë©° ë”°ëœ»í•˜ê²Œ ë°˜ì‘.
- neutral: í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ê¸°.
- negative: ê°ì •ì„ ì¸ì •í•˜ê³ , ë¶ˆì•ˆÂ·í˜¼ë€ì„ ë‹¤ë…ì´ëŠ” ë§íˆ¬.
- primary emotion, secondary emotionsë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•˜ë˜ ì§ì ‘ ë‚˜ì—´í•˜ì§€ ì•ŠëŠ”ë‹¤.
- risk_levelì´ ë†’ì„ ê²½ìš°:
  - "ìœ„í—˜í•˜ë‹¤" ê°™ì€ ë‹¨ì–´ëŠ” ê¸ˆì§€.
  - ë¶€ë‹´ ì—†ëŠ” ë„ì›€ ê°€ëŠ¥ì„±ë§Œ ì€ê·¼íˆ ì—´ì–´ë‘”ë‹¤.
  - ì „ì²´ í†¤ì€ ë”ìš± ì•ˆì •ì ì´ê³  í¬ê·¼í•˜ê²Œ.

[ë£¨í‹´ ì •ë³´ í™œìš© ê·œì¹™]
- routine_suggestionì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ 1ë¬¸ì¥ ì •ë„ë¡œ ì œì•ˆ.
- ê°•ìš”í•˜ì§€ ì•Šê³  "í•´ë³¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„" ì •ë„ë¡œ ì™„ë§Œí•˜ê²Œ ì œì‹œ.

[ìŒì„± ì…ë ¥ì˜ ê²½ìš°]
- ë³„ë„ ì•ˆë‚´ ì—†ì´ í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬.
- ìŒì„± ê°ì • ì‹ í˜¸(ì†ë„/í†¤ ë“±)ê°€ ì œê³µë˜ë©´, í…ìŠ¤íŠ¸ ê°ì •ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì‘ë‹µ.

[ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© ê·œì¹™]
- ì´ì „ ëŒ€í™” ë§¥ë½ì´ ì œê³µë˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ê¸°ì–µí•˜ê³  ë°˜ì˜í•œë‹¤.
- ì‚¬ìš©ìê°€ ì´ì „ì— ì–¸ê¸‰í•œ ê°ì •ì´ë‚˜ ìƒí™©ì„ ê¸°ì–µí•˜ê³  ìˆëŠ” ë“¯í•œ ë°˜ì‘ì„ ë³´ì¸ë‹¤.
- ë‹¨, "ì§€ë‚œë²ˆì— ë§ì”€í•˜ì…¨ë“¯ì´" ê°™ì€ ëª…ì‹œì  í‘œí˜„ì€ í”¼í•œë‹¤.
- ë°˜ë³µë˜ëŠ” íŒ¨í„´ì´ë‚˜ ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì§€í•˜ì—¬ ì–¸ê¸‰í•  ìˆ˜ ìˆë‹¤.
- ëŒ€í™”ê°€ ì²˜ìŒì¸ ê²½ìš° íˆìŠ¤í† ë¦¬ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ì…ë ¥ì—ë§Œ ì§‘ì¤‘í•œë‹¤.

ë‹µë³€ í˜•ì‹:
1) ì‚¬ìš©ì ê°ì • ì¸ì •
2) ê°ì •ì„ ë°›ì•„ì£¼ëŠ” ê³µê° í‘œí˜„
3) í•„ìš” ì‹œ ê°€ë²¼ìš´ ê²©ë ¤ ë˜ëŠ” ë¶€ë“œëŸ¬ìš´ ì œì•ˆ
4) ë¬¸ì¥ 1~3ê°œ
"""
    
    # User Prompt í…œí”Œë¦¿
    user_prompt_template = """
{memory_context}

{rag_context}

{conversation_history}

ì‚¬ìš©ì ì…ë ¥:
"{user_text}"

ê°ì • ë¶„ì„ ê²°ê³¼:
- ì „ì²´ ê°ì •: {sentiment_overall}
- ì£¼ìš” ê°ì •: {primary_emotion_name} 
  (ê°•ë„: {primary_emotion_intensity}/5, ì‹ ë¢°ë„: {primary_emotion_confidence})
- ì¶”ì²œ ì‘ë‹µ ìŠ¤íƒ€ì¼: {recommended_response_style}
- ìœ„í—˜ ìˆ˜ì¤€: {risk_level}

ë£¨í‹´ ì‹ í˜¸:
{routine_info}

ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë´„ì´ì˜ ë‹µë³€ì„ ë§Œë“¤ì–´ë¼:
- [ì¤‘ìš”] Memory Layerì™€ RAG Contextì— ìˆëŠ” ì‚¬ìš©ìì˜ ê³¼ê±° ì •ë³´ë‚˜ ê³ ë¯¼ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•˜ì—¬, "ê¸°ì–µí•˜ê³  ìˆë‹¤"ëŠ” ëŠë‚Œì„ ì¤€ë‹¤.
- ê°ì • ë¶„ì„(primary emotion ë° ë¶€ì • ê°ì • í¬í•¨)ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•œë‹¤.
- ì‚¬ìš©ìê°€ ëŠë‚€ ì‹ ì²´ì Â·ê°ì •ì  ë¶ˆí¸ì´ ê°±ë…„ê¸°ì  íŠ¹ì„±ê³¼ ì—°ê´€ë  ìˆ˜ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•´ì£¼ëŠ” í†¤ì„ ì‚¬ìš©í•œë‹¤.
- routine_suggestionì´ ìˆì„ ê²½ìš° ë§ˆì§€ë§‰ ë¬¸ì¥ì— ì„ íƒí˜•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œë‹¤.
- ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•˜ë˜, ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì „ì²´ ë‹µë³€ì€ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  í¬ê·¼í•˜ê²Œ ì‘ì„±í•œë‹¤.
"""
    
    # ChatPromptTemplate ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt_template)
    ])
    
    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | StrOutputParser()
    
    return chain


def get_llm_chain():
    """
    LLM ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
    
    ë§¤ë²ˆ ChatOpenAI ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ,
    í•œ ë²ˆ ìƒì„±ëœ ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Returns:
        ìºì‹œëœ LLM ì²´ì¸
    """
    global _llm_chain_cache
    if _llm_chain_cache is None:
        _llm_chain_cache = create_llm_chain()
    return _llm_chain_cache


def generate_llm_response(
    user_text: str, 
    emotion_result: EmotionResult, 
    routine_result: list[dict] | None = None,
    conversation_history: list[dict] | None = None,
    memory_context: str = "",
    rag_context: str = ""
) -> str:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
        routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ì„ íƒ)
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒ)
        memory_context: Memory Layer ì¡°íšŒ ê²°ê³¼ ë¬¸ìì—´ (ì„ íƒ)
        rag_context: RAG ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´ (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # LLM ì²´ì¸ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
    chain = get_llm_chain()
    
    # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    primary_emotion = emotion_result.get("primary_emotion", {})
    sentiment_overall = emotion_result.get("sentiment_overall", "neutral")
    recommended_response_style = emotion_result.get("recommended_response_style", [])
    risk_level = emotion_result.get("risk_level", "low")
    
    # ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    style_str = ", ".join(recommended_response_style) if recommended_response_style else "ê³µê°ì ì´ê³  ë”°ëœ»í•œ ë‹µë³€"
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
    history_text = ""
    if conversation_history and len(conversation_history) > 0:
        history_text = "ìµœê·¼ ëŒ€í™” ë§¥ë½:\n"
        for msg in conversation_history:
            role_name = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI ë´„ì´"
            content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
            history_text += f"- {role_name}: {content_preview}\n"
        history_text += "\n"
    
    # ë£¨í‹´ ì¶”ì²œ ì •ë³´ í¬ë§·íŒ…
    routine_info = ""
    routine_suggestion = ""
    if routine_result and len(routine_result) > 0:
        routine_info = "ì¶”ì²œ ë£¨í‹´:\n"
        for i, routine in enumerate(routine_result[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            routine_info += f"  {i}. {routine.get('title', 'N/A')}: {routine.get('reason', 'N/A')}\n"
        routine_suggestion = "ê°€ëŠ¥í•˜ë‹¤ë©´ ì¶”ì²œ ë£¨í‹´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì¤˜. ë‹¨, ê°•ìš”í•˜ì§€ ë§ê³  ë¶€ë“œëŸ½ê²Œ ì œì•ˆí•˜ëŠ” í†¤ìœ¼ë¡œ."
    
    # LLM í˜¸ì¶œ
    response = chain.invoke({
        "conversation_history": history_text,
        "memory_context": memory_context,
        "rag_context": rag_context,
        "user_text": user_text,
        "sentiment_overall": sentiment_overall,
        "primary_emotion_name": primary_emotion.get("name_ko", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "primary_emotion_intensity": primary_emotion.get("intensity", 3),
        "primary_emotion_confidence": primary_emotion.get("confidence", 0.7),
        "recommended_response_style": style_str,
        "risk_level": risk_level,
        "routine_info": routine_info,
        "routine_suggestion": routine_suggestion
    })
    
    return response


# ============================================================================
# 4. ë©”ì¸ Agent í•¨ìˆ˜ë“¤
# ============================================================================

def run_ai_bomi_from_text(
    user_text: str, 
    session_id: str = "default",
    stt_quality: str = "success",
    speaker_id: Optional[str] = None
) -> dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ ì…ë ¥ ê¸°ë°˜ AI ë´„ì´ ì‹¤í–‰ (Memory + RAG í†µí•©)
    """
    logger.info(f"ğŸš€ [Agent] í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ (ì„¸ì…˜: {session_id})")
    
    store = get_conversation_store()
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    store.add_message(session_id, "user", user_text)
    
    # 2. Tool Routing (ê°ì • ë¶„ì„ ë“±)
    tool_results = route_tools(user_text)
    emotion_result = tool_results["emotion_result"]
    routine_result = tool_results["routine_result"]
    
    # 3. Memory Layer & RAG Context Retrieval
    memory_context = ""
    rag_context = ""
    
    try:
        # 3-1. Memory Layer (ì¥ê¸° ê¸°ì–µ)
        # ì €ì¥ ì—¬ë¶€ íŒë‹¨ ë° ì €ì¥
        if should_store_memory(user_text, emotion_result):
            add_memory(user_text, emotion_result, session_id)
            
        # ê´€ë ¨ ê¸°ì–µ ì¡°íšŒ
        memories = get_memories_for_prompt(user_text)
        if memories:
            memory_context = f"[ê¸°ì–µëœ ì •ë³´]\n{memories}\n"
            
        # 3-2. Conversation RAG (ê³¼ê±° ëŒ€í™”)
        # í˜„ì¬ ë©”ì‹œì§€ë¥¼ RAGì— ì €ì¥ (ë¹„ë™ê¸°ë¡œ í•˜ë©´ ì¢‹ì§€ë§Œ ì¼ë‹¨ ë™ê¸° ì²˜ë¦¬)
        msg_id_user = f"msg_{session_id}_{uuid.uuid4().hex[:8]}"
        add_message_to_rag(msg_id_user, session_id, "user", user_text, emotion_result)
        
        # ê´€ë ¨ ëŒ€í™” ì¡°íšŒ
        rag_docs = get_rag_context_for_prompt(user_text, session_id)
        if rag_docs:
            rag_context = f"[ê³¼ê±° ëŒ€í™”]\n{rag_docs}\n"
            
    except Exception as e:
        logger.error(f"Memory/RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
    
    # 4. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì „ì²´ ì„¸ì…˜ ëŒ€í™”)
    conversation_history = store.get_history(session_id, limit=None)
    
    # 5. LLM ì‘ë‹µ ìƒì„±
    ai_response_text = generate_llm_response(
        user_text=user_text,
        emotion_result=emotion_result,
        routine_result=routine_result,
        conversation_history=conversation_history,
        memory_context=memory_context,
        rag_context=rag_context
    )
    
    # 6. AI ì‘ë‹µ ì €ì¥
    store.add_message(session_id, "assistant", ai_response_text)
    
    # RAGì—ë„ AI ì‘ë‹µ ì €ì¥
    try:
        msg_id_ai = f"msg_{session_id}_{uuid.uuid4().hex[:8]}"
        add_message_to_rag(msg_id_ai, session_id, "assistant", ai_response_text)
    except Exception as e:
        logger.error(f"RAG ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    logger.info(f"âœ… [Agent] ì‘ë‹µ ìƒì„± ì™„ë£Œ: {ai_response_text[:50]}...")
    
    return {
        "reply_text": ai_response_text,
        "input_text": user_text,
        "emotion_result": emotion_result,
        "routine_result": routine_result,
        "meta": {
            "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
            "used_tools": tool_results["used_tools"],
            "session_id": session_id,
            "stt_quality": stt_quality,
            "speaker_id": speaker_id,
            "memory_used": bool(memory_context),
            "rag_used": bool(rag_context)
        }
    }


def run_ai_bomi_from_audio(audio_bytes: bytes, session_id: str = "default") -> dict[str, Any]:
    """
    ìŒì„± ì…ë ¥ ê¸°ë°˜ AI ë´„ì´ ì‹¤í–‰
    """
    logger.info(f"ğŸ¤ [Agent] ìŒì„± ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ (ì„¸ì…˜: {session_id})")
    
    # 1. STT ì‹¤í–‰
    stt_result = run_speech_to_text(audio_bytes)
    user_text = stt_result["text"]
    stt_quality = stt_result["quality"]
    
    # ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì¡°ê¸° ì¢…ë£Œ
    if not user_text:
        return {
            "reply_text": "ì£„ì†¡í•´ìš”, ì˜ ë“¤ë¦¬ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?",
            "input_text": "",
            "emotion_result": None,
            "routine_result": None,
            "meta": {
                "stt_quality": stt_quality,
                "session_id": session_id
            }
        }
        
    # 2. í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬ë¡œ ìœ„ì„
    return run_ai_bomi_from_text(user_text, session_id, stt_quality)


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    print("Agent í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    result = run_ai_bomi_from_text("ìš”ì¦˜ ì ì´ ì˜ ì•ˆ ì™€ì„œ ë„ˆë¬´ í”¼ê³¤í•´.", session_id="test_session")
    print("\n[í…ŒìŠ¤íŠ¸ ê²°ê³¼]")
    print(f"ì‚¬ìš©ì: {result['input_text']}")
    print(f"AI ë´„ì´: {result['reply_text']}")
    print(f"ê°ì •: {result['emotion_result']['primary_emotion']['name_ko']}")
    
    # 2. ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸
    print("\n[ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸]")
    result2 = run_ai_bomi_from_text("ê·¸ë˜ì„œ ë‚®ì—ë„ ê³„ì† ë©í•˜ê³  ì§‘ì¤‘ì´ ì•ˆ ë¼.", session_id="test_session")
    print(f"ì‚¬ìš©ì: {result2['input_text']}")
    print(f"AI ë´„ì´: {result2['reply_text']}")