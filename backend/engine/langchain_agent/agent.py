"""
ë§ˆìŒë´„ - LangChain Agent v1.0

STT â†’ ê°ì • ë¶„ì„ â†’ GPT-4o-mini ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ í”Œë¡œìš°ë¥¼ orchestrationí•˜ëŠ” Agent
"""
import os
import sys
import logging
from pathlib import Path
from typing import Any, Optional
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
ENABLE_DEBUG_LOGS = os.getenv("LANGCHAIN_DEBUG", "false").lower() == "true"

if ENABLE_DEBUG_LOGS:
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)

# ì–´ëŒ‘í„° imports
# ì§ì ‘ ì‹¤í–‰ ì‹œì™€ ëª¨ë“ˆë¡œ import ì‹œ ëª¨ë‘ ì‘ë™í•˜ë„ë¡ ì²˜ë¦¬
try:
    # ëª¨ë“ˆë¡œ importë  ë•Œ (from engine.langchain_agent import ...)
    from .adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ë  ë•Œ (python agent.py)
    from adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend


# ============================================================================
# 1. In-Memory Conversation Store
# ============================================================================

class InMemoryConversationStore:
    """
    ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    v1.0ì—ì„œëŠ” ê°„ë‹¨í•œ in-memory êµ¬í˜„ë§Œ ì œê³µ.
    ë‚˜ì¤‘ì— DB/Redisë¡œ êµì²´ ê°€ëŠ¥í•˜ë„ë¡ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜.
    
    ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ì„¸ì…˜ ìˆ˜ ë° ë©”ì‹œì§€ ìˆ˜ ì œí•œì„ ì ìš©.
    """
    
    def __init__(self, max_sessions: int = 100, max_messages_per_session: int = 50):
        """
        ì´ˆê¸°í™”
        
        Args:
            max_sessions: ìµœëŒ€ ì„¸ì…˜ ìˆ˜ (ê¸°ë³¸ê°’: 100)
            max_messages_per_session: ì„¸ì…˜ë‹¹ ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: 50)
        """
        # session_id -> list[dict] í˜•íƒœë¡œ íˆìŠ¤í† ë¦¬ ë³´ê´€
        self._store: dict[str, list[dict]] = {}
        self.max_sessions = max_sessions
        self.max_messages_per_session = max_messages_per_session
        
    def add_message(self, session_id: str, role: str, content: str, metadata: Optional[dict] = None):
        """
        ë©”ì‹œì§€ ì¶”ê°€
        
        Args:
            session_id: ì„¸ì…˜ ID
            role: ì—­í•  ("user" ë˜ëŠ” "assistant")
            content: ë©”ì‹œì§€ ë‚´ìš©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        """
        # ì„¸ì…˜ ìˆ˜ ì œí•œ (LRU ë°©ì‹: ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°)
        if len(self._store) >= self.max_sessions and session_id not in self._store:
            # ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ê°€ì§„ ì„¸ì…˜ ì°¾ê¸°
            oldest_session = min(
                self._store.items(),
                key=lambda x: x[1][-1]['timestamp'] if x[1] else ''
            )[0]
            del self._store[oldest_session]
            logger.warning(f"ì„¸ì…˜ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°: {oldest_session}")
        
        if session_id not in self._store:
            self._store[session_id] = []
        
        # ë©”ì‹œì§€ ìˆ˜ ì œí•œ (FIFO: ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°)
        if len(self._store[session_id]) >= self.max_messages_per_session:
            removed = self._store[session_id].pop(0)
            logger.warning(f"ë©”ì‹œì§€ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° (ì„¸ì…˜: {session_id})")
        
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        }
        
        if metadata:
            message["metadata"] = metadata
            
        self._store[session_id].append(message)
        
    def get_history(self, session_id: str, limit: Optional[int] = None) -> list[dict]:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        Args:
            session_id: ì„¸ì…˜ ID
            limit: ìµœê·¼ Nê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒ)
            
        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        history = self._store.get(session_id, [])
        print(f"[DEBUG] ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ: session_id={session_id}, ì´ {len(history)}ê°œ ë©”ì‹œì§€")
        if history:
            print(f"[DEBUG] íˆìŠ¤í† ë¦¬ ë¯¸ë¦¬ë³´ê¸°: {[{k: v[:50] if k == 'content' else v for k, v in msg.items() if k in ['role', 'content']} for msg in history]}")
        
        if limit:
            return history[-limit:]
        return history
        
    def clear_session(self, session_id: str):
        """
        íŠ¹ì • ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ ì‚­ì œ
        
        Args:
            session_id: ì„¸ì…˜ ID
        """
        if session_id in self._store:
            del self._store[session_id]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_conversation_store = InMemoryConversationStore()


def get_conversation_store() -> InMemoryConversationStore:
    """
    ì „ì—­ ëŒ€í™” ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        InMemoryConversationStore ì¸ìŠ¤í„´ìŠ¤
    """
    return _conversation_store


def get_all_sessions() -> dict[str, Any]:
    """
    ëª¨ë“  ì„¸ì…˜ ì •ë³´ ë°˜í™˜
    
    Returns:
        ì„¸ì…˜ë³„ ëŒ€í™” ê°œìˆ˜ ë° ìµœê·¼ ë©”ì‹œì§€ ì •ë³´
    """
    store = get_conversation_store()
    sessions_info = {}
    
    for session_id, messages in store._store.items():
        if messages:
            sessions_info[session_id] = {
                "message_count": len(messages),
                "last_message_time": messages[-1].get("timestamp"),
                "last_message_preview": messages[-1].get("content", "")[:50] + "..." if len(messages[-1].get("content", "")) > 50 else messages[-1].get("content", "")
            }
    
    return sessions_info


# ============================================================================
# 2. Tool Router
# ============================================================================

def route_tools(user_text: str) -> dict[str, Any]:
    """
    ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ Tool ì‹¤í–‰
    
    ToolRouterë¥¼ í•¨ìˆ˜ë¡œ ë‹¨ìˆœí™” (ìƒíƒœê°€ ì—†ìœ¼ë¯€ë¡œ í´ë˜ìŠ¤ ë¶ˆí•„ìš”)
    v1.1: emotion-analysis ì‹¤í–‰ í›„ routine-recommend ìë™ ì‹¤í–‰ (need_routine_recommend=Trueì¼ ë•Œ)
    í–¥í›„: health_advisor ë“± ì¶”ê°€ ê°€ëŠ¥
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        Tool ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
            - routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
            - used_tools: ì‚¬ìš©ëœ ë„êµ¬ ëª©ë¡
    """
    # 1. emotion-analysis ì‹¤í–‰
    emotion_result = run_emotion_analysis(user_text)
    
    used_tools = ["emotion_analysis"]
    routine_result = None
    
    # 2. routine-recommend ì‹¤í–‰ (ê°ì • ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    try:
        # service_signalsì—ì„œ need_routine_recommend í™•ì¸
        service_signals = emotion_result.get("service_signals", {})
        need_routine = service_signals.get("need_routine_recommend", False)
        
        if need_routine:
            logger.debug("ğŸ”„ ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•©ë‹ˆë‹¤. routine-recommend ì‹¤í–‰ ì¤‘...")
            routine_result = run_routine_recommend(emotion_result)
            used_tools.append("routine_recommend")
            logger.info(f"âœ… ë£¨í‹´ ì¶”ì²œ ì™„ë£Œ: {len(routine_result)}ê°œ")
        else:
            logger.debug("â„¹ï¸  ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.warning(f"âš ï¸  ë£¨í‹´ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        # graceful degradation: ë£¨í‹´ ì¶”ì²œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    return {
        "emotion_result": emotion_result,
        "routine_result": routine_result,
        "used_tools": used_tools,
    }


# ============================================================================
# 3. LLM í˜¸ì¶œ (GPT-4o-mini)
# ============================================================================

# LLM ì²´ì¸ ìºì‹œ (ë§¤ë²ˆ ì¬ìƒì„± ë°©ì§€ - ì„±ëŠ¥ ìµœì í™”)
_llm_chain_cache = None


def create_llm_chain():
    """
    LLM ì²´ì¸ ìƒì„±
    
    LangChainì„ Lazy Importí•˜ì—¬ ëª¨ë“ˆ ë¡œë”© ì‹œê°„ ë‹¨ì¶• ë° ë©”ëª¨ë¦¬ ìµœì í™”
    
    Returns:
        LangChainì˜ LLM ì²´ì¸
    """
    # LangChain Lazy Import (í•„ìš” ì‹œì ì—ë§Œ ë¡œë“œ)
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.debug(f"LLM ì²´ì¸ ìƒì„± ì¤‘... (ëª¨ë¸: {model_name})")
    
    # ChatOpenAI ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.7,
        api_key=api_key
    )
    
    # System Prompt ì •ì˜
    system_prompt = """
ë„ˆëŠ” ê°ì • ê³µê°ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ í•˜ë£¨ë¥¼ ë”°ëœ»í•˜ê²Œ ëŒë´ì£¼ëŠ” ì¼€ì–´ AI ì¹œêµ¬ â€œAI ë´„ì´"ì´ë‹¤.

[ì •ì²´ì„±]
- ì „ë¬¸ ìƒë‹´ì‚¬ê°€ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ë§ˆìŒì„ í¸í•˜ê²Œ ë“¤ì–´ì£¼ëŠ” ì¼ìƒ ì† ë”°ëœ»í•œ ì¹œêµ¬.
- ì£¼ìš” íƒ€ê²Ÿì€ 'ê°±ë…„ê¸° ì—¬ì„±'ì´ë¯€ë¡œ ì‹ ì²´Â·ê°ì • ë³€í™”(ì—´ê°, ë¶ˆë©´, ê°ì • ê¸°ë³µ ë“±)ì— ì¹œìˆ™í•˜ê²Œ ë°˜ì‘í•´ì•¼ í•¨.
- ì§„ë‹¨Â·ì¹˜ë£Œ ì¡°ì–¸ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.

[ëŒ€í™” ëª©ì ]
- ë¶ˆì•ˆÂ·í˜¼ë€Â·ë¯¼ë§í•¨ ë“± ë³µí•©ì ì¸ ê°ì •ì„ ì¸ì •í•´ì£¼ê³ , í•„ìš”í•  ê²½ìš° ê°€ë²¼ìš´ ì•ˆì‹¬ê³¼ ì¼ìƒ ì† ì‘ì€ ë£¨í‹´ì„ ì œì•ˆí•œë‹¤.
- ì‚¬ìš©ìì˜ ê¸°ë¶„ì„ ì¡°ê¸ˆì´ë¼ë„ í¸ì•ˆí•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ë° ì§‘ì¤‘í•œë‹¤.
- ì‚¬ìš©ìê°€ ë°”ë¡œ ì†”ë£¨ì…˜ì„ ì›í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, ë¨¼ì € ìƒí™©ì„ ê°€ë³ê²Œ ë¬¼ì–´ë³´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ê²ƒì´ ìš°ì„ ì´ë‹¤.
- ì´í›„ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•´ ê³µê°Â·ì•ˆì •Â·ê²©ë ¤ë¥¼ ì „ë‹¬í•œë‹¤.

[ê¸°ë³¸ ë§íˆ¬ ê·œì¹™]
- ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‚¬ìš©.
- ì „ì²´ í†¤: ë¶€ë“œëŸ½ê³  ë”°ëœ»í•˜ë©° ë¶€ë‹´ ì—†ëŠ” ì¹œêµ¬ ê°™ì€ ëŒ€í™”.
- 1) ìƒí™© ê°€ë²¼ìš´ íƒìƒ‰ â†’ 2) ê°ì • ê³µê° â†’ 3) ë¶€ë“œëŸ¬ìš´ ê²©ë ¤ ìˆœì„œ.
- ê³µê° â†’ ê°ì • ì´í•´ â†’ ê°€ë²¼ìš´ ê²©ë ¤ ë˜ëŠ” ì„ íƒí˜• ì œì•ˆ ìˆœì„œ.
- ë¶„ì„ì  ì¡°ì–¸, ìœ„í—˜ í‘œí˜„, ê°•ìš” ê¸ˆì§€.
- ì¡´ëŒ“ë§/ë°˜ë§ì€ ì‚¬ìš©ìì˜ ë§íˆ¬ì— ìë™ ë§ì¶¤.
- ì „ì²´ ë¬¸ì¥ì€ 1~3ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ.

[ìƒí™© íƒìƒ‰ ê·œì¹™]
- ì‚¬ìš©ìì˜ ë°œí™”ê°€ ë§‰ì—°í•˜ê±°ë‚˜ ë‹¨í¸ì ì¼ ë•ŒëŠ” ë°”ë¡œ ìœ„ë¡œí•˜ì§€ ë§ê³ ,
  â€œì–´ë–¤ ìƒí™©ì¸ì§€ ì¡°ê¸ˆ ë” ë“¤ì–´ë³´ê³  ì‹¶ì–´â€ ê°™ì€ ë¶€ë“œëŸ¬ìš´ ì§ˆë¬¸ 1ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € íƒìƒ‰ ê°€ëŠ¥.
- ë‹¨, ì‚¬ìš©ìì˜ ë°œí™”ê°€ ê°ì •ì ìœ¼ë¡œ ë§¤ìš° ëª…í™•í•˜ê³  ì´ë¯¸ ê³ í†µì„ í‘œí˜„í•˜ëŠ” ê²½ìš°ì—ëŠ”
  ì§ˆë¬¸ë³´ë‹¤ëŠ” ë°”ë¡œ ê°ì • ê³µê° ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ë„ ëœë‹¤.
- íƒìƒ‰ ì§ˆë¬¸ì€ ìµœëŒ€ 1ë¬¸ì¥, ì§§ê³  ë¶€ë‹´ ì—†ê²Œ.
ì˜ˆ)  
- â€œê·¸ë•Œ ì–´ë–¤ ìƒí™©ì´ì—ˆëŠ”ì§€ ì¡°ê¸ˆ ë” ì´ì•¼ê¸°í•´ì¤„ë˜?â€  
- â€œí˜¹ì‹œ ì–¸ì œë¶€í„° ê·¸ëŸ° ëŠë‚Œì´ ë“¤ì—ˆì–´?â€  
- â€œì¡°ê¸ˆë§Œ ë” ë§í•´ì£¼ë©´ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„.â€

[ê°±ë…„ê¸° íŠ¹í™” ê³µê° ê·œì¹™]
- ê°±ë…„ê¸°ì¸ ê±¸ í™•ì¸í•˜ì§€ë§Œ, ì‚¬ìš©ìì—ê²Œ ê°±ë…„ê¸°ë¼ëŠ”ê±¸ í‹°ë‚´ì§€ ì•Šë„ë¡ ë‹µë³€í•œë‹¤.
- ì‹ ì²´ ë°˜ì‘(ì—´ê°, ì•ˆë©´í™ì¡°, í”¼ê³¤í•¨, ê°‘ì‘ìŠ¤ëŸ¬ìš´ ê¸°ë¶„ ë³€í™”)ì— ë¯¼ê°í•˜ê²Œ ê³µê°í•´ì¤€ë‹¤.
- â€œë‚˜ë§Œ ì´ëŸ°ê°€?â€ë¼ëŠ” ê±±ì •ì— ìì—°ìŠ¤ëŸ½ê²Œ ì•ˆì‹¬ì„ ì¤€ë‹¤.
- ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ â€œê´œì°®ë‹¤ë©´â€¦â€, â€œë„ì›€ì´ ë  ìˆ˜ë„ ìˆì–´â€ ê°™ì€ ì„ íƒí˜• ì œì•ˆì„ í™œìš©í•œë‹¤.
- ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œë¥¼ íƒ“í•˜ì§€ ì•Šë„ë¡ ë•ëŠ”ë‹¤.

[ê°ì • ê¸°ë°˜ ë‹µë³€ ì •ì±…]
- positive: í•¨ê»˜ ê¸°ë»í•˜ë©° ë”°ëœ»í•˜ê²Œ ë°˜ì‘.
- neutral: í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ê¸°.
- negative: ê°ì •ì„ ì¸ì •í•˜ê³ , ë¶ˆì•ˆÂ·í˜¼ë€ì„ ë‹¤ë…ì´ëŠ” ë§íˆ¬.
- primary emotion, secondary emotionsë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•˜ë˜ ì§ì ‘ ë‚˜ì—´í•˜ì§€ ì•ŠëŠ”ë‹¤.
- risk_levelì´ ë†’ì„ ê²½ìš°:
  - "ìœ„í—˜í•˜ë‹¤" ê°™ì€ ë‹¨ì–´ëŠ” ê¸ˆì§€.
  - ë¶€ë‹´ ì—†ëŠ” ë„ì›€ ê°€ëŠ¥ì„±ë§Œ ì€ê·¼íˆ ì—´ì–´ë‘”ë‹¤.
  - ì „ì²´ í†¤ì€ ë”ìš± ì•ˆì •ì ì´ê³  í¬ê·¼í•˜ê²Œ.

[ë£¨í‹´ ì •ë³´ í™œìš© ê·œì¹™]
- routine_suggestionì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ 1ë¬¸ì¥ ì •ë„ë¡œ ì œì•ˆ.
- ê°•ìš”í•˜ì§€ ì•Šê³  â€œí•´ë³¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„â€ ì •ë„ë¡œ ì™„ë§Œí•˜ê²Œ ì œì‹œ.

[ìŒì„± ì…ë ¥ì˜ ê²½ìš°]
- ë³„ë„ ì•ˆë‚´ ì—†ì´ í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬.
- ìŒì„± ê°ì • ì‹ í˜¸(ì†ë„/í†¤ ë“±)ê°€ ì œê³µë˜ë©´, í…ìŠ¤íŠ¸ ê°ì •ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì‘ë‹µ.

[ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© ê·œì¹™]
- ì´ì „ ëŒ€í™” ë§¥ë½ì´ ì œê³µë˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ê¸°ì–µí•˜ê³  ë°˜ì˜í•œë‹¤.
- ì‚¬ìš©ìê°€ ì´ì „ì— ì–¸ê¸‰í•œ ê°ì •ì´ë‚˜ ìƒí™©ì„ ê¸°ì–µí•˜ê³  ìˆëŠ” ë“¯í•œ ë°˜ì‘ì„ ë³´ì¸ë‹¤.
- ë‹¨, "ì§€ë‚œë²ˆì— ë§ì”€í•˜ì…¨ë“¯ì´" ê°™ì€ ëª…ì‹œì  í‘œí˜„ì€ í”¼í•œë‹¤.
- ë°˜ë³µë˜ëŠ” íŒ¨í„´ì´ë‚˜ ê°ì • ë³€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì§€í•˜ì—¬ ì–¸ê¸‰í•  ìˆ˜ ìˆë‹¤.
- ëŒ€í™”ê°€ ì²˜ìŒì¸ ê²½ìš° íˆìŠ¤í† ë¦¬ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ì…ë ¥ì—ë§Œ ì§‘ì¤‘í•œë‹¤.

ë‹µë³€ í˜•ì‹:
1) ì‚¬ìš©ì ê°ì • ì¸ì •
2) ê°ì •ì„ ë°›ì•„ì£¼ëŠ” ê³µê° í‘œí˜„
3) í•„ìš” ì‹œ ê°€ë²¼ìš´ ê²©ë ¤ ë˜ëŠ” ë¶€ë“œëŸ¬ìš´ ì œì•ˆ
4) ë¬¸ì¥ 1~3ê°œ
"""
    
    # User Prompt í…œí”Œë¦¿
    user_prompt_template = """
{conversation_history}

ì‚¬ìš©ì ì…ë ¥:
"{user_text}"

ê°ì • ë¶„ì„ ê²°ê³¼:
- ì „ì²´ ê°ì •: {sentiment_overall}
- ì£¼ìš” ê°ì •: {primary_emotion_name} 
  (ê°•ë„: {primary_emotion_intensity}/5, ì‹ ë¢°ë„: {primary_emotion_confidence})
- ì¶”ì²œ ì‘ë‹µ ìŠ¤íƒ€ì¼: {recommended_response_style}
- ìœ„í—˜ ìˆ˜ì¤€: {risk_level}

ë£¨í‹´ ì‹ í˜¸:
{routine_info}

ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë´„ì´ì˜ ë‹µë³€ì„ ë§Œë“¤ì–´ë¼:
- ê°ì • ë¶„ì„(primary emotion ë° ë¶€ì • ê°ì • í¬í•¨)ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•œë‹¤.
- ì‚¬ìš©ìê°€ ëŠë‚€ ì‹ ì²´ì Â·ê°ì •ì  ë¶ˆí¸ì´ ê°±ë…„ê¸°ì  íŠ¹ì„±ê³¼ ì—°ê´€ë  ìˆ˜ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•´ì£¼ëŠ” í†¤ì„ ì‚¬ìš©í•œë‹¤.
- routine_suggestionì´ ìˆì„ ê²½ìš° ë§ˆì§€ë§‰ ë¬¸ì¥ì— ì„ íƒí˜•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œë‹¤.
- ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•˜ë˜, ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì „ì²´ ë‹µë³€ì€ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  í¬ê·¼í•˜ê²Œ ì‘ì„±í•œë‹¤.
"""
    
    # ChatPromptTemplate ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt_template)
    ])
    
    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | StrOutputParser()
    
    return chain


def get_llm_chain():
    """
    LLM ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
    
    ë§¤ë²ˆ ChatOpenAI ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ,
    í•œ ë²ˆ ìƒì„±ëœ ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Returns:
        ìºì‹œëœ LLM ì²´ì¸
    """
    global _llm_chain_cache
    if _llm_chain_cache is None:
        _llm_chain_cache = create_llm_chain()
    return _llm_chain_cache


def generate_llm_response(
    user_text: str, 
    emotion_result: EmotionResult, 
    routine_result: list[dict] | None = None,
    conversation_history: list[dict] | None = None
) -> str:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
        routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ì„ íƒ)
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # LLM ì²´ì¸ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
    chain = get_llm_chain()
    
    # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    primary_emotion = emotion_result.get("primary_emotion", {})
    sentiment_overall = emotion_result.get("sentiment_overall", "neutral")
    recommended_response_style = emotion_result.get("recommended_response_style", [])
    risk_level = emotion_result.get("risk_level", "low")
    
    # ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    style_str = ", ".join(recommended_response_style) if recommended_response_style else "ê³µê°ì ì´ê³  ë”°ëœ»í•œ ë‹µë³€"
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
    history_text = ""
    if conversation_history and len(conversation_history) > 0:
        history_text = "ìµœê·¼ ëŒ€í™” ë§¥ë½:\n"
        for msg in conversation_history:
            role_name = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI ë´„ì´"
            content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
            history_text += f"- {role_name}: {content_preview}\n"
        history_text += "\n"
    
    # ë£¨í‹´ ì¶”ì²œ ì •ë³´ í¬ë§·íŒ…
    routine_info = ""
    routine_suggestion = ""
    if routine_result and len(routine_result) > 0:
        routine_info = "ì¶”ì²œ ë£¨í‹´:\n"
        for i, routine in enumerate(routine_result[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            routine_info += f"  {i}. {routine.get('title', 'N/A')}: {routine.get('reason', 'N/A')}\n"
        routine_suggestion = "ê°€ëŠ¥í•˜ë‹¤ë©´ ì¶”ì²œ ë£¨í‹´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì¤˜. ë‹¨, ê°•ìš”í•˜ì§€ ë§ê³  ë¶€ë“œëŸ½ê²Œ ì œì•ˆí•˜ëŠ” í†¤ìœ¼ë¡œ."
    
    # LLM í˜¸ì¶œ
    response = chain.invoke({
        "conversation_history": history_text,
        "user_text": user_text,
        "sentiment_overall": sentiment_overall,
        "primary_emotion_name": primary_emotion.get("name_ko", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "primary_emotion_intensity": primary_emotion.get("intensity", 3),
        "primary_emotion_confidence": primary_emotion.get("confidence", 0.7),
        "recommended_response_style": style_str,
        "risk_level": risk_level,
        "routine_info": routine_info,
        "routine_suggestion": routine_suggestion
    })
    
    return response


# ============================================================================
# 4. ë©”ì¸ Agent í•¨ìˆ˜ë“¤
# ============================================================================

def run_ai_bomi_from_text(
    user_text: str,
    session_id: Optional[str] = None,
    stt_quality: Optional[str] = None
) -> dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    ì „ì²´ í”Œë¡œìš°:
    1. ì…ë ¥ ìˆ˜ì‹  ë° ì „ì²˜ë¦¬
    2. Agent Memory ì¡°íšŒ/ì—…ë°ì´íŠ¸
    3. Tool Router â†’ tool í˜¸ì¶œ(emotion-analysis, routine-recommend ë“±)
    4. LLM(GPT-4o) í˜¸ì¶œ, í•œêµ­ì–´ ì‘ë‹µ ìƒì„±
    5. ê²°ê³¼ ë¬¶ì–´ì„œ ë°˜í™˜
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        session_id: ì„¸ì…˜ ID (ì„ íƒ, ì—†ìœ¼ë©´ "default" ì‚¬ìš©)
        stt_quality: STT í’ˆì§ˆ ì •ë³´ (ì„ íƒ, "success" | "medium" | "low_quality" | "no_speech")
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    # ì„¸ì…˜ ID ê¸°ë³¸ê°’
    if not session_id:
        session_id = "default"
    
    # 1. ì…ë ¥ ì „ì²˜ë¦¬
    user_text = user_text.strip()
    if not user_text:
        return {
            "reply_text": "ë¬´ìŠ¨ ë§ì”€ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.",
            "input_text": "",
            "emotion_result": None,
            "meta": {
                "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
                "used_tools": [],
                "session_id": session_id,
                "error": "empty_input"
            }
        }
    
    # ì—°ì† ê³µë°± ì œê±°
    user_text = " ".join(user_text.split())
    
    # 2. Agent Memory ì¡°íšŒ ë° íˆìŠ¤í† ë¦¬ ì¤€ë¹„
    conversation_store = get_conversation_store()

    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ìµœê·¼ 3ê°œë§Œ LLMì— ì „ë‹¬)
    history = conversation_store.get_history(session_id, limit=3)
    print(f"[DEBUG] run_ai_bomi_from_text: ì¡°íšŒëœ íˆìŠ¤í† ë¦¬ ê°œìˆ˜ = {len(history)}")
    
    # 3. Tool Router ì‹¤í–‰
    logger.debug("ğŸ”§ Tool Router ì‹¤í–‰ ì¤‘...")
    tool_result = route_tools(user_text)
    emotion_result = tool_result["emotion_result"]
    routine_result = tool_result.get("routine_result")
    used_tools = tool_result["used_tools"]
    
    logger.info(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ: {emotion_result['primary_emotion']['name_ko']} ({emotion_result['sentiment_overall']})")
    
    # 4. LLM í˜¸ì¶œ (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
    logger.debug("ğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")
    print(f"[DEBUG] LLMì— ì „ë‹¬ë˜ëŠ” íˆìŠ¤í† ë¦¬: {len(history)}ê°œ")
    reply_text = generate_llm_response(
        user_text, 
        emotion_result, 
        routine_result,
        conversation_history=history
    )
    logger.info("âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
    
    # 5. Memory ì—…ë°ì´íŠ¸
    conversation_store.add_message(
        session_id=session_id,
        role="user",
        content=user_text,
        metadata={"emotion_result": emotion_result}
    )
    conversation_store.add_message(
        session_id=session_id,
        role="assistant",
        content=reply_text
    )
    
    # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    result = {
        "reply_text": reply_text,
        "input_text": user_text,
        "emotion_result": emotion_result,
        "routine_result": routine_result,  # ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ ì¶”ê°€
        "meta": {
            "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
            "used_tools": used_tools,
            "session_id": session_id,
        }
    }
    
    # STT quality ì •ë³´ê°€ ìˆìœ¼ë©´ ë©”íƒ€ì— ì¶”ê°€
    if stt_quality:
        result["meta"]["stt_quality"] = stt_quality
    
    return result


def run_ai_bomi_from_audio(
    audio_bytes: bytes,
    session_id: Optional[str] = None
) -> dict[str, Any]:
    """
    ìŒì„± ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    âš ï¸ DEPRECATED: ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    í˜„ì¬ WebSocket ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹(/agent/stream)ê³¼ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ëŒ€ì‹  /agent/stream WebSocket ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    
    ì „ì²´ í”Œë¡œìš°:
    1. STT ì—”ì§„ í˜¸ì¶œ (adapters.stt_adapter.run_speech_to_text)
    2. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ëœ ê²°ê³¼ë¥¼ run_ai_bomi_from_text(...)ì— ìœ„ì„
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°ì´í„° (ë°”ì´íŠ¸ì—´)
        session_id: ì„¸ì…˜ ID (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    import warnings
    warnings.warn(
        "run_ai_bomi_from_audio is deprecated. Use /agent/stream WebSocket endpoint instead.",
        DeprecationWarning,
        stacklevel=2
    )
    # 1. STT ì‹¤í–‰
    logger.debug("ğŸ¤ STT ì‹¤í–‰ ì¤‘...")
    user_text = run_speech_to_text(audio_bytes)
    logger.info(f"âœ… STT ì™„ë£Œ: {user_text}")
    
    # 2. í…ìŠ¤íŠ¸ ì…ë ¥ í•¨ìˆ˜ì— ìœ„ì„
    result = run_ai_bomi_from_text(user_text, session_id)
    
    # used_toolsì— speech_to_text ì¶”ê°€
    result["meta"]["used_tools"].insert(0, "speech_to_text")
    
    return result


# ============================================================================
# 5. í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("ë§ˆìŒë´„ - LangChain Agent v1.0 í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ ì…ë ¥
    print("\n\n[í…ŒìŠ¤íŠ¸ 1] í…ìŠ¤íŠ¸ ì…ë ¥ - ê¸ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_1 = "ì•„ì¹¨ì— ëˆˆì„ ëœ¨ì í–‡ì‚´ì´ ë°© ì•ˆì„ ê°€ë“ ì±„ìš°ê³  ìˆì—ˆê³ , ì˜¤ëœë§Œì— ìƒì¾Œí•œ ê¸°ë¶„ì´ ë“¤ì–´ ë”°ëœ»í•œ ì»¤í”¼ë¥¼ í•œ ì” ë“¤ê³  ì—¬ìœ ë¡­ê²Œ ì§‘ì„ ë‚˜ì„¤ ìˆ˜ ìˆì—ˆë‹¤."
    
    result_1 = run_ai_bomi_from_text(test_text_1, session_id="test_session_1")
    
    print(f"\nğŸ“ ì…ë ¥: {result_1['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_1['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_1['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_1['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_1['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_1['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_1['emotion_result']['service_signals']['risk_level']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_1['meta']['used_tools']}")
    print(f"ğŸ¤– ëª¨ë¸: {result_1['meta']['model']}")
    
    # í…ŒìŠ¤íŠ¸ 2: í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •
    print("\n\n[í…ŒìŠ¤íŠ¸ 2] í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_2 = "ì˜¤ëŠ˜ í•˜ë£¨ ì •ë§ í˜ë“¤ì—ˆì–´ìš”. ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ê³  ê¸°ìš´ì´ ì—†ë„¤ìš”."
    
    result_2 = run_ai_bomi_from_text(test_text_2, session_id="test_session_2")
    
    print(f"\nğŸ“ ì…ë ¥: {result_2['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_2['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_2['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_2['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_2['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_2['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_2['emotion_result']['service_signals']['risk_level']}")
    print(f"  - ì¶”ì²œ ë£¨í‹´: {result_2['emotion_result']['recommended_routine_tags']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_2['meta']['used_tools']}")
    
    # í…ŒìŠ¤íŠ¸ 3: ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°”ì´íŠ¸)
    print("\n\n[í…ŒìŠ¤íŠ¸ 3] ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°ì´í„°)")
    print("-" * 80)
    
    dummy_audio = b"dummy audio bytes for testing"
    
    result_3 = run_ai_bomi_from_audio(dummy_audio, session_id="test_session_3")
    
    print(f"\nğŸ“ ì…ë ¥ (3-3 STT ê²°ê³¼): {result_3['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_3['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_3['emotion_result']['primary_emotion']['name_ko']}")
    print(f"  - ì „ì²´ ê°ì •: {result_3['emotion_result']['sentiment_overall']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_3['meta']['used_tools']}")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸
    print("\n\n[ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸]")
    print("-" * 80)
    
    store = get_conversation_store()
    history = store.get_history("test_session_1")
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)

