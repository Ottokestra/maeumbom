"""
ë§ˆìŒë´„ - LangChain Agent v1.0

STT â†’ ê°ì • ë¶„ì„ â†’ GPT-4o ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ í”Œë¡œìš°ë¥¼ orchestrationí•˜ëŠ” Agent
"""
import os
import sys
from pathlib import Path
from typing import Any, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ì–´ëŒ‘í„° imports
# ì§ì ‘ ì‹¤í–‰ ì‹œì™€ ëª¨ë“ˆë¡œ import ì‹œ ëª¨ë‘ ì‘ë™í•˜ë„ë¡ ì²˜ë¦¬
try:
    # ëª¨ë“ˆë¡œ importë  ë•Œ (from engine.langchain_agent import ...)
    from .adapters import run_speech_to_text, run_emotion_analysis, EmotionResult
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ë  ë•Œ (python agent.py)
    from adapters import run_speech_to_text, run_emotion_analysis, EmotionResult


# ============================================================================
# 1. In-Memory Conversation Store
# ============================================================================

class InMemoryConversationStore:
    """
    ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    v1.0ì—ì„œëŠ” ê°„ë‹¨í•œ in-memory êµ¬í˜„ë§Œ ì œê³µ.
    ë‚˜ì¤‘ì— DB/Redisë¡œ êµì²´ ê°€ëŠ¥í•˜ë„ë¡ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜.
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # session_id -> list[dict] í˜•íƒœë¡œ íˆìŠ¤í† ë¦¬ ë³´ê´€
        self._store: dict[str, list[dict]] = {}
        
    def add_message(self, session_id: str, role: str, content: str, metadata: Optional[dict] = None):
        """
        ë©”ì‹œì§€ ì¶”ê°€
        
        Args:
            session_id: ì„¸ì…˜ ID
            role: ì—­í•  ("user" ë˜ëŠ” "assistant")
            content: ë©”ì‹œì§€ ë‚´ìš©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        """
        if session_id not in self._store:
            self._store[session_id] = []
            
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        }
        
        if metadata:
            message["metadata"] = metadata
            
        self._store[session_id].append(message)
        
    def get_history(self, session_id: str, limit: Optional[int] = None) -> list[dict]:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        Args:
            session_id: ì„¸ì…˜ ID
            limit: ìµœê·¼ Nê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒ)
            
        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        history = self._store.get(session_id, [])
        
        if limit:
            return history[-limit:]
        return history
        
    def clear_session(self, session_id: str):
        """
        íŠ¹ì • ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ ì‚­ì œ
        
        Args:
            session_id: ì„¸ì…˜ ID
        """
        if session_id in self._store:
            del self._store[session_id]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_conversation_store = InMemoryConversationStore()


def get_conversation_store() -> InMemoryConversationStore:
    """
    ì „ì—­ ëŒ€í™” ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        InMemoryConversationStore ì¸ìŠ¤í„´ìŠ¤
    """
    return _conversation_store


def get_all_sessions() -> dict[str, Any]:
    """
    ëª¨ë“  ì„¸ì…˜ ì •ë³´ ë°˜í™˜
    
    Returns:
        ì„¸ì…˜ë³„ ëŒ€í™” ê°œìˆ˜ ë° ìµœê·¼ ë©”ì‹œì§€ ì •ë³´
    """
    store = get_conversation_store()
    sessions_info = {}
    
    for session_id, messages in store._store.items():
        if messages:
            sessions_info[session_id] = {
                "message_count": len(messages),
                "last_message_time": messages[-1].get("timestamp"),
                "last_message_preview": messages[-1].get("content", "")[:50] + "..." if len(messages[-1].get("content", "")) > 50 else messages[-1].get("content", "")
            }
    
    return sessions_info


# ============================================================================
# 2. Tool Router
# ============================================================================

class ToolRouter:
    """
    Tool í˜¸ì¶œì„ ë¼ìš°íŒ…í•˜ëŠ” í´ë˜ìŠ¤
    
    v1.0ì—ì„œëŠ” emotion-analysisë§Œ ì‚¬ìš©í•˜ì§€ë§Œ,
    ë‚˜ì¤‘ì— routine_recommend, health_advisor ë“±ì„ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆê²Œ ì„¤ê³„
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        pass
        
    def run(self, user_text: str) -> dict[str, Any]:
        """
        ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ Tool ì‹¤í–‰
        
        v1.0: ë¬´ì¡°ê±´ emotion-analysis ì‹¤í–‰
        
        Args:
            user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
            
        Returns:
            Tool ì‹¤í–‰ ê²°ê³¼
        """
        # emotion-analysis ì‹¤í–‰
        emotion_result = run_emotion_analysis(user_text)
        
        return {
            "emotion_result": emotion_result,
            "used_tools": ["emotion_analysis"],
        }


# ============================================================================
# 3. LLM í˜¸ì¶œ (GPT-4o)
# ============================================================================

def create_llm_chain():
    """
    LLM ì²´ì¸ ìƒì„±
    
    Returns:
        LangChainì˜ LLM ì²´ì¸
    """
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ChatOpenAI ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.7,
        api_key=api_key
    )
    
    # System Prompt ì •ì˜
    system_prompt = """ë„ˆëŠ” ê°ì • ì¼€ì–´ AI "AI ë´„ì´"ë‹¤.

**ì—­í• :**
- ì‚¬ìš©ìì˜ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•´ì„œ, ì‚¬ìš©ìì˜ ê¸°ë¶„ì„ ì¸ì •í•˜ê³  ê³µê°í•˜ê±°ë‚˜ ê°€ë³ê²Œ ê²©ë ¤í•˜ëŠ” í•œêµ­ì–´ ë‹µë³€ì„ ì¤€ë‹¤.
- ìƒë‹´ì‚¬ì²˜ëŸ¼ ë¬´ê²ê²Œ ë§í•˜ê¸°ë³´ë‹¤ëŠ”, ì¼ìƒì„ í•¨ê»˜ ë‚˜ëˆ„ëŠ” ë”°ëœ»í•œ ì¹œêµ¬ì²˜ëŸ¼ ë¶€ë“œëŸ½ê²Œ ì´ì•¼ê¸°í•œë‹¤.
- ë‹µë³€ì€ 3~5ë¬¸ì¥ ì •ë„ë¡œ í•œë‹¤.

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ê³µê°ê³¼ ì´í•´ë¥¼ ìš°ì„ ìœ¼ë¡œ í•œë‹¤.
- ì‚¬ìš©ìì˜ ê°ì •ì„ íŒë‹¨í•˜ê±°ë‚˜ ë¹„ë‚œí•˜ì§€ ì•ŠëŠ”ë‹¤.
- í•„ìš”í•˜ë©´ ê°€ë³ê²Œ ê²©ë ¤í•˜ë˜, ê°•ìš”í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•œë‹¤.
"""
    
    # User Prompt í…œí”Œë¦¿
    user_prompt_template = """ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ ë§í–ˆì–´:

"{user_text}"

ê°ì • ë¶„ì„ ê²°ê³¼:
- ì „ì²´ ê°ì •: {sentiment_overall}
- ì£¼ìš” ê°ì •: {primary_emotion_name} (ê°•ë„: {primary_emotion_intensity}/5, ì‹ ë¢°ë„: {primary_emotion_confidence})
- ì¶”ì²œ ì‘ë‹µ ìŠ¤íƒ€ì¼: {recommended_response_style}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ, ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ë‹µë³€ì„ í•´ì¤˜.
"""
    
    # ChatPromptTemplate ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt_template)
    ])
    
    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | StrOutputParser()
    
    return chain


def generate_llm_response(user_text: str, emotion_result: EmotionResult) -> str:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # LLM ì²´ì¸ ìƒì„±
    chain = create_llm_chain()
    
    # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    primary_emotion = emotion_result.get("primary_emotion", {})
    sentiment_overall = emotion_result.get("sentiment_overall", "neutral")
    recommended_response_style = emotion_result.get("recommended_response_style", [])
    
    # ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    style_str = ", ".join(recommended_response_style) if recommended_response_style else "ê³µê°ì ì´ê³  ë”°ëœ»í•œ ë‹µë³€"
    
    # LLM í˜¸ì¶œ
    response = chain.invoke({
        "user_text": user_text,
        "sentiment_overall": sentiment_overall,
        "primary_emotion_name": primary_emotion.get("name_ko", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "primary_emotion_intensity": primary_emotion.get("intensity", 3),
        "primary_emotion_confidence": primary_emotion.get("confidence", 0.7),
        "recommended_response_style": style_str
    })
    
    return response


# ============================================================================
# 4. ë©”ì¸ Agent í•¨ìˆ˜ë“¤
# ============================================================================

def run_ai_bomi_from_text(
    user_text: str,
    session_id: Optional[str] = None
) -> dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    ì „ì²´ í”Œë¡œìš°:
    1. ì…ë ¥ ìˆ˜ì‹  ë° ì „ì²˜ë¦¬
    2. Agent Memory ì¡°íšŒ/ì—…ë°ì´íŠ¸
    3. Tool Router â†’ emotion-analysis í˜¸ì¶œ
    4. LLM(GPT-4o) í˜¸ì¶œ, í•œêµ­ì–´ ì‘ë‹µ ìƒì„±
    5. ê²°ê³¼ ë¬¶ì–´ì„œ ë°˜í™˜
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        session_id: ì„¸ì…˜ ID (ì„ íƒ, ì—†ìœ¼ë©´ "default" ì‚¬ìš©)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    # ì„¸ì…˜ ID ê¸°ë³¸ê°’
    if not session_id:
        session_id = "default"
    
    # 1. ì…ë ¥ ì „ì²˜ë¦¬
    user_text = user_text.strip()
    if not user_text:
        return {
            "reply_text": "ë¬´ìŠ¨ ë§ì”€ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.",
            "input_text": "",
            "emotion_result": None,
            "meta": {
                "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
                "used_tools": [],
                "session_id": session_id,
                "error": "empty_input"
            }
        }
    
    # ì—°ì† ê³µë°± ì œê±°
    user_text = " ".join(user_text.split())
    
    # 2. Agent Memory ì¡°íšŒ (v1.0ì—ì„œëŠ” ë‹¨ìˆœ ì €ì¥ë§Œ)
    conversation_store = get_conversation_store()
    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (í•„ìš”ì‹œ ì‚¬ìš©)
    # history = conversation_store.get_history(session_id, limit=5)
    
    # 3. Tool Router ì‹¤í–‰
    print(f"\nğŸ”§ Tool Router ì‹¤í–‰ ì¤‘...")
    tool_result = ToolRouter().run(user_text)
    emotion_result = tool_result["emotion_result"]
    used_tools = tool_result["used_tools"]
    
    print(f"âœ… 3-4 ê°ì • ë¶„ì„ ì™„ë£Œ: {emotion_result['primary_emotion']['name_ko']} ({emotion_result['sentiment_overall']})")
    
    # 4. LLM í˜¸ì¶œ
    print(f"\nğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")
    reply_text = generate_llm_response(user_text, emotion_result)
    print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
    
    # 5. Memory ì—…ë°ì´íŠ¸
    conversation_store.add_message(
        session_id=session_id,
        role="user",
        content=user_text,
        metadata={"emotion_result": emotion_result}
    )
    conversation_store.add_message(
        session_id=session_id,
        role="assistant",
        content=reply_text
    )
    
    # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    result = {
        "reply_text": reply_text,
        "input_text": user_text,
        "emotion_result": emotion_result,
        "meta": {
            "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
            "used_tools": used_tools,
            "session_id": session_id,
        }
    }
    
    return result


def run_ai_bomi_from_audio(
    audio_bytes: bytes,
    session_id: Optional[str] = None
) -> dict[str, Any]:
    """
    ìŒì„± ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    ì „ì²´ í”Œë¡œìš°:
    1. STT ì—”ì§„ í˜¸ì¶œ (adapters.stt_adapter.run_speech_to_text)
    2. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ëœ ê²°ê³¼ë¥¼ run_ai_bomi_from_text(...)ì— ìœ„ì„
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°ì´í„° (ë°”ì´íŠ¸ì—´)
        session_id: ì„¸ì…˜ ID (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    # 1. STT ì‹¤í–‰
    print(f"\nğŸ¤ 3-3 STT ì‹¤í–‰ ì¤‘...")
    user_text = run_speech_to_text(audio_bytes)
    print(f"âœ… 3-3 STT ì™„ë£Œ: {user_text}")
    
    # 2. í…ìŠ¤íŠ¸ ì…ë ¥ í•¨ìˆ˜ì— ìœ„ì„
    result = run_ai_bomi_from_text(user_text, session_id)
    
    # used_toolsì— speech_to_text ì¶”ê°€
    result["meta"]["used_tools"].insert(0, "speech_to_text")
    
    return result


# ============================================================================
# 5. í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("ë§ˆìŒë´„ - LangChain Agent v1.0 í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ ì…ë ¥
    print("\n\n[í…ŒìŠ¤íŠ¸ 1] í…ìŠ¤íŠ¸ ì…ë ¥ - ê¸ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_1 = "ì•„ì¹¨ì— ëˆˆì„ ëœ¨ì í–‡ì‚´ì´ ë°© ì•ˆì„ ê°€ë“ ì±„ìš°ê³  ìˆì—ˆê³ , ì˜¤ëœë§Œì— ìƒì¾Œí•œ ê¸°ë¶„ì´ ë“¤ì–´ ë”°ëœ»í•œ ì»¤í”¼ë¥¼ í•œ ì” ë“¤ê³  ì—¬ìœ ë¡­ê²Œ ì§‘ì„ ë‚˜ì„¤ ìˆ˜ ìˆì—ˆë‹¤."
    
    result_1 = run_ai_bomi_from_text(test_text_1, session_id="test_session_1")
    
    print(f"\nğŸ“ ì…ë ¥: {result_1['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_1['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_1['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_1['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_1['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_1['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_1['emotion_result']['service_signals']['risk_level']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_1['meta']['used_tools']}")
    print(f"ğŸ¤– ëª¨ë¸: {result_1['meta']['model']}")
    
    # í…ŒìŠ¤íŠ¸ 2: í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •
    print("\n\n[í…ŒìŠ¤íŠ¸ 2] í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_2 = "ì˜¤ëŠ˜ í•˜ë£¨ ì •ë§ í˜ë“¤ì—ˆì–´ìš”. ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ê³  ê¸°ìš´ì´ ì—†ë„¤ìš”."
    
    result_2 = run_ai_bomi_from_text(test_text_2, session_id="test_session_2")
    
    print(f"\nğŸ“ ì…ë ¥: {result_2['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_2['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_2['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_2['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_2['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_2['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_2['emotion_result']['service_signals']['risk_level']}")
    print(f"  - ì¶”ì²œ ë£¨í‹´: {result_2['emotion_result']['recommended_routine_tags']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_2['meta']['used_tools']}")
    
    # í…ŒìŠ¤íŠ¸ 3: ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°”ì´íŠ¸)
    print("\n\n[í…ŒìŠ¤íŠ¸ 3] ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°ì´í„°)")
    print("-" * 80)
    
    dummy_audio = b"dummy audio bytes for testing"
    
    result_3 = run_ai_bomi_from_audio(dummy_audio, session_id="test_session_3")
    
    print(f"\nğŸ“ ì…ë ¥ (3-3 STT ê²°ê³¼): {result_3['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_3['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_3['emotion_result']['primary_emotion']['name_ko']}")
    print(f"  - ì „ì²´ ê°ì •: {result_3['emotion_result']['sentiment_overall']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_3['meta']['used_tools']}")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸
    print("\n\n[ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸]")
    print("-" * 80)
    
    store = get_conversation_store()
    history = store.get_history("test_session_1")
    print(f"\ntest_session_1ì˜ ëŒ€í™” ê°œìˆ˜: {len(history)}")
    for i, msg in enumerate(history, 1):
        print(f"{i}. [{msg['role']}] {msg['content'][:50]}...")
    
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)

