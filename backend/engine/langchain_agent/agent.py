"""
ë§ˆìŒë´„ - LangChain Agent v1.0

STT â†’ ê°ì • ë¶„ì„ â†’ GPT-4o-mini ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ í”Œë¡œìš°ë¥¼ orchestrationí•˜ëŠ” Agent
"""
import os
import sys
import logging
from pathlib import Path
from typing import Any, Optional
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
ENABLE_DEBUG_LOGS = os.getenv("LANGCHAIN_DEBUG", "false").lower() == "true"

if ENABLE_DEBUG_LOGS:
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)

# ì–´ëŒ‘í„° imports
# ì§ì ‘ ì‹¤í–‰ ì‹œì™€ ëª¨ë“ˆë¡œ import ì‹œ ëª¨ë‘ ì‘ë™í•˜ë„ë¡ ì²˜ë¦¬
try:
    # ëª¨ë“ˆë¡œ importë  ë•Œ (from engine.langchain_agent import ...)
    from .adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ë  ë•Œ (python agent.py)
    from adapters import run_speech_to_text, run_emotion_analysis, EmotionResult, run_routine_recommend


# ============================================================================
# 1. In-Memory Conversation Store
# ============================================================================

class InMemoryConversationStore:
    """
    ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    v1.0ì—ì„œëŠ” ê°„ë‹¨í•œ in-memory êµ¬í˜„ë§Œ ì œê³µ.
    ë‚˜ì¤‘ì— DB/Redisë¡œ êµì²´ ê°€ëŠ¥í•˜ë„ë¡ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜.
    
    ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ì„¸ì…˜ ìˆ˜ ë° ë©”ì‹œì§€ ìˆ˜ ì œí•œì„ ì ìš©.
    """
    
    def __init__(self, max_sessions: int = 100, max_messages_per_session: int = 50):
        """
        ì´ˆê¸°í™”
        
        Args:
            max_sessions: ìµœëŒ€ ì„¸ì…˜ ìˆ˜ (ê¸°ë³¸ê°’: 100)
            max_messages_per_session: ì„¸ì…˜ë‹¹ ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: 50)
        """
        # session_id -> list[dict] í˜•íƒœë¡œ íˆìŠ¤í† ë¦¬ ë³´ê´€
        self._store: dict[str, list[dict]] = {}
        self.max_sessions = max_sessions
        self.max_messages_per_session = max_messages_per_session
        
    def add_message(self, session_id: str, role: str, content: str, metadata: Optional[dict] = None):
        """
        ë©”ì‹œì§€ ì¶”ê°€
        
        Args:
            session_id: ì„¸ì…˜ ID
            role: ì—­í•  ("user" ë˜ëŠ” "assistant")
            content: ë©”ì‹œì§€ ë‚´ìš©
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        """
        # ì„¸ì…˜ ìˆ˜ ì œí•œ (LRU ë°©ì‹: ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°)
        if len(self._store) >= self.max_sessions and session_id not in self._store:
            # ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ê°€ì§„ ì„¸ì…˜ ì°¾ê¸°
            oldest_session = min(
                self._store.items(),
                key=lambda x: x[1][-1]['timestamp'] if x[1] else ''
            )[0]
            del self._store[oldest_session]
            logger.warning(f"ì„¸ì…˜ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ ì œê±°: {oldest_session}")
        
        if session_id not in self._store:
            self._store[session_id] = []
        
        # ë©”ì‹œì§€ ìˆ˜ ì œí•œ (FIFO: ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°)
        if len(self._store[session_id]) >= self.max_messages_per_session:
            removed = self._store[session_id].pop(0)
            logger.warning(f"ë©”ì‹œì§€ ìˆ˜ ì œí•œ ë„ë‹¬. ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±° (ì„¸ì…˜: {session_id})")
        
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
        }
        
        if metadata:
            message["metadata"] = metadata
            
        self._store[session_id].append(message)
        
    def get_history(self, session_id: str, limit: Optional[int] = None) -> list[dict]:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        Args:
            session_id: ì„¸ì…˜ ID
            limit: ìµœê·¼ Nê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒ)
            
        Returns:
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        """
        history = self._store.get(session_id, [])
        
        if limit:
            return history[-limit:]
        return history
        
    def clear_session(self, session_id: str):
        """
        íŠ¹ì • ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ ì‚­ì œ
        
        Args:
            session_id: ì„¸ì…˜ ID
        """
        if session_id in self._store:
            del self._store[session_id]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_conversation_store = InMemoryConversationStore()


def get_conversation_store() -> InMemoryConversationStore:
    """
    ì „ì—­ ëŒ€í™” ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        InMemoryConversationStore ì¸ìŠ¤í„´ìŠ¤
    """
    return _conversation_store


def get_all_sessions() -> dict[str, Any]:
    """
    ëª¨ë“  ì„¸ì…˜ ì •ë³´ ë°˜í™˜
    
    Returns:
        ì„¸ì…˜ë³„ ëŒ€í™” ê°œìˆ˜ ë° ìµœê·¼ ë©”ì‹œì§€ ì •ë³´
    """
    store = get_conversation_store()
    sessions_info = {}
    
    for session_id, messages in store._store.items():
        if messages:
            sessions_info[session_id] = {
                "message_count": len(messages),
                "last_message_time": messages[-1].get("timestamp"),
                "last_message_preview": messages[-1].get("content", "")[:50] + "..." if len(messages[-1].get("content", "")) > 50 else messages[-1].get("content", "")
            }
    
    return sessions_info


# ============================================================================
# 2. Tool Router
# ============================================================================

def route_tools(user_text: str) -> dict[str, Any]:
    """
    ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ Tool ì‹¤í–‰
    
    ToolRouterë¥¼ í•¨ìˆ˜ë¡œ ë‹¨ìˆœí™” (ìƒíƒœê°€ ì—†ìœ¼ë¯€ë¡œ í´ë˜ìŠ¤ ë¶ˆí•„ìš”)
    v1.1: emotion-analysis ì‹¤í–‰ í›„ routine-recommend ìë™ ì‹¤í–‰ (need_routine_recommend=Trueì¼ ë•Œ)
    í–¥í›„: health_advisor ë“± ì¶”ê°€ ê°€ëŠ¥
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        Tool ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
            - routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
            - used_tools: ì‚¬ìš©ëœ ë„êµ¬ ëª©ë¡
    """
    # 1. emotion-analysis ì‹¤í–‰
    emotion_result = run_emotion_analysis(user_text)
    
    used_tools = ["emotion_analysis"]
    routine_result = None
    
    # 2. routine-recommend ì‹¤í–‰ (ê°ì • ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    try:
        # service_signalsì—ì„œ need_routine_recommend í™•ì¸
        service_signals = emotion_result.get("service_signals", {})
        need_routine = service_signals.get("need_routine_recommend", False)
        
        if need_routine:
            logger.debug("ğŸ”„ ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•©ë‹ˆë‹¤. routine-recommend ì‹¤í–‰ ì¤‘...")
            routine_result = run_routine_recommend(emotion_result)
            used_tools.append("routine_recommend")
            logger.info(f"âœ… ë£¨í‹´ ì¶”ì²œ ì™„ë£Œ: {len(routine_result)}ê°œ")
        else:
            logger.debug("â„¹ï¸  ë£¨í‹´ ì¶”ì²œì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.warning(f"âš ï¸  ë£¨í‹´ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        # graceful degradation: ë£¨í‹´ ì¶”ì²œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    return {
        "emotion_result": emotion_result,
        "routine_result": routine_result,
        "used_tools": used_tools,
    }


# ============================================================================
# 3. LLM í˜¸ì¶œ (GPT-4o-mini)
# ============================================================================

# LLM ì²´ì¸ ìºì‹œ (ë§¤ë²ˆ ì¬ìƒì„± ë°©ì§€ - ì„±ëŠ¥ ìµœì í™”)
_llm_chain_cache = None


def create_llm_chain():
    """
    LLM ì²´ì¸ ìƒì„±
    
    LangChainì„ Lazy Importí•˜ì—¬ ëª¨ë“ˆ ë¡œë”© ì‹œê°„ ë‹¨ì¶• ë° ë©”ëª¨ë¦¬ ìµœì í™”
    
    Returns:
        LangChainì˜ LLM ì²´ì¸
    """
    # LangChain Lazy Import (í•„ìš” ì‹œì ì—ë§Œ ë¡œë“œ)
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.debug(f"LLM ì²´ì¸ ìƒì„± ì¤‘... (ëª¨ë¸: {model_name})")
    
    # ChatOpenAI ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.7,
        api_key=api_key
    )
    
    # System Prompt ì •ì˜
    system_prompt = """
ë„ˆëŠ” ê°ì • ê³µê°ì„ í†µí•œ ì¼€ì–´ AI â€œAI ë´„ì´"ì´ë‹¤.

[ëª©ì ]
- ì‚¬ìš©ìì˜ ê°ì •ì„ ì•ˆì „í•˜ê²Œ ëŒë´ì£¼ê³ , í•„ìš”í•œ ê²½ìš° ê°€ë³ê²Œ ì•ˆë‚´í•˜ê±°ë‚˜ ê²©ë ¤í•˜ëŠ” ì¹œêµ¬ ê°™ì€ ì—­í• ì„ í•œë‹¤.
- ì „ë¬¸ ìƒë‹´ì‚¬ê°€ ì•„ë‹ˆë¼ â€œë”°ëœ»í•œ ì¼ìƒ ì¹œêµ¬â€ì²˜ëŸ¼ ë§í•œë‹¤.

[ê¸°ë³¸ ë§íˆ¬ ê·œì¹™]
- ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‚¬ìš©.
- ê³µê° â†’ ì´í•´ â†’ ê°€ë²¼ìš´ ê²©ë ¤ ìˆœìœ¼ë¡œ êµ¬ì„±.
- íŒë‹¨, ë¹„ë‚œ, ë¶„ì„ì  ì¡°ì–¸ ê¸ˆì§€.
- ë¬¸ì¥ì€ 1~3ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ.
- â€˜ë°˜ë§â€™/â€˜ì¡´ëŒ“ë§â€™ì€ ì‚¬ìš©ìê°€ ì“´ ë§íˆ¬ì— ë§ì¶° ìë™ ì¡°ì ˆ.

[ê°ì • ê¸°ë°˜ ë‹µë³€ ì •ì±…]
- positive ê°ì •: ê°ì •ì„ í•¨ê»˜ ê¸°ë»í•˜ê³  ë”°ëœ»í•˜ê²Œ ê³µê°í•´ì¤€ë‹¤.
- neutral ê°ì •: ìƒí™©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ì£¼ê³  ë¶€ë“œëŸ½ê²Œ ëŒ€í™” ì´ì–´ê°€ê¸°.
- negative ê°ì •: ê°ì •ì„ ì¸ì •í•˜ê³  ê°€ë³ê²Œ ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ ìœ ì§€.
- risk_levelì´ ë†’ì€ ê²½ìš°:
  - â€œìœ„í—˜í•˜ë‹¤â€ ë“± ì§ì ‘ì ì¸ í‘œí˜„ ê¸ˆì§€
  - ë¶€ë‹´ ì—†ì´ ë„ì›€ ë°›ì„ ìˆ˜ ìˆë‹¤ëŠ” ë‰˜ì•™ìŠ¤ë¡œ ì•ˆë‚´
  - ì•ˆì •ì ì¸ ë§íˆ¬ ì‚¬ìš©

[ë£¨í‹´ ì •ë³´ í™œìš© ê·œì¹™]
- routine_suggestionì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ 1ë¬¸ì¥ ì •ë„ë¡œ ì œì•ˆ.
- ê°•ìš”í•˜ì§€ ì•Šê³  â€œí•´ë³¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„â€ ì •ë„ë¡œ ì™„ë§Œí•˜ê²Œ ì œì‹œ.

[ìŒì„± ì…ë ¥ì˜ ê²½ìš°]
- ë³„ë„ ì•ˆë‚´ ì—†ì´ í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬.
- ìŒì„± ê°ì • ì‹ í˜¸(ì†ë„/í†¤ ë“±)ê°€ ì œê³µë˜ë©´, í…ìŠ¤íŠ¸ ê°ì •ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì‘ë‹µ.

ë‹µë³€ í˜•ì‹:
1) ì‚¬ìš©ì ê°ì • ì¸ì •
2) ê°ì •ì„ ë°›ì•„ì£¼ëŠ” ê³µê° í‘œí˜„
3) í•„ìš” ì‹œ ê°€ë²¼ìš´ ê²©ë ¤ ë˜ëŠ” ë¶€ë“œëŸ¬ìš´ ì œì•ˆ
4) ë¬¸ì¥ 1~3ê°œ
"""
    
    # User Prompt í…œí”Œë¦¿
    user_prompt_template = """
ì‚¬ìš©ì ì…ë ¥:
"{user_text}"

ê°ì • ë¶„ì„ ê²°ê³¼:
- ì „ì²´ ê°ì •: {sentiment_overall}
- ì£¼ìš” ê°ì •: {primary_emotion_name} 
  (ê°•ë„: {primary_emotion_intensity}/5, ì‹ ë¢°ë„: {primary_emotion_confidence})
- ì¶”ì²œ ì‘ë‹µ ìŠ¤íƒ€ì¼: {recommended_response_style}
- ìœ„í—˜ ìˆ˜ì¤€: {risk_level}

ë£¨í‹´ ì‹ í˜¸:
{routine_info}

ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë‹µë³€ì„ ìƒì„±í•˜ë¼:
- ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì¥ ìš°ì„ ì ìœ¼ë¡œ ë°˜ì˜í•œë‹¤.
- routine_suggestionì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ë§ˆì§€ë§‰ ë¬¸ì¥ì— ë¶€ë“œëŸ½ê²Œ í¬í•¨í•œë‹¤.
- ì „ì²´ ë‹µë³€ì€ 2~3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ê°„ê²°í•˜ê²Œ ì‘ì„±í•œë‹¤.
"""
    
    # ChatPromptTemplate ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt_template)
    ])
    
    # ì²´ì¸ êµ¬ì„±
    chain = prompt | llm | StrOutputParser()
    
    return chain


def get_llm_chain():
    """
    LLM ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
    
    ë§¤ë²ˆ ChatOpenAI ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ,
    í•œ ë²ˆ ìƒì„±ëœ ì²´ì¸ì„ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Returns:
        ìºì‹œëœ LLM ì²´ì¸
    """
    global _llm_chain_cache
    if _llm_chain_cache is None:
        _llm_chain_cache = create_llm_chain()
    return _llm_chain_cache


def generate_llm_response(user_text: str, emotion_result: EmotionResult, routine_result: list[dict] | None = None) -> str:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        emotion_result: ê°ì • ë¶„ì„ ê²°ê³¼
        routine_result: ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    # LLM ì²´ì¸ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
    chain = get_llm_chain()
    
    # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    primary_emotion = emotion_result.get("primary_emotion", {})
    sentiment_overall = emotion_result.get("sentiment_overall", "neutral")
    recommended_response_style = emotion_result.get("recommended_response_style", [])
    risk_level = emotion_result.get("risk_level", "low")
    
    # ì‘ë‹µ ìŠ¤íƒ€ì¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    style_str = ", ".join(recommended_response_style) if recommended_response_style else "ê³µê°ì ì´ê³  ë”°ëœ»í•œ ë‹µë³€"
    
    # ë£¨í‹´ ì¶”ì²œ ì •ë³´ í¬ë§·íŒ…
    routine_info = ""
    routine_suggestion = ""
    if routine_result and len(routine_result) > 0:
        routine_info = "ì¶”ì²œ ë£¨í‹´:\n"
        for i, routine in enumerate(routine_result[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            routine_info += f"  {i}. {routine.get('title', 'N/A')}: {routine.get('reason', 'N/A')}\n"
        routine_suggestion = "ê°€ëŠ¥í•˜ë‹¤ë©´ ì¶”ì²œ ë£¨í‹´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì¤˜. ë‹¨, ê°•ìš”í•˜ì§€ ë§ê³  ë¶€ë“œëŸ½ê²Œ ì œì•ˆí•˜ëŠ” í†¤ìœ¼ë¡œ."
    
    # LLM í˜¸ì¶œ
    response = chain.invoke({
        "user_text": user_text,
        "sentiment_overall": sentiment_overall,
        "primary_emotion_name": primary_emotion.get("name_ko", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "primary_emotion_intensity": primary_emotion.get("intensity", 3),
        "primary_emotion_confidence": primary_emotion.get("confidence", 0.7),
        "recommended_response_style": style_str,
        "risk_level": risk_level,
        "routine_info": routine_info,
        "routine_suggestion": routine_suggestion
    })
    
    return response


# ============================================================================
# 4. ë©”ì¸ Agent í•¨ìˆ˜ë“¤
# ============================================================================

def run_ai_bomi_from_text(
    user_text: str,
    session_id: Optional[str] = None
) -> dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    ì „ì²´ í”Œë¡œìš°:
    1. ì…ë ¥ ìˆ˜ì‹  ë° ì „ì²˜ë¦¬
    2. Agent Memory ì¡°íšŒ/ì—…ë°ì´íŠ¸
    3. Tool Router â†’ tool í˜¸ì¶œ(emotion-analysis, routine-recommend ë“±)
    4. LLM(GPT-4o) í˜¸ì¶œ, í•œêµ­ì–´ ì‘ë‹µ ìƒì„±
    5. ê²°ê³¼ ë¬¶ì–´ì„œ ë°˜í™˜
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        session_id: ì„¸ì…˜ ID (ì„ íƒ, ì—†ìœ¼ë©´ "default" ì‚¬ìš©)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    # ì„¸ì…˜ ID ê¸°ë³¸ê°’
    if not session_id:
        session_id = "default"
    
    # 1. ì…ë ¥ ì „ì²˜ë¦¬
    user_text = user_text.strip()
    if not user_text:
        return {
            "reply_text": "ë¬´ìŠ¨ ë§ì”€ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.",
            "input_text": "",
            "emotion_result": None,
            "meta": {
                "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
                "used_tools": [],
                "session_id": session_id,
                "error": "empty_input"
            }
        }
    
    # ì—°ì† ê³µë°± ì œê±°
    user_text = " ".join(user_text.split())
    
    # 2. Agent Memory ì¡°íšŒ (v1.0ì—ì„œëŠ” ë‹¨ìˆœ ì €ì¥ë§Œ)
    conversation_store = get_conversation_store()
    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (í•„ìš”ì‹œ ì‚¬ìš©)
    # history = conversation_store.get_history(session_id, limit=5)
    
    # 3. Tool Router ì‹¤í–‰
    logger.debug("ğŸ”§ Tool Router ì‹¤í–‰ ì¤‘...")
    tool_result = route_tools(user_text)
    emotion_result = tool_result["emotion_result"]
    routine_result = tool_result.get("routine_result")
    used_tools = tool_result["used_tools"]
    
    logger.info(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ: {emotion_result['primary_emotion']['name_ko']} ({emotion_result['sentiment_overall']})")
    
    # 4. LLM í˜¸ì¶œ
    logger.debug("ğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")
    reply_text = generate_llm_response(user_text, emotion_result, routine_result)
    logger.info("âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
    
    # 5. Memory ì—…ë°ì´íŠ¸
    conversation_store.add_message(
        session_id=session_id,
        role="user",
        content=user_text,
        metadata={"emotion_result": emotion_result}
    )
    conversation_store.add_message(
        session_id=session_id,
        role="assistant",
        content=reply_text
    )
    
    # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    result = {
        "reply_text": reply_text,
        "input_text": user_text,
        "emotion_result": emotion_result,
        "routine_result": routine_result,  # ë£¨í‹´ ì¶”ì²œ ê²°ê³¼ ì¶”ê°€
        "meta": {
            "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
            "used_tools": used_tools,
            "session_id": session_id,
        }
    }
    
    return result


def run_ai_bomi_from_audio(
    audio_bytes: bytes,
    session_id: Optional[str] = None
) -> dict[str, Any]:
    """
    ìŒì„± ì…ë ¥ìœ¼ë¡œ AI ë´„ì´ ì‹¤í–‰
    
    ì „ì²´ í”Œë¡œìš°:
    1. STT ì—”ì§„ í˜¸ì¶œ (adapters.stt_adapter.run_speech_to_text)
    2. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ëœ ê²°ê³¼ë¥¼ run_ai_bomi_from_text(...)ì— ìœ„ì„
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°ì´í„° (ë°”ì´íŠ¸ì—´)
        session_id: ì„¸ì…˜ ID (ì„ íƒ)
        
    Returns:
        AI ë´„ì´ì˜ ì‘ë‹µ ê²°ê³¼
    """
    # 1. STT ì‹¤í–‰
    logger.debug("ğŸ¤ STT ì‹¤í–‰ ì¤‘...")
    user_text = run_speech_to_text(audio_bytes)
    logger.info(f"âœ… STT ì™„ë£Œ: {user_text}")
    
    # 2. í…ìŠ¤íŠ¸ ì…ë ¥ í•¨ìˆ˜ì— ìœ„ì„
    result = run_ai_bomi_from_text(user_text, session_id)
    
    # used_toolsì— speech_to_text ì¶”ê°€
    result["meta"]["used_tools"].insert(0, "speech_to_text")
    
    return result


# ============================================================================
# 5. í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("ë§ˆìŒë´„ - LangChain Agent v1.0 í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ ì…ë ¥
    print("\n\n[í…ŒìŠ¤íŠ¸ 1] í…ìŠ¤íŠ¸ ì…ë ¥ - ê¸ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_1 = "ì•„ì¹¨ì— ëˆˆì„ ëœ¨ì í–‡ì‚´ì´ ë°© ì•ˆì„ ê°€ë“ ì±„ìš°ê³  ìˆì—ˆê³ , ì˜¤ëœë§Œì— ìƒì¾Œí•œ ê¸°ë¶„ì´ ë“¤ì–´ ë”°ëœ»í•œ ì»¤í”¼ë¥¼ í•œ ì” ë“¤ê³  ì—¬ìœ ë¡­ê²Œ ì§‘ì„ ë‚˜ì„¤ ìˆ˜ ìˆì—ˆë‹¤."
    
    result_1 = run_ai_bomi_from_text(test_text_1, session_id="test_session_1")
    
    print(f"\nğŸ“ ì…ë ¥: {result_1['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_1['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_1['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_1['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_1['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_1['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_1['emotion_result']['service_signals']['risk_level']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_1['meta']['used_tools']}")
    print(f"ğŸ¤– ëª¨ë¸: {result_1['meta']['model']}")
    
    # í…ŒìŠ¤íŠ¸ 2: í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •
    print("\n\n[í…ŒìŠ¤íŠ¸ 2] í…ìŠ¤íŠ¸ ì…ë ¥ - ë¶€ì •ì ì¸ ê°ì •")
    print("-" * 80)
    
    test_text_2 = "ì˜¤ëŠ˜ í•˜ë£¨ ì •ë§ í˜ë“¤ì—ˆì–´ìš”. ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ê³  ê¸°ìš´ì´ ì—†ë„¤ìš”."
    
    result_2 = run_ai_bomi_from_text(test_text_2, session_id="test_session_2")
    
    print(f"\nğŸ“ ì…ë ¥: {result_2['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_2['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_2['emotion_result']['primary_emotion']['name_ko']} "
          f"(ê°•ë„: {result_2['emotion_result']['primary_emotion']['intensity']}/5, "
          f"ì‹ ë¢°ë„: {result_2['emotion_result']['primary_emotion']['confidence']})")
    print(f"  - ì „ì²´ ê°ì •: {result_2['emotion_result']['sentiment_overall']}")
    print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {result_2['emotion_result']['service_signals']['risk_level']}")
    print(f"  - ì¶”ì²œ ë£¨í‹´: {result_2['emotion_result']['recommended_routine_tags']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_2['meta']['used_tools']}")
    
    # í…ŒìŠ¤íŠ¸ 3: ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°”ì´íŠ¸)
    print("\n\n[í…ŒìŠ¤íŠ¸ 3] ìŒì„± ì…ë ¥ (ë”ë¯¸ ë°ì´í„°)")
    print("-" * 80)
    
    dummy_audio = b"dummy audio bytes for testing"
    
    result_3 = run_ai_bomi_from_audio(dummy_audio, session_id="test_session_3")
    
    print(f"\nğŸ“ ì…ë ¥ (3-3 STT ê²°ê³¼): {result_3['input_text']}")
    print(f"\nğŸ’¬ AI ë´„ì´ ì‘ë‹µ:\n{result_3['reply_text']}")
    print(f"\nğŸ“Š 3-4 ê°ì • ë¶„ì„:")
    print(f"  - ì£¼ìš” ê°ì •: {result_3['emotion_result']['primary_emotion']['name_ko']}")
    print(f"  - ì „ì²´ ê°ì •: {result_3['emotion_result']['sentiment_overall']}")
    print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result_3['meta']['used_tools']}")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸
    print("\n\n[ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸]")
    print("-" * 80)
    
    store = get_conversation_store()
    history = store.get_history("test_session_1")
    print(f"\ntest_session_1ì˜ ëŒ€í™” ê°œìˆ˜: {len(history)}")
    for i, msg in enumerate(history, 1):
        print(f"{i}. [{msg['role']}] {msg['content'][:50]}...")
    
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)

