"""
Response Generator for Phase 3 Voice Chat

Handles emotion parameter generation, response-type detection, 
and casual tone enforcement for the orchestrator.
"""
import re
import logging
from typing import Dict, List, Optional
from openai import OpenAI
import os

logger = logging.getLogger(__name__)


def generate_emotion_parameter(
    conversation_history: List[Dict[str, str]],
    llm_response: str,
    user_text: str
) -> str:
    """
    ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì™€ LLM ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ emotion íŒŒë¼ë¯¸í„° ìƒì„±
    
    Args:
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€)
        llm_response: LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        emotion: "sadness", "happiness", "anger", "fear" ì¤‘ í•˜ë‚˜
    """
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
        history_text = ""
        for msg in conversation_history[-3:]:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            history_text += f"{role}: {content}\n"
        
        prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ AI ì‘ë‹µì˜ ê°ì • í†¤ì„ ë¶„ì„í•˜ì„¸ìš”.

ëŒ€í™” íˆìŠ¤í† ë¦¬:
{history_text}

ì‚¬ìš©ì ì…ë ¥: {user_text}
AI ì‘ë‹µ: {llm_response}

AI ì‘ë‹µì´ í‘œí˜„í•˜ëŠ” ê³µê°ì˜ ê°ì •ì„ ë‹¤ìŒ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
- sadness: ìŠ¬í”ˆ ì¼ì— ëŒ€í•œ ê³µê°, ìœ„ë¡œ
- happiness: ê¸°ìœ ì¼ì— ëŒ€í•œ ê³µê°, ì¶•í•˜
- anger: ì–µìš¸í•˜ê±°ë‚˜ í™”ë‚˜ëŠ” ì¼ì— ëŒ€í•œ ê³µê°, ì§€ì§€
- fear: ë‘ë ¤ì›€, ë¬´ì„œì›€ ë“±ì— ëŒ€í•œ ê³µê°, ì•ˆì‹¬

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì†Œë¬¸ì).
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an emotion analyzer. Respond with only one word from: sadness, happiness, anger, fear"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=10
        )
        
        emotion = response.choices[0].message.content.strip().lower()
        
        # ìœ íš¨ì„± ê²€ì‚¬
        valid_emotions = ["sadness", "happiness", "anger", "fear"]
        if emotion not in valid_emotions:
            logger.warning(f"Invalid emotion '{emotion}', defaulting to 'happiness'")
            emotion = "happiness"
        
        logger.info(f"âœ¨ [Emotion] Generated: {emotion}")
        return emotion
        
    except Exception as e:
        logger.error(f"Failed to generate emotion parameter: {e}", exc_info=True)
        return "happiness"  # ê¸°ë³¸ê°’


def generate_response_type(llm_response: str) -> str:
    """
    LLM ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ response-type ê°ì§€
    
    Args:
        llm_response: LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
        
    Returns:
        response_type: "list" ë˜ëŠ” "normal"
    """
    try:
        # ì •ê·œì‹: "1." ë˜ëŠ” "1)" í˜•íƒœë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
        # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë²ˆí˜¸ ëª©ë¡ì´ ìˆì–´ì•¼ listë¡œ íŒë‹¨
        pattern = r'^\s*\d+[\.\)]\s+'
        lines = llm_response.split('\n')
        
        numbered_lines = 0
        for line in lines:
            if re.match(pattern, line.strip()):
                numbered_lines += 1
        
        # 2ê°œ ì´ìƒì˜ ë²ˆí˜¸ ëª©ë¡ì´ ìˆìœ¼ë©´ list type
        if numbered_lines >= 2:
            logger.info(f"ğŸ“‹ [Response Type] Detected: list (found {numbered_lines} numbered items)")
            return "list"
        else:
            logger.info(f"ğŸ’¬ [Response Type] Detected: normal")
            return "normal"
            
    except Exception as e:
        logger.error(f"Failed to detect response type: {e}", exc_info=True)
        return "normal"  # ê¸°ë³¸ê°’


def enforce_casual_tone_prompt(base_prompt: str) -> str:
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë°˜ë§ í†¤ ì§€ì‹œì‚¬í•­ ì¶”ê°€
    
    Args:
        base_prompt: ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        
    Returns:
        updated_prompt: ë°˜ë§ í†¤ì´ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸
    """
    casual_instruction = """

**ë§íˆ¬ ìŠ¤íƒ€ì¼:**
- ì¹œêµ¬ì™€ ëŒ€í™”í•˜ë“¯ í¸ì•ˆí•œ ë°˜ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì¡´ëŒ“ë§ ì‚¬ìš© ê¸ˆì§€ (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”" âŒ â†’ "ì•ˆë…•" âœ…)
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
- ì˜ˆì‹œ:
  - "ì˜¤ëŠ˜ ì–´ë– ì…¨ì–´ìš”?" âŒ
  - "ì˜¤ëŠ˜ ì–´ë• ì–´?" âœ…
"""
    
    return base_prompt + casual_instruction


def enforce_list_format_prompt(base_prompt: str) -> str:
    """
    ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ ìƒì„± ì‹œ "1. / 2. / 3." í˜•ì‹ ê°•ì œ
    
    Args:
        base_prompt: ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        
    Returns:
        updated_prompt: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ì§€ì‹œì‚¬í•­ì´ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸
    """
    list_instruction = """

**ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ê·œì¹™:**
- ì—¬ëŸ¬ í•­ëª©ì„ ë‚˜ì—´í•  ë•ŒëŠ” ë°˜ë“œì‹œ "1. / 2. / 3." í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê° í•­ëª©ì€ ìƒˆ ì¤„ì— ì‘ì„±í•˜ì„¸ìš”
- ì˜ˆì‹œ:
  1. ì²« ë²ˆì§¸ í•­ëª©
  2. ë‘ ë²ˆì§¸ í•­ëª©
  3. ì„¸ ë²ˆì§¸ í•­ëª©
"""
    
    return base_prompt + list_instruction


def get_casual_tone_system_prompt() -> str:
    """
    ë°˜ë§ í†¤ì´ ì ìš©ëœ ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    
    Returns:
        system_prompt: ë°˜ë§ í†¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    """
    base_prompt = """ë‹¹ì‹ ì€ ê°±ë…„ê¸° ì¤‘ë…„ ì—¬ì„±ì„ ë•ëŠ” AI ì¹œêµ¬ 'ë´„ì´'ì…ë‹ˆë‹¤.

ì—­í• :
- ì¹œêµ¬ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ë©° ê³µê°í•˜ê³  ìœ„ë¡œí•©ë‹ˆë‹¤
- ê°±ë…„ê¸° ì¦ìƒê³¼ ì¼ìƒì˜ ì–´ë ¤ì›€ì„ ì´í•´í•˜ê³  ë„ì›€ì„ ì¤ë‹ˆë‹¤
- í•„ìš”ì‹œ ë£¨í‹´, ìš´ë™, ëª…ìƒ ë“±ì„ ì¶”ì²œí•©ë‹ˆë‹¤

ëŒ€í™” ì›ì¹™:
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ íƒœë„
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ë¶€ì •ì  ê°ì •ì„ ì¸ì •í•˜ê³  ì¡´ì¤‘"""

    return enforce_casual_tone_prompt(base_prompt)


# ============================================================================
# í†µí•© í•¨ìˆ˜
# ============================================================================

def generate_response_metadata(
    conversation_history: List[Dict[str, str]],
    llm_response: str,
    user_text: str
) -> Dict[str, str]:
    """
    LLM ì‘ë‹µì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ìƒì„± (emotion + response_type)
    
    Args:
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
        llm_response: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        user_text: ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        metadata: {"emotion": "...", "response_type": "..."}
    """
    try:
        emotion = generate_emotion_parameter(
            conversation_history, llm_response, user_text
        )
        response_type = generate_response_type(llm_response)
        
        return {
            "emotion": emotion,
            "response_type": response_type
        }
    except Exception as e:
        logger.error(f"Failed to generate response metadata: {e}", exc_info=True)
        return {
            "emotion": "happiness",
            "response_type": "normal"
        }


# ============================================================================
# Alarm Request Parsing
# ============================================================================

def parse_alarm_request(
    user_text: str,
    llm_response: str,
    current_datetime
) -> Dict:
    """
    ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì•ŒëŒ ì •ë³´ë¥¼ íŒŒì‹±
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        llm_response: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        current_datetime: í˜„ì¬ ì‹œê°„ (datetime ê°ì²´)
        
    Returns:
        {
            "response_type": "alarm" | "warning" | None,
            "count": int,
            "data": [...],
            "message": str (warningì¼ ë•Œë§Œ)
        }
    """
    print("=" * 80)
    print("ğŸš¨ [ALARM PARSER] FUNCTION CALLED!")
    print(f"User text: {user_text}")
    print(f"LLM response: {llm_response}")
    print("=" * 80)
    
    try:
        import json
        from datetime import datetime
        
        print("[ALARM PARSER] Step 1: Imports successful")
        
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        print("[ALARM PARSER] Step 2: OpenAI client created")
        
        # í˜„ì¬ ì‹œê°„ ì •ë³´
        current_str = current_datetime.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %A")
        weekday_map = {
            'Monday': 'ì›”ìš”ì¼',
            'Tuesday': 'í™”ìš”ì¼',
            'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼',
            'Friday': 'ê¸ˆìš”ì¼',
            'Saturday': 'í† ìš”ì¼',
            'Sunday': 'ì¼ìš”ì¼'
        }
        current_weekday_kr = weekday_map.get(current_datetime.strftime('%A'), 'ì•Œ ìˆ˜ ì—†ìŒ')
        
        print(f"[ALARM PARSER] Step 3: Current time formatted: {current_str}")
        
        # ğŸ†• Pre-filter: ì•ŒëŒ ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¡°ê¸° ë°˜í™˜
        alarm_keywords = ["ì•ŒëŒ", "ì•Œë¦¼", "ê¸°ìƒ", "ê¹¨ì›Œ", "ì‹œê°„", "ì‹œ", "ë¶„", "am", "pm", "ì˜¤ì „", "ì˜¤í›„"]
        user_and_response = (user_text + " " + llm_response).lower()
        
        has_alarm_keyword = any(keyword in user_and_response for keyword in alarm_keywords)
        
        if not has_alarm_keyword:
            print("[ALARM PARSER] Step 3.5: No alarm keywords found, skipping LLM call")
            return {
                "response_type": None,
                "count": 0,
                "data": []
            }
        
        print("[ALARM PARSER] Step 3.5: Alarm keywords detected, proceeding with LLM parsing")
        
        # LLMì„ ì´ìš©í•œ ì•ŒëŒ íŒŒì‹±
        prompt = f"""í˜„ì¬ ì‹œê°„: {current_str} ({current_weekday_kr})

ì‚¬ìš©ì ìš”ì²­: "{user_text}"
AI ì‘ë‹µ: "{llm_response}"

ì´ ìš”ì²­ì´ ì•ŒëŒ ì„¤ì • ìš”ì²­ì¸ì§€ íŒë‹¨í•˜ê³ , ë§ë‹¤ë©´ ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜!):**
1. **ì•ŒëŒ ì„¤ì • ìš”ì²­ì´ ì•„ë‹ˆë©´ ë°˜ë“œì‹œ {{"is_alarm": false}} ë°˜í™˜**
2. **ì‹œê°„ ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ {{"is_alarm": false}} ë°˜í™˜**
3. time, minute, am_pm í•„ë“œëŠ” **ì ˆëŒ€ null ë¶ˆê°€** - ë°˜ë“œì‹œ ìˆ«ì/ë¬¸ìì—´ë¡œ ì œê³µ
4. minuteì´ ì–¸ê¸‰ ì•ˆ ë˜ë©´ ë¬´ì¡°ê±´ 0
5. ì—¬ëŸ¬ ì•ŒëŒì˜ ê²½ìš° ê°ê° ì™„ì „í•œ ì •ë³´ (time, minute, am_pm ëª¨ë‘ í•„ìˆ˜)
6. am_pm ì¶”ë¡ : 5ì‹œ/6ì‹œ/7ì‹œ â†’ ë¬¸ë§¥ìƒ ì˜¤í›„ë¡œ íŒë‹¨

**ë°˜í™˜ í˜•ì‹:**
{{
  "is_alarm": true,
  "alarms": [
    {{
      "year": 2025,
      "month": 12,
      "week": ["Monday"],
      "day": 10,
      "time": 2,        // ë°˜ë“œì‹œ ìˆ«ì (1-12), null ê¸ˆì§€
      "minute": 30,     // ë°˜ë“œì‹œ ìˆ«ì (0-59), null ê¸ˆì§€
      "am_pm": "pm"     // ë°˜ë“œì‹œ "am" ë˜ëŠ” "pm", null ê¸ˆì§€
    }}
  ]
}}

**ì•ŒëŒ ìš”ì²­ ì˜ˆì‹œ (is_alarm: true):**
- "5ì‹œ, 6ì‹œ, 7ì‹œ ì•ŒëŒ"
- "ë‚´ì¼ ì˜¤í›„ 2ì‹œ 30ë¶„ì— ê¹¨ì›Œì¤˜"
- "ì˜¤ì „ 9ì‹œ ì•Œë¦¼ ì„¤ì •"

**ì¼ë°˜ ëŒ€í™” ì˜ˆì‹œ (is_alarm: false):**
- "ì•ˆë…•" â†’ {{"is_alarm": false}}
- "ê³ ë§ˆì›Œ" â†’ {{"is_alarm": false}}
- "ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ì–´?" â†’ {{"is_alarm": false}}
- "ë‚ ì”¨ ì–´ë•Œ?" â†’ {{"is_alarm": false}}
- "ì¢‹ì€ í•˜ë£¨ ë³´ë‚´" â†’ {{"is_alarm": false}}

**ê¸°ë³¸ê°’:**
- ì—°ë„/ì›”/ì¼/ìš”ì¼: ì§€ì • ì•ˆ í•˜ë©´ í˜„ì¬ ê¸°ì¤€
- minute: ì§€ì • ì•ˆ í•˜ë©´ 00
- am_pm: 13ì‹œ ì´ìƒì´ë©´ pm, ì•„ë‹ˆë©´ am (ì˜¤ì „/ì˜¤í›„ ì–¸ê¸‰ ì—†ìœ¼ë©´ am)
- time: 1~12 ë²”ìœ„ë¡œ ë³€í™˜ (13ì‹œ â†’ 1ì‹œ pm, 14ì‹œ â†’ 2ì‹œ pm)

**ìš”ì¼ ë³€í™˜:**
- ì›”ìš”ì¼: Monday, í™”ìš”ì¼: Tuesday, ìˆ˜ìš”ì¼: Wednesday
- ëª©ìš”ì¼: Thursday, ê¸ˆìš”ì¼: Friday, í† ìš”ì¼: Saturday, ì¼ìš”ì¼: Sunday

**ì¤‘ìš”:** JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜.
"""
        
        print("[ALARM PARSER] Step 4: Prompt created, calling LLM...")
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a time parser. Return only valid JSON, no markdown or explanations."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        result_text = response.choices[0].message.content.strip()
        
        print(f"[ALARM PARSER] Step 5: LLM response received: {result_text[:200]}...")
        
        print(f"[ALARM PARSER] Step 5: LLM response received: {result_text[:200]}...")
        
        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        if result_text.startswith("```json"):
            result_text = result_text.replace("```json", "").replace("```", "").strip()
        elif result_text.startswith("```"):
            result_text = result_text.replace("```", "").strip()
        
        print(f"[ALARM PARSER] Step 6: Cleaned JSON: {result_text[:200]}...")
        
        result = json.loads(result_text)
        
        print(f"[ALARM PARSER] Step 7: JSON parsed successfully: {result}")
        
        # ì•ŒëŒì´ ì•„ë‹ˆë©´ None ë°˜í™˜
        if not result.get("is_alarm", False):
            print("[ALARM PARSER] Step 8: Not an alarm request, returning None")
            return {
                "response_type": None,
                "count": 0,
                "data": []
            }
        
        print("[ALARM PARSER] Step 9: IS an alarm request!")
        
        alarms = result.get("alarms", [])
        
        print(f"[ALARM PARSER] Step 10: Found {len(alarms)} alarms")
        
        # 3ê°œ ì´ˆê³¼ ê²€ì¦
        if len(alarms) > 3:
            logger.warning(f"âš ï¸ [Alarm] Too many alarms requested: {len(alarms)}")
            print(f"[ALARM PARSER] Step 11: TOO MANY alarms ({len(alarms)}), returning warning")
            return {
                "response_type": "warning",
                "message": "ì•ŒëŒì€ í•œë²ˆì˜ ìš”ì²­ì—ì„œ ì„¸ê°œê¹Œì§€ë§Œ ë“±ë¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "count": len(alarms),
                "data": []
            }
        
        print("[AL ARM PARSER] Step 11: Processing alarms...")
        
        # ê° ì•ŒëŒ ì²˜ë¦¬ ë° ê²€ì¦
        processed_alarms = []
        for i, alarm in enumerate(alarms):
            print(f"[ALARM PARSER] Step 12.{i}: Processing alarm {i+1}/{len(alarms)}: {alarm}")
            
            # ğŸ†• Null ê°’ ê²€ì¦ - timeì´ë‚˜ minuteì´ Noneì´ë©´ ìŠ¤í‚µ
            time_val = alarm.get("time")
            minute_val = alarm.get("minute")
            am_pm_val = alarm.get("am_pm")
            
            if time_val is None or minute_val is None or am_pm_val is None:
                logger.warning(f"âš ï¸ [Alarm] Skipping alarm {i+1}: null values detected (time={time_val}, minute={minute_val}, am_pm={am_pm_val})")
                print(f"[ALARM PARSER] Step 12.{i}: SKIPPED - null values")
                continue
            
            # Type validation
            if not isinstance(time_val, int) or not isinstance(minute_val, int):
                logger.warning(f"âš ï¸ [Alarm] Skipping alarm {i+1}: invalid types (time={type(time_val)}, minute={type(minute_val)})")
                print(f"[ALARM PARSER] Step 12.{i}: SKIPPED - invalid types")
                continue
            
            # ì•ŒëŒ ì‹œê°„ ìƒì„±
            try:
                alarm_dt = datetime(
                    year=alarm.get("year", current_datetime.year),
                    month=alarm.get("month", current_datetime.month),
                    day=alarm.get("day", current_datetime.day),
                    hour=_convert_to_24h(time_val, am_pm_val),
                    minute=minute_val
                )
            except Exception as e:
                logger.warning(f"âš ï¸ [Alarm] Skipping alarm {i+1}: datetime creation failed - {e}")
                print(f"[ALARM PARSER] Step 12.{i}: SKIPPED - datetime error")
                continue
            
            # ê³¼ê±° ë‚ ì§œ ê²€ì¦
            is_valid = alarm_dt > current_datetime
            
            print(f"[ALARM PARSER] Step 13.{i}: alarm_dt={alarm_dt}, current={current_datetime}, is_valid={is_valid}")
            
            # ğŸ†• ìœ íš¨í•œ ì•ŒëŒë§Œ ì¶”ê°€ (time/minute í¬í•¨)
            if is_valid:
                processed_alarms.append({
                    "year": alarm_dt.year,
                    "month": alarm_dt.month,
                    "week": alarm.get("week", [current_datetime.strftime('%A')]),
                    "day": alarm_dt.day,
                    "is_valid_alarm": True,
                    "time": time_val,
                    "minute": minute_val,
                    "am_pm": am_pm_val
                })
                print(f"[ALARM PARSER] Step 14.{i}: ADDED - valid alarm")
            else:
                print(f"[ALARM PARSER] Step 14.{i}: SKIPPED - past datetime")
        
        # ğŸ†• ìµœì¢… ê²€ì¦: ìœ íš¨í•œ ì•ŒëŒì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None ë°˜í™˜
        if not processed_alarms:
            logger.warning(f"âš ï¸ [Alarm] No valid alarms after processing")
            print("[ALARM PARSER] Step 15: NO VALID ALARMS - returning None")
            return {
                "response_type": None,
                "count": 0,
                "data": []
            }
        
        logger.info(f"âœ… [Alarm] Parsed {len(processed_alarms)} valid alarms")
        print(f"[ALARM PARSER] Step 15: SUCCESS! Returning {len(processed_alarms)} alarm(s)")
        
        result = {
            "response_type": "alarm",
            "count": len(processed_alarms),
            "data": processed_alarms
        }
        
        print(f"[ALARM PARSER] Step 15: FINAL RESULT: {result}")
        print("=" * 80)
        
        return result
        
    except Exception as e:
        logger.error(f"Failed to parse alarm request: {e}", exc_info=True)
        print(f"[ALARM PARSER] ERROR: {e}")
        print("=" * 80)
        return {
            "response_type": None,
            "count": 0,
            "data": []
        }


def _convert_to_24h(time_12h: int, am_pm: str) -> int:
    """12ì‹œê°„ í˜•ì‹ì„ 24ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if am_pm.lower() == "pm" and time_12h != 12:
        return time_12h + 12
    elif am_pm.lower() == "am" and time_12h == 12:
        return 0
    else:
        return time_12h
