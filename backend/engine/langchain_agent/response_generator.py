"""
Response Generator for Phase 3 Voice Chat

Handles emotion parameter generation, response-type detection, 
and casual tone enforcement for the orchestrator.
"""
import re
import logging
from typing import Dict, List, Optional
from openai import OpenAI
import os

logger = logging.getLogger(__name__)


def generate_emotion_parameter(
    conversation_history: List[Dict[str, str]],
    llm_response: str,
    user_text: str
) -> str:
    """
    ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì™€ LLM ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ emotion íŒŒë¼ë¯¸í„° ìƒì„±
    
    Args:
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€)
        llm_response: LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        emotion: "sadness", "happiness", "anger", "fear" ì¤‘ í•˜ë‚˜
    """
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
        history_text = ""
        for msg in conversation_history[-3:]:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            history_text += f"{role}: {content}\n"
        
        prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ AI ì‘ë‹µì˜ ê°ì • í†¤ì„ ë¶„ì„í•˜ì„¸ìš”.

ëŒ€í™” íˆìŠ¤í† ë¦¬:
{history_text}

ì‚¬ìš©ì ì…ë ¥: {user_text}
AI ì‘ë‹µ: {llm_response}

AI ì‘ë‹µì´ í‘œí˜„í•˜ëŠ” ê³µê°ì˜ ê°ì •ì„ ë‹¤ìŒ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
- sadness: ìŠ¬í”ˆ ì¼ì— ëŒ€í•œ ê³µê°, ìœ„ë¡œ
- happiness: ê¸°ìœ ì¼ì— ëŒ€í•œ ê³µê°, ì¶•í•˜
- anger: ì–µìš¸í•˜ê±°ë‚˜ í™”ë‚˜ëŠ” ì¼ì— ëŒ€í•œ ê³µê°, ì§€ì§€
- fear: ë‘ë ¤ì›€, ë¬´ì„œì›€ ë“±ì— ëŒ€í•œ ê³µê°, ì•ˆì‹¬

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì†Œë¬¸ì).
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an emotion analyzer. Respond with only one word from: sadness, happiness, anger, fear"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=10
        )
        
        emotion = response.choices[0].message.content.strip().lower()
        
        # ìœ íš¨ì„± ê²€ì‚¬
        valid_emotions = ["sadness", "happiness", "anger", "fear"]
        if emotion not in valid_emotions:
            logger.warning(f"Invalid emotion '{emotion}', defaulting to 'happiness'")
            emotion = "happiness"
        
        logger.info(f"âœ¨ [Emotion] Generated: {emotion}")
        return emotion
        
    except Exception as e:
        logger.error(f"Failed to generate emotion parameter: {e}", exc_info=True)
        return "happiness"  # ê¸°ë³¸ê°’


def generate_response_type(llm_response: str) -> str:
    """
    LLM ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ response-type ê°ì§€
    
    Args:
        llm_response: LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
        
    Returns:
        response_type: "list" ë˜ëŠ” "normal"
    """
    try:
        # ì •ê·œì‹: "1." ë˜ëŠ” "1)" í˜•íƒœë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
        # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë²ˆí˜¸ ëª©ë¡ì´ ìˆì–´ì•¼ listë¡œ íŒë‹¨
        pattern = r'^\s*\d+[\.\)]\s+'
        lines = llm_response.split('\n')
        
        numbered_lines = 0
        for line in lines:
            if re.match(pattern, line.strip()):
                numbered_lines += 1
        
        # 2ê°œ ì´ìƒì˜ ë²ˆí˜¸ ëª©ë¡ì´ ìˆìœ¼ë©´ list type
        if numbered_lines >= 2:
            logger.info(f"ğŸ“‹ [Response Type] Detected: list (found {numbered_lines} numbered items)")
            return "list"
        else:
            logger.info(f"ğŸ’¬ [Response Type] Detected: normal")
            return "normal"
            
    except Exception as e:
        logger.error(f"Failed to detect response type: {e}", exc_info=True)
        return "normal"  # ê¸°ë³¸ê°’


def enforce_casual_tone_prompt(base_prompt: str) -> str:
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë°˜ë§ í†¤ ì§€ì‹œì‚¬í•­ ì¶”ê°€
    
    Args:
        base_prompt: ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        
    Returns:
        updated_prompt: ë°˜ë§ í†¤ì´ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸
    """
    casual_instruction = """

**ë§íˆ¬ ìŠ¤íƒ€ì¼:**
- ì¹œêµ¬ì™€ ëŒ€í™”í•˜ë“¯ í¸ì•ˆí•œ ë°˜ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì¡´ëŒ“ë§ ì‚¬ìš© ê¸ˆì§€ (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”" âŒ â†’ "ì•ˆë…•" âœ…)
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
- ì˜ˆì‹œ:
  - "ì˜¤ëŠ˜ ì–´ë– ì…¨ì–´ìš”?" âŒ
  - "ì˜¤ëŠ˜ ì–´ë• ì–´?" âœ…
"""
    
    return base_prompt + casual_instruction


def enforce_list_format_prompt(base_prompt: str) -> str:
    """
    ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ ìƒì„± ì‹œ "1. / 2. / 3." í˜•ì‹ ê°•ì œ
    
    Args:
        base_prompt: ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        
    Returns:
        updated_prompt: ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ì§€ì‹œì‚¬í•­ì´ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸
    """
    list_instruction = """

**ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ê·œì¹™:**
- ì—¬ëŸ¬ í•­ëª©ì„ ë‚˜ì—´í•  ë•ŒëŠ” ë°˜ë“œì‹œ "1. / 2. / 3." í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê° í•­ëª©ì€ ìƒˆ ì¤„ì— ì‘ì„±í•˜ì„¸ìš”
- ì˜ˆì‹œ:
  1. ì²« ë²ˆì§¸ í•­ëª©
  2. ë‘ ë²ˆì§¸ í•­ëª©
  3. ì„¸ ë²ˆì§¸ í•­ëª©
"""
    
    return base_prompt + list_instruction


def get_casual_tone_system_prompt() -> str:
    """
    ë°˜ë§ í†¤ì´ ì ìš©ëœ ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    
    Returns:
        system_prompt: ë°˜ë§ í†¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    """
    base_prompt = """ë‹¹ì‹ ì€ ê°±ë…„ê¸° ì¤‘ë…„ ì—¬ì„±ì„ ë•ëŠ” AI ì¹œêµ¬ 'ë´„ì´'ì…ë‹ˆë‹¤.

ì—­í• :
- ì¹œêµ¬ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ë©° ê³µê°í•˜ê³  ìœ„ë¡œí•©ë‹ˆë‹¤
- ê°±ë…„ê¸° ì¦ìƒê³¼ ì¼ìƒì˜ ì–´ë ¤ì›€ì„ ì´í•´í•˜ê³  ë„ì›€ì„ ì¤ë‹ˆë‹¤
- í•„ìš”ì‹œ ë£¨í‹´, ìš´ë™, ëª…ìƒ ë“±ì„ ì¶”ì²œí•©ë‹ˆë‹¤

ëŒ€í™” ì›ì¹™:
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ íƒœë„
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ë¶€ì •ì  ê°ì •ì„ ì¸ì •í•˜ê³  ì¡´ì¤‘"""

    return enforce_casual_tone_prompt(base_prompt)


# ============================================================================
# í†µí•© í•¨ìˆ˜
# ============================================================================

def generate_response_metadata(
    conversation_history: List[Dict[str, str]],
    llm_response: str,
    user_text: str
) -> Dict[str, str]:
    """
    LLM ì‘ë‹µì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ìƒì„± (emotion + response_type)
    
    Args:
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
        llm_response: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        user_text: ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        metadata: {"emotion": "...", "response_type": "..."}
    """
    try:
        emotion = generate_emotion_parameter(
            conversation_history, llm_response, user_text
        )
        response_type = generate_response_type(llm_response)
        
        return {
            "emotion": emotion,
            "response_type": response_type
        }
    except Exception as e:
        logger.error(f"Failed to generate response metadata: {e}", exc_info=True)
        return {
            "emotion": "happiness",
            "response_type": "normal"
        }
