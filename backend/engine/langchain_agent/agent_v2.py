import os
import uuid
import logging
import json
from typing import Any, Optional, List, Dict
from openai import OpenAI

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# Tool Imports
import sys
from pathlib import Path

# Add backend root to sys.path to ensure engine imports work
current_file = Path(__file__).resolve()
backend_root = current_file.parent.parent.parent
if str(backend_root) not in sys.path:
    sys.path.insert(0, str(backend_root))

# Import EmotionAnalyzer (handling hyphen in directory name)
try:
    # Try standard import first (in case it's renamed or aliased)
    from engine.emotion_analysis.src.emotion_analyzer import EmotionAnalyzer
except ImportError:
    # Fallback: Add emotion-analysis/src to sys.path
    emotion_src = backend_root / "engine" / "emotion-analysis" / "src"
    if str(emotion_src) not in sys.path:
        sys.path.insert(0, str(emotion_src))
    try:
        from emotion_analyzer import EmotionAnalyzer
    except ImportError as e:
        logger.error(f"Failed to import EmotionAnalyzer: {e}")
        raise

# Import RoutineRecommendFromEmotionEngine and schemas
try:
    from engine.routine_recommend.engine import RoutineRecommendFromEmotionEngine
    from engine.routine_recommend.models.schemas import EmotionAnalysisResult
except ImportError as e:
    logger.error(f"Failed to import RoutineRecommendFromEmotionEngine or schemas: {e}")
    raise

async def route_tools(user_text: str) -> Dict[str, Any]:
    """
    Analyze text and route to appropriate tools (Emotion, Routine)
    """
    # 1. Emotion Analysis
    analyzer = EmotionAnalyzer()
    emotion_result_dict = analyzer.analyze_emotion(user_text)
    
    # 2. Routine Recommendation
    routine_engine = RoutineRecommendFromEmotionEngine()
    
    # Convert dict to Pydantic model for Routine Engine
    try:
        emotion_model = EmotionAnalysisResult(**emotion_result_dict)
        # recommend is async
        routine_result = await routine_engine.recommend(emotion_model)
    except Exception as e:
        logger.error(f"Routine recommendation failed: {e}")
        routine_result = []
    
    return {
        "emotion_result": emotion_result_dict,
        "routine_result": routine_result,
        "used_tools": ["emotion_analysis", "routine_recommend"]
    }

def generate_llm_response(
    user_text: str,
    emotion_result: Dict[str, Any],
    routine_result: List[Any],
    conversation_history: List[Dict],
    memory_context: str,
    rag_context: str
) -> str:
    """
    Generate response using GPT-4o-mini with all context
    """
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # Construct System Prompt
    # ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½
    emotion_summary = f"{emotion_result.get('polarity', 'neutral')} ({emotion_result.get('cluster_label', 'unknown')})"
    
    system_prompt = f"""ë‹¹ì‹ ì€ ê°±ë…„ê¸° ì—¬ì„±ì„ ìœ„í•œ ê³µê°í˜• AI ì¹œêµ¬ 'ë´„ì´'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°ì •ì— ê¹Šì´ ê³µê°í•˜ê³ , ë”°ëœ»í•œ ìœ„ë¡œì™€ ì‹¤ì§ˆì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

[ì‚¬ìš©ì í”„ë¡œí•„]
- 40~50ëŒ€ ê°±ë…„ê¸° ì—¬ì„±
- ê°ì • ê¸°ë³µì´ ì‹¬í•˜ê³  ì‹ ì²´ì /ì •ì‹ ì  ì–´ë ¤ì›€ì„ ê²ªì„ ìˆ˜ ìˆìŒ

[ëŒ€í™” ì»¨í…ìŠ¤íŠ¸]
{memory_context}
{rag_context}

[ê°ì • ë¶„ì„ ê²°ê³¼]
- ê°ì •: {emotion_summary}
- ìƒì„¸: {json.dumps(emotion_result, ensure_ascii=False)}

[ì¶”ì²œ ë£¨í‹´]
{json.dumps([r.dict() for r in routine_result] if routine_result else [], ensure_ascii=False)}

[ì§€ì¹¨]
1. ê³µê° ìš°ì„ : ì‚¬ìš©ìì˜ ê°ì •ì„ ì½ì–´ì£¼ê³  ê³µê°í•˜ëŠ” ë§ì„ ë¨¼ì € í•˜ì„¸ìš”.
2. ë£¨í‹´ ì œì•ˆ: ì¶”ì²œëœ ë£¨í‹´ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ê¶Œìœ í•˜ì„¸ìš”. (ê°•ìš”í•˜ì§€ ì•ŠìŒ)
3. ì§§ê³  ê°„ê²°í•˜ê²Œ: ë„ˆë¬´ ê¸´ ë‹µë³€ë³´ë‹¤ëŠ” ëŒ€í™”í•˜ë“¯ í¸ì•ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
4. í•œêµ­ì–´ ì‚¬ìš©: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

    messages = [{"role": "system", "content": system_prompt}]
    
    # Add history (limit to last 10 messages to save tokens)
    for msg in conversation_history[-10:]:
        role = "assistant" if msg["role"] == "assistant" else "user"
        messages.append({"role": role, "content": msg["content"]})
        
    # Add current user message
    messages.append({"role": "user", "content": user_text})
    
    response = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
        messages=messages,
        temperature=0.7
    )
    
    return response.choices[0].message.content

async def run_ai_bomi_from_text_v2(
    user_text: str,
    user_id: int,
    session_id: str = "default",
    stt_quality: str = "success",
    speaker_id: Optional[str] = None
) -> dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ ì…ë ¥ ê¸°ë°˜ AI ë´„ì´ ì‹¤í–‰ (V2 - DB ì €ì¥)
    
    Args:
        user_text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        user_id: User ID (for DB storage and data isolation)
        session_id: Session identifier
        stt_quality: STT quality indicator
        speaker_id: Speaker identifier (optional)
    
    Returns:
        Agent response dictionary
    """
    logger.info(f"ğŸš€ [Agent V2] í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ (user_id: {user_id}, session: {session_id})")
    
    # DB ê¸°ë°˜ ì €ì¥ì†Œ ê°€ì ¸ì˜¤ê¸°
    try:
        from .db_conversation_store import get_conversation_store
    except ImportError:
        from db_conversation_store import get_conversation_store
    
    store = get_conversation_store()
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (DBì— ì €ì¥)
    store.add_message(user_id, session_id, "user", user_text, speaker_id=speaker_id)
    
    # 2. Tool Routing (ê°ì • ë¶„ì„ ë“±)
    tool_results = await route_tools(user_text)
    emotion_result = tool_results["emotion_result"]
    routine_result = tool_results["routine_result"]
    
    # 2.5 Save Emotion Analysis
    try:
        store.save_emotion_analysis(user_id, user_text, emotion_result, check_root="conversation")
    except Exception as e:
        logger.error(f"Failed to save emotion analysis: {e}")
    
    # 3. Memory Layer & RAG Context Retrieval (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
    memory_context = ""
    rag_context = ""
    
    try:
        # 3-1. Memory Layer (ì¥ê¸° ê¸°ì–µ) - ì¼ë‹¨ ê¸°ì¡´ JSON ê¸°ë°˜ ì‚¬ìš©
        try:
            from .adapters.memory_adapter import should_store_memory, add_memory, get_memories_for_prompt
        except ImportError:
            from adapters.memory_adapter import should_store_memory, add_memory, get_memories_for_prompt
        
        # ì €ì¥ ì—¬ë¶€ íŒë‹¨ ë° ì €ì¥
        if should_store_memory(user_text, emotion_result):
            add_memory(user_text, emotion_result, session_id, user_id)
            
        # ê´€ë ¨ ê¸°ì–µ ì¡°íšŒ
        memories = get_memories_for_prompt(session_id, user_id)
        if memories:
            memory_context = f"[ê¸°ì–µëœ ì •ë³´]\n{memories}\n"
            
        # 3-2. Conversation RAG (ê³¼ê±° ëŒ€í™”) - V2 ë³µêµ¬
        try:
            from .conversation_rag_v2 import get_conversation_rag
            rag_store = get_conversation_rag()
            
            # í˜„ì¬ ë©”ì‹œì§€ë¥¼ RAGì— ì €ì¥
            rag_store.add_message(user_id, session_id, "user", user_text)
            
            # ê´€ë ¨ ëŒ€í™” ì¡°íšŒ (í˜„ì¬ ì„¸ì…˜ ì œì™¸)
            similar_msgs = rag_store.search_similar(user_id, user_text, session_id, k=3)
            if similar_msgs:
                rag_context = "[ê³¼ê±° ìœ ì‚¬ ëŒ€í™”]\n"
                for msg in similar_msgs:
                    rag_context += f"- {msg['role']}: {msg['content']} (session: {msg['session_id']})\n"
                rag_context += "\n"
                logger.info(f"ğŸ” [RAG] Found {len(similar_msgs)} similar messages")
                
        except Exception as e:
            logger.error(f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
            
    except Exception as e:
        logger.error(f"Memory/RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
    
    # 4. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (DBì—ì„œ ì¡°íšŒ)
    conversation_history = store.get_history(user_id, session_id, limit=None)
    
    # 5. LLM ì‘ë‹µ ìƒì„±
    ai_response_text = generate_llm_response(
        user_text=user_text,
        emotion_result=emotion_result,
        routine_result=routine_result,
        conversation_history=conversation_history,
        memory_context=memory_context,
        rag_context=rag_context
    )
    
    # 6. AI ì‘ë‹µ ì €ì¥ (DBì— ì €ì¥)
    store.add_message(user_id, session_id, "assistant", ai_response_text)
    
    # RAGì—ë„ AI ì‘ë‹µ ì €ì¥ (V2 ë³µêµ¬)
    try:
        if 'rag_store' in locals():
            rag_store.add_message(user_id, session_id, "assistant", ai_response_text)
    except Exception as e:
        logger.error(f"RAG ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    logger.info(f"âœ… [Agent V2] ì‘ë‹µ ìƒì„± ì™„ë£Œ (DB ì €ì¥): {ai_response_text[:50]}...")
    
    return {
        "reply_text": ai_response_text,
        "input_text": user_text,
        "emotion_result": emotion_result,
        "routine_result": routine_result,
        "meta": {
            "model": os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini"),
            "used_tools": tool_results["used_tools"],
            "session_id": session_id,
            "stt_quality": stt_quality,
            "speaker_id": speaker_id,
            "memory_used": bool(memory_context),
            "rag_used": bool(rag_context),
            "user_id": user_id,
            "storage": "database",  # V2 êµ¬ë¶„ì
            "api_version": "v2"
        }
    }


async def run_ai_bomi_from_audio_v2(
    audio_bytes: bytes,
    user_id: int,
    session_id: str = "default"
) -> dict[str, Any]:
    """
    ìŒì„± ì…ë ¥ ê¸°ë°˜ AI ë´„ì´ ì‹¤í–‰ (V2 - DB ì €ì¥)
    
    Args:
        audio_bytes: Audio data
        user_id: User ID (for DB storage)
        session_id: Session identifier
    """
    logger.info(f"ğŸ¤ [Agent V2] ìŒì„± ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ (user_id: {user_id}, session: {session_id})")
    
    # 1. STT ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
    try:
        from .adapters import run_speech_to_text
    except ImportError:
        from adapters import run_speech_to_text
    
    stt_result = run_speech_to_text(audio_bytes)
    user_text = stt_result["text"]
    stt_quality = stt_result["quality"]
    
    # ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì¡°ê¸° ì¢…ë£Œ
    if not user_text:
        return {
            "reply_text": "ì£„ì†¡í•´ìš”, ì˜ ë“¤ë¦¬ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?",
            "input_text": "",
            "emotion_result": None,
            "routine_result": None,
            "meta": {
                "stt_quality": stt_quality,
                "session_id": session_id,
                "user_id": user_id,
                "storage": "database",
                "api_version": "v2"
            }
        }
        
    # 2. í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²˜ë¦¬ë¡œ ìœ„ì„ (V2 í•¨ìˆ˜ ì‚¬ìš©)
    return await run_ai_bomi_from_text_v2(user_text, user_id, session_id, stt_quality)
