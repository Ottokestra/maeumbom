import { useState, useEffect, useRef } from 'react'

function STTTest() {
  const [isRecording, setIsRecording] = useState(false)
  const [isConnected, setIsConnected] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [quality, setQuality] = useState(null)
  const [error, setError] = useState(null)
  
  const wsRef = useRef(null)
  const mediaStreamRef = useRef(null)
  const audioContextRef = useRef(null)
  const processorRef = useRef(null)
  const sourceRef = useRef(null)
  const bufferRef = useRef([])
  const isRecordingRef = useRef(false)

  const SAMPLE_RATE = 16000
  const CHUNK_SIZE = 512

  useEffect(() => {
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      if (wsRef.current) {
        wsRef.current.close()
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop())
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
    }
  }, [])

  const connectWebSocket = () => {
    return new Promise((resolve, reject) => {
      try {
        // Vite í”„ë¡ì‹œë¥¼ í†µí•´ WebSocket ì—°ê²° (HTTPS í˜ì´ì§€ì—ì„œë„ ì‘ë™)
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
        const wsUrl = `${protocol}//${window.location.host}/stt/stream`
        console.log('[STT] WebSocket ì—°ê²° ì‹œë„:', wsUrl)
        const ws = new WebSocket(wsUrl)
        wsRef.current = ws

        ws.onopen = () => {
          console.log('[STT] âœ… WebSocket ì—°ê²° ì„±ê³µ')
          setIsConnected(true)
          setError(null)
          resolve(ws)
        }

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data)
          console.log('[STT] ğŸ“¨ ë©”ì‹œì§€ ìˆ˜ì‹ :', data)
          
          if (data.status === 'ready') {
            console.log('[STT] âœ… STT ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ')
            setError(null)
          } else if (data.status === 'reset') {
            console.log('[STT] ğŸ”„ VAD ë¦¬ì…‹ ì™„ë£Œ')
          } else if (data.error) {
            console.error('[STT] âŒ ì„œë²„ ì˜¤ë¥˜:', data.error)
            setError(`ì„œë²„ ì˜¤ë¥˜: ${data.error}`)
          } else if (data.text !== undefined) {
            // ì¸ì‹ ê²°ê³¼
            console.log('[STT] ğŸ“ ì¸ì‹ ê²°ê³¼:', { text: data.text, quality: data.quality })
            setQuality(data.quality)
            if (data.text) {
              setTranscript(prev => {
                // ì¤‘ë³µ ë°©ì§€ ë° ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°
                const newText = prev && !prev.endsWith(' ') && !data.text.startsWith(' ') 
                  ? prev + ' ' + data.text 
                  : prev + data.text
                console.log('[STT] ğŸ“ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸:', newText)
                return newText
              })
            } else {
              console.log('[STT] âš ï¸ í…ìŠ¤íŠ¸ ì—†ìŒ (í’ˆì§ˆ:', data.quality, ')')
            }
          }
        } catch (err) {
          console.error('[STT] âŒ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', err, 'ì›ë³¸:', event.data)
          setError(`ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: ${err.message}`)
        }
      }

        ws.onerror = (error) => {
          console.error('[STT] âŒ WebSocket ì˜¤ë¥˜:', error)
          setError('WebSocket ì—°ê²° ì˜¤ë¥˜ - ë¸Œë¼ìš°ì € ì½˜ì†”ì„ í™•ì¸í•˜ì„¸ìš”')
          setIsConnected(false)
          reject(error)
        }

        ws.onclose = (event) => {
          console.log('[STT] ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ:', { code: event.code, reason: event.reason, wasClean: event.wasClean })
          setIsConnected(false)
          if (isRecordingRef.current) {
            // ë…¹ìŒ ì¤‘ì´ë©´ ì¬ì—°ê²° ì‹œë„
            console.log('[STT] ğŸ”„ ì¬ì—°ê²° ì‹œë„ ì¤‘...')
            setTimeout(() => {
              if (isRecordingRef.current) {
                connectWebSocket().catch(err => {
                  console.error('[STT] âŒ ì¬ì—°ê²° ì‹¤íŒ¨:', err)
                  setError(`ì¬ì—°ê²° ì‹¤íŒ¨: ${err.message}`)
                })
              }
            }, 1000)
          }
        }
      } catch (err) {
        console.error('[STT] âŒ WebSocket ì—°ê²° ì‹¤íŒ¨:', err)
        setError(`WebSocket ì—°ê²° ì‹¤íŒ¨: ${err.message}`)
        reject(err)
      }
    })
  }

  const startRecording = async () => {
    try {
      console.log('[STT] ğŸ¤ ë…¹ìŒ ì‹œì‘ ì‹œë„...')
      setError(null)
      setTranscript('')
      setQuality(null)

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      console.log('[STT] ğŸ“± ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...')
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: SAMPLE_RATE,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })
      
      console.log('[STT] âœ… ë§ˆì´í¬ ê¶Œí•œ íšë“:', {
        id: stream.id,
        active: stream.active,
        tracks: stream.getTracks().map(t => ({ id: t.id, kind: t.kind, enabled: t.enabled, readyState: t.readyState }))
      })
      
      mediaStreamRef.current = stream

      // WebSocket ì—°ê²° (ì—°ê²° ì™„ë£Œ ëŒ€ê¸°)
      console.log('[STT] ğŸ”Œ WebSocket ì—°ê²° ì¤‘...')
      await connectWebSocket()
      console.log('[STT] âœ… WebSocket ì—°ê²° ì™„ë£Œ')

      // AudioContext ìƒì„±
      console.log('[STT] ğŸµ AudioContext ìƒì„± ì¤‘...')
      const audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: SAMPLE_RATE
      })
      console.log('[STT] âœ… AudioContext ìƒì„± ì™„ë£Œ:', {
        sampleRate: audioContext.sampleRate,
        state: audioContext.state
      })
      audioContextRef.current = audioContext

      // ë§ˆì´í¬ ì…ë ¥ ì†ŒìŠ¤ ìƒì„±
      const source = audioContext.createMediaStreamSource(stream)
      sourceRef.current = source
      console.log('[STT] âœ… ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ìƒì„± ì™„ë£Œ')

      // ScriptProcessorNode ìƒì„± (512 ìƒ˜í”Œ ë²„í¼)
      const processor = audioContext.createScriptProcessor(CHUNK_SIZE, 1, 1)
      processorRef.current = processor

      let chunkCount = 0
      processor.onaudioprocess = (e) => {
        if (!isRecordingRef.current) {
          return
        }

        if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
          if (chunkCount % 100 === 0) { // 100ë²ˆë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ ë¡œê·¸
            console.warn('[STT] âš ï¸ WebSocketì´ ì—´ë ¤ìˆì§€ ì•ŠìŒ:', wsRef.current?.readyState)
          }
          return
        }

        const inputData = e.inputBuffer.getChannelData(0)
        
        // Float32Arrayë¡œ ë³€í™˜ (ì´ë¯¸ Float32Arrayì´ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ë³µì‚¬)
        const float32Array = new Float32Array(inputData.length)
        for (let i = 0; i < inputData.length; i++) {
          float32Array[i] = inputData[i]
        }

        // WebSocketìœ¼ë¡œ ì „ì†¡
        try {
          wsRef.current.send(float32Array.buffer)
          chunkCount++
          if (chunkCount % 100 === 0) { // 100ë²ˆë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ ë¡œê·¸
            console.log('[STT] ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡:', chunkCount, 'ê°œ (í¬ê¸°:', float32Array.length, 'ìƒ˜í”Œ)')
          }
        } catch (err) {
          console.error('[STT] âŒ ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜:', err)
          setError(`ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: ${err.message}`)
        }
      }

      source.connect(processor)
      processor.connect(audioContext.destination)
      console.log('[STT] âœ… ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì—°ê²° ì™„ë£Œ')

      isRecordingRef.current = true
      setIsRecording(true)
      console.log('[STT] âœ… ë…¹ìŒ ì‹œì‘ ì™„ë£Œ!')
    } catch (err) {
      console.error('[STT] âŒ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', err)
      setError(`ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ${err.message} - ë¸Œë¼ìš°ì € ì½˜ì†”ì„ í™•ì¸í•˜ì„¸ìš”`)
      isRecordingRef.current = false
      setIsRecording(false)
    }
  }

  const stopRecording = () => {
    console.log('[STT] â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ì¤‘...')
    isRecordingRef.current = false
    setIsRecording(false)

    // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (mediaStreamRef.current) {
      console.log('[STT] ğŸ”‡ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì¤‘...')
      mediaStreamRef.current.getTracks().forEach(track => {
        track.stop()
        console.log('[STT] âœ… íŠ¸ë™ ì •ì§€:', track.id)
      })
      mediaStreamRef.current = null
    }

    // AudioContext ì •ë¦¬
    if (processorRef.current) {
      console.log('[STT] ğŸ”Œ í”„ë¡œì„¸ì„œ ì—°ê²° í•´ì œ ì¤‘...')
      processorRef.current.disconnect()
      processorRef.current = null
    }
    if (sourceRef.current) {
      console.log('[STT] ğŸ”Œ ì†ŒìŠ¤ ì—°ê²° í•´ì œ ì¤‘...')
      sourceRef.current.disconnect()
      sourceRef.current = null
    }
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      console.log('[STT] ğŸ”Œ AudioContext ì¢…ë£Œ ì¤‘...')
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    // WebSocketì€ ìœ ì§€ (ì¬ì—°ê²°ì„ ìœ„í•´)
    if (wsRef.current) {
      console.log('[STT] ğŸ”Œ WebSocket ì¢…ë£Œ ì¤‘...')
      wsRef.current.close()
      wsRef.current = null
    }
    
    console.log('[STT] âœ… ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ')
  }

  const handleReset = () => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send('reset')
    }
    setTranscript('')
    setQuality(null)
  }

  const getQualityLabel = (quality) => {
    const labels = {
      success: 'ì„±ê³µ',
      medium: 'ë³´í†µ',
      low_quality: 'í’ˆì§ˆ ë‚®ìŒ',
      no_speech: 'ìŒì„± ì—†ìŒ'
    }
    return labels[quality] || quality
  }

  const getQualityColor = (quality) => {
    const colors = {
      success: '#4caf50',
      medium: '#ff9800',
      low_quality: '#f44336',
      no_speech: '#9e9e9e'
    }
    return colors[quality] || '#666'
  }

  return (
    <div className="card">
      <h2>Speech-to-Text í…ŒìŠ¤íŠ¸</h2>
      
      <div style={{ marginBottom: '1rem' }}>
        <div style={{ 
          display: 'flex', 
          alignItems: 'center', 
          gap: '0.5rem',
          marginBottom: '0.5rem',
          flexWrap: 'wrap'
        }}>
          <div style={{
            width: '12px',
            height: '12px',
            borderRadius: '50%',
            backgroundColor: isConnected ? '#4caf50' : '#f44336'
          }} />
          <span style={{ fontSize: '0.9rem', color: '#666' }}>
            {isConnected ? 'ì—°ê²°ë¨' : 'ì—°ê²° ì•ˆ ë¨'}
          </span>
          {isRecording && (
            <>
              <div style={{
                width: '12px',
                height: '12px',
                borderRadius: '50%',
                backgroundColor: '#f44336',
                animation: 'pulse 1.5s ease-in-out infinite'
              }} />
              <span style={{ 
                fontSize: '0.9rem', 
                color: '#f44336',
                fontWeight: 'bold'
              }}>
                ğŸ¤ ë…¹ìŒ ì¤‘...
              </span>
            </>
          )}
        </div>
        {quality && (
          <div style={{ fontSize: '0.9rem', color: getQualityColor(quality) }}>
            í’ˆì§ˆ: {getQualityLabel(quality)}
          </div>
        )}
      </div>

      <style>{`
        @keyframes pulse {
          0%, 100% {
            opacity: 1;
          }
          50% {
            opacity: 0.5;
          }
        }
      `}</style>

      {error && (
        <div style={{
          padding: '0.75rem',
          marginBottom: '1rem',
          backgroundColor: '#ffebee',
          color: '#c62828',
          borderRadius: '8px',
          fontSize: '0.9rem'
        }}>
          {error}
        </div>
      )}

      <div className="button-group" style={{ marginBottom: '1rem' }}>
        <button
          className={`btn ${isRecording ? 'btn-danger' : 'btn-primary'}`}
          onClick={isRecording ? stopRecording : startRecording}
          disabled={false}
          style={{
            minWidth: '150px',
            position: 'relative'
          }}
        >
          {isRecording ? (
            <>
              <span style={{ 
                display: 'inline-block',
                width: '8px',
                height: '8px',
                borderRadius: '50%',
                backgroundColor: 'white',
                marginRight: '8px',
                animation: 'pulse 1s ease-in-out infinite'
              }} />
              â¹ï¸ ë…¹ìŒ ì¤‘ì§€
            </>
          ) : (
            'ğŸ¤ ë…¹ìŒ ì‹œì‘'
          )}
        </button>
        {isRecording && (
          <button
            className="btn btn-secondary"
            onClick={() => {
              console.log('[STT] ğŸ”¨ ê°•ì œ ì¸ì‹ ìš”ì²­')
              if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
                wsRef.current.send('force_process')
              } else {
                setError('WebSocketì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
              }
            }}
            disabled={!isConnected}
            style={{
              backgroundColor: '#ff9800',
              color: 'white'
            }}
          >
            ğŸ”¨ ê°•ì œ ì¸ì‹
          </button>
        )}
        <button
          className="btn btn-secondary"
          onClick={handleReset}
          disabled={!isConnected || isRecording}
        >
          ë¦¬ì…‹
        </button>
      </div>

      <div className="input-group">
        <div style={{ 
          display: 'flex', 
          justifyContent: 'space-between',
          alignItems: 'center',
          marginBottom: '0.5rem'
        }}>
          <label style={{ 
            fontWeight: 600,
            color: '#333'
          }}>
            ì¸ì‹ëœ í…ìŠ¤íŠ¸:
          </label>
          {transcript && (
            <button
              onClick={() => setTranscript('')}
              style={{
                padding: '0.25rem 0.75rem',
                fontSize: '0.85rem',
                backgroundColor: '#f5f5f5',
                border: '1px solid #ddd',
                borderRadius: '4px',
                cursor: 'pointer'
              }}
            >
              ì§€ìš°ê¸°
            </button>
          )}
        </div>
        <textarea
          value={transcript || ''}
          readOnly
          placeholder={isRecording ? "ë§ì”€í•˜ì‹œë©´ ì—¬ê¸°ì— í…ìŠ¤íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤..." : "ë…¹ìŒì„ ì‹œì‘í•˜ë©´ ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤..."}
          style={{
            minHeight: '150px',
            backgroundColor: isRecording ? '#fff' : '#f5f5f5',
            border: isRecording ? '2px solid #4caf50' : '2px solid #e0e0e0',
            transition: 'all 0.3s'
          }}
        />
        {isRecording && !transcript && (
          <div style={{
            marginTop: '0.5rem',
            fontSize: '0.85rem',
            color: '#666',
            fontStyle: 'italic'
          }}>
            ğŸ’¡ ë§ˆì´í¬ì— ë§ì”€í•´ì£¼ì„¸ìš”. ë°œí™”ê°€ ëë‚˜ë©´ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.
          </div>
        )}
      </div>

      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        backgroundColor: '#f5f5f5', 
        borderRadius: '8px',
        fontSize: '0.85rem',
        color: '#666'
      }}>
        <strong>ì‚¬ìš© ë°©ë²•:</strong>
        <ul style={{ marginTop: '0.5rem', paddingLeft: '1.5rem' }}>
          <li>ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ì„¸ìš”</li>
          <li>ë§ˆì´í¬ì— ë§í•˜ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤</li>
          <li>2ì´ˆ ì´ìƒ ì¹¨ë¬µí•˜ë©´ ìë™ìœ¼ë¡œ ë°œí™”ê°€ ì¢…ë£Œë©ë‹ˆë‹¤</li>
          <li>ë¦¬ì…‹ ë²„íŠ¼ìœ¼ë¡œ VADë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</li>
        </ul>
        <div style={{ 
          marginTop: '1rem', 
          padding: '0.75rem', 
          backgroundColor: '#e3f2fd', 
          borderRadius: '6px',
          border: '1px solid #90caf9'
        }}>
          <strong>ğŸ” ë””ë²„ê¹…:</strong> ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬(F12)ì˜ ì½˜ì†” íƒ­ì„ ì—´ì–´ <code>[STT]</code>ë¡œ ì‹œì‘í•˜ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.
        </div>
      </div>
    </div>
  )
}

export default STTTest

